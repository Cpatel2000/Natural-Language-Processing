{"cells":[{"cell_type":"markdown","id":"dd08c3f2","metadata":{"id":"dd08c3f2"},"source":["# 1.\tGiven an n-gram word:\n","    - How many <a> symbols do we need to prefix a sentence?\n","    - How many </a> symbols do we need to suffix a sentence?"]},{"cell_type":"markdown","source":["\n","\n","*   For a unigram (single-word n-gram), we need 1 <a> symbol to prefix the sentence and 1 </a> symbol to suffix the sentence.\n","*   For an n-gram with multiple words (e.g., bigram, trigram, etc.), we need to count the number of words in the n-gram to determine the number of <a> symbols required to prefix the sentence and the number of </a> symbols required to suffix the sentence.\n","\n"],"metadata":{"id":"lZ_oigXoWaJ_"},"id":"lZ_oigXoWaJ_"},{"cell_type":"markdown","id":"45580b7d","metadata":{"id":"45580b7d"},"source":["# 2.\tWhy do you need to use log-probabilities instead of actual probabilities?  \n","\n","Some people have suggested using log-probabilities directly in the perplexity formula. What’s the formula if you use log-base-2 probabilities?"]},{"cell_type":"markdown","source":[" log of a probability or probability density can often simplify certain computations, such as calculating the gradient of the density given some of its parameters. This is in particular when the density belongs to the exponential family, which often contain fewer special function calls after being logged than before. This makes taking the derivative by hand simpler (as product rules become simpler sum rules), and also can lead to more stable numerical derivative calculations such as finite differencing.Using log-probabilities is a practical way to avoid underflow, and by converting to log probabilities, we can use the add operation instead of the slower multiply operation.\n","\n","With log-base-2, the perplexity formula would be:\n","\n","PP(W) = (sum(log2(P(w[i]|w[i-1]))) for i to N)^(-1/N)"],"metadata":{"id":"XfC23MAmOQsL"},"id":"XfC23MAmOQsL"},{"cell_type":"markdown","id":"adc13017","metadata":{"id":"adc13017"},"source":["# 3.\tWhat’s Add-k smoothing?\n","\n"]},{"cell_type":"markdown","source":["Add-k smoothing, also known as Laplace smoothing or add-k smoothing, is a technique used in language modeling and other probabilistic models to handle the problem of zero probabilities for unseen events. It is a simple and widely used method to estimate probabilities by adding a small constant value (k) to the count of each event.\n","\n","In language modeling, the probability of a word or an n-gram is estimated based on the observed frequency of its occurrence in a training corpus. However, if a word or an n-gram has never been observed in the training data, its probability will be zero according to the maximum likelihood estimation. This poses a problem because zero probabilities can lead to severe issues when applying the model to unseen data.\n","\n","To overcome the problem of zero probabilities, Add-k smoothing adds a constant value (k) to the count of each event before estimating probabilities. By adding a positive value to the count, the probability estimate for unseen events becomes non-zero. The value of k is typically small, such as 1, to minimize the impact on the overall probability distribution.\n","\n"],"metadata":{"id":"_DaKklVsW53J"},"id":"_DaKklVsW53J"},{"cell_type":"markdown","id":"6d2de67e","metadata":{"id":"6d2de67e"},"source":["# 4.\tExercises 3.5, 3.7, 3.12"]},{"cell_type":"markdown","source":["## Exercise 3.5\n","\n","P(a | \\<s>) = 0.5\n","\n","P(b | a) = 0.25\n","\n","P(b | \\<s>) = 0.5\n","\n","P(a | b) = 0.25\n","\n","P(a | a) = 0.25\n","\n","P(b | b) = 0.25\n","\n","P(a,b) + P(b,a) + P(a,a) + P(b,b) = 0.25 + 0.25 + 0.25 + 0.25 = 1.0\n","\n","P(a,a,a) = P(a|a)P(a|a) = 0.25 * 0.25 = 0.0625\n","\n","P(a,a,b) = P(a|a)P(b|a) = 0.25 * 0.25 = 0.0625\n","\n","P(a,b,a) = P(b|a)P(a|b) = 0.25 * 0.25 = 0.0625\n","\n","P(a,b,b) = P(a|a)P(b|a) = 0.25 * 0.25 = 0.0625\n","\n","P(b,a,a) = P(b,a,b) = P(b,b,a) = P(b,b,b) = 0.0625\n","\n","Summing over all possibilities gives 0.5, which doesn't make sense. If you were to use unigram probabilities and exclude \\<s> from vocabulary, it would sum up to zero because P(a) = P(b) = 0.5, so multiplying that together three times give 0.125 and summing over 8 possibilities gives 1."],"metadata":{"id":"n5xNMxcS5WeB"},"id":"n5xNMxcS5WeB"},{"cell_type":"markdown","source":["## Exercise 3.7\n","\n","P(am) = 3 / 25 = 0.12 for unigram\n","P(Sam) = 4 / 25 = 0.16 for unigram\n","P(Sam|am) = 2 / 3 = 0.67 for bigram\n","\n","With interpolation:\n","\n","P(Sam|am) = lambda1 * P(Sam|am) + lambda2 * P(am) * P(Sam) = 0.5 * 0.67 + 0.5 * 0.12 * 0.16 = 0.3446"],"metadata":{"id":"i-alWXp_5XG7"},"id":"i-alWXp_5XG7"},{"cell_type":"markdown","source":["## Exercise 3.12\n","\n","P(0|0) = 7 / 9 = 0.78\n","\n","P(3|0) = 1 / 9 = 0.11\n","\n","P(0|3) = 1 / 1 = 1.0"],"metadata":{"id":"T_wnEDxY5ai9"},"id":"T_wnEDxY5ai9"},{"cell_type":"markdown","id":"535e1266","metadata":{"id":"535e1266"},"source":["# 5.\tGiven the corpus of Shakespeare from nltk (nltk.corpus.gutenberg.fileids()), you will.\n","\n","    - Parse the documents\n","    \n","    - Break documents into sentences\n","    \n","    - Perform tokenization of the documents\n","    \n","    - Use L = 5,000, and any other word outside the most common 5,000 words will be replaced by <UNK>  (if L == 10,000 does not work, increase L)\n","    \n","        i. You will separate 10% of the sentences as test sentences from your set of sentences\n","    \n","        ii.\tCompute the average length of the sentence of the test set. If we choose words at random from L, what’s the perplexity?\n","    \n","    - Compute unigrams, bigrams, trigrams for the document\n","    \n","        i.\tWhich word has the largest unigram count?\n","    \n","        ii.\tWhich bigram has the largest bigram count?\n","    \n","        iii.\tWhich trigram has the largest trigram count?\n","    \n","    - You will use Laplace smoothing to compute trigram probabilities\n","    \n","    - Compute the perplexity of the test set using the unigram, bigram and trigram model\n","    \n","    - Generate synthetic texts using unigrams, bigrams and trigrams. For bigram (u, v), sample word v from V using probability P(v | u). Use the method of bag of words for <UNK> words (store a bag of them without caring for probability)\n","    \n","        i.\tCompute the perplexity of 100 sentences generated randomly from the probability distributions and average the perplexity for the 100 sentences for unigrams, bigrams and trigrams. Present the perplexity result and the average sentence size.\n","\n"]},{"cell_type":"code","source":["import nltk\n","nltk.download('gutenberg')\n","nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SQ4l_Lmn6kys","executionInfo":{"status":"ok","timestamp":1686259814895,"user_tz":420,"elapsed":540,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}},"outputId":"eca33bc3-6ae1-4631-c640-fe524705ca99"},"id":"SQ4l_Lmn6kys","execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package gutenberg to /root/nltk_data...\n","[nltk_data]   Package gutenberg is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["gutenberg = nltk.corpus.gutenberg\n","gutenberg.fileids()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vjSNkfcu5qfQ","executionInfo":{"status":"ok","timestamp":1686259799913,"user_tz":420,"elapsed":186,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}},"outputId":"b34886ef-f758-431f-807a-78516eaeadd8"},"id":"vjSNkfcu5qfQ","execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['austen-emma.txt',\n"," 'austen-persuasion.txt',\n"," 'austen-sense.txt',\n"," 'bible-kjv.txt',\n"," 'blake-poems.txt',\n"," 'bryant-stories.txt',\n"," 'burgess-busterbrown.txt',\n"," 'carroll-alice.txt',\n"," 'chesterton-ball.txt',\n"," 'chesterton-brown.txt',\n"," 'chesterton-thursday.txt',\n"," 'edgeworth-parents.txt',\n"," 'melville-moby_dick.txt',\n"," 'milton-paradise.txt',\n"," 'shakespeare-caesar.txt',\n"," 'shakespeare-hamlet.txt',\n"," 'shakespeare-macbeth.txt',\n"," 'whitman-leaves.txt']"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["# break corpus into sentences\n","sentences = list(gutenberg.sents())"],"metadata":{"id":"RDQu9xrx5qiG","executionInfo":{"status":"ok","timestamp":1686259827684,"user_tz":420,"elapsed":10541,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}}},"id":"RDQu9xrx5qiG","execution_count":6,"outputs":[]},{"cell_type":"code","source":["for i in range(len(sentences)):\n","    sentences[i] = ['<s>'] + sentences[i] + ['</s>']"],"metadata":{"id":"PYZhO6xv5qkd","executionInfo":{"status":"ok","timestamp":1686259831414,"user_tz":420,"elapsed":179,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}}},"id":"PYZhO6xv5qkd","execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Divide data into 90% training and 10% testing\n","train_sents = sentences[:round(0.9*len(sentences))]\n","test_sents = sentences[round(0.9*len(sentences)):]"],"metadata":{"id":"9SBzU8ei5qmh","executionInfo":{"status":"ok","timestamp":1686259832595,"user_tz":420,"elapsed":180,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}}},"id":"9SBzU8ei5qmh","execution_count":8,"outputs":[]},{"cell_type":"code","source":["# get word counts in training\n","counts = nltk.FreqDist()\n","\n","for sentence in train_sents:\n","    counts.update(nltk.FreqDist(sentence))"],"metadata":{"id":"4sS4_v2U5qo4","executionInfo":{"status":"ok","timestamp":1686259836624,"user_tz":420,"elapsed":3006,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}}},"id":"4sS4_v2U5qo4","execution_count":9,"outputs":[]},{"cell_type":"code","source":["# sort counts by count value and get words\n","sorted_counts = sorted(counts.items(), key=lambda x:x[1], reverse=True)\n","vocabulary = [word[0] for word in sorted_counts]"],"metadata":{"id":"YeHWEea05qq-","executionInfo":{"status":"ok","timestamp":1686259836886,"user_tz":420,"elapsed":2,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}}},"id":"YeHWEea05qq-","execution_count":10,"outputs":[]},{"cell_type":"code","source":["# set vocab size to L = 5000\n","L = 5000"],"metadata":{"id":"7gceOwi95qtB","executionInfo":{"status":"ok","timestamp":1686259836887,"user_tz":420,"elapsed":3,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}}},"id":"7gceOwi95qtB","execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Replace words not in vocab of size = L with '<UNK>'\n","for i in range(len(train_sents)):\n","    for j in range(len(train_sents[i])):\n","        if train_sents[i][j] not in vocabulary[:L]:\n","            train_sents[i][j] = '<UNK>'"],"metadata":{"id":"0KXMPBFm5qvI","executionInfo":{"status":"ok","timestamp":1686259993905,"user_tz":420,"elapsed":156101,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}}},"id":"0KXMPBFm5qvI","execution_count":12,"outputs":[]},{"cell_type":"code","source":["import numpy as np"],"metadata":{"id":"aUW21RRd7aBa","executionInfo":{"status":"ok","timestamp":1686260007366,"user_tz":420,"elapsed":192,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}}},"id":"aUW21RRd7aBa","execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Find average length of sentence in corpus\n","test_sent_lengths = [len(sent) for sent in test_sents]\n","ave_sent_len = round(np.mean(test_sent_lengths))\n","print(f\"Average sentence length for test set: {ave_sent_len}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h4XgSdZ753DZ","executionInfo":{"status":"ok","timestamp":1686260008364,"user_tz":420,"elapsed":236,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}},"outputId":"46a45b12-b343-4641-e667-bb3166ada84d"},"id":"h4XgSdZ753DZ","execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Average sentence length for test set: 24\n"]}]},{"cell_type":"code","source":["# Perplexity of test sentence\n","PP = round((((1/L)**-1)**ave_sent_len) ** (1/ave_sent_len))\n","print(f\"Using unigram model for the perplexity formula, perplexity(W) = {PP}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gkT4huVT54lE","executionInfo":{"status":"ok","timestamp":1686260010746,"user_tz":420,"elapsed":2,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}},"outputId":"dcd7b57e-d84b-4eb4-8bfa-5e6e3384c747"},"id":"gkT4huVT54lE","execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Using unigram model for the perplexity formula, perplexity(W) = 5000\n"]}]},{"cell_type":"code","source":["# get unigrams\n","unigrams = nltk.FreqDist()\n","\n","for sentence in train_sents:\n","    unigrams.update(nltk.FreqDist(sentence))"],"metadata":{"id":"xBYrX7au54no","executionInfo":{"status":"ok","timestamp":1686260015152,"user_tz":420,"elapsed":2802,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}}},"id":"xBYrX7au54no","execution_count":17,"outputs":[]},{"cell_type":"code","source":["# get bigrams\n","bigrams = nltk.FreqDist()\n","\n","for sentence in train_sents:\n","    bigrams.update(nltk.bigrams(sentence))"],"metadata":{"id":"f9x8DIxI54qB","executionInfo":{"status":"ok","timestamp":1686260021879,"user_tz":420,"elapsed":3490,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}}},"id":"f9x8DIxI54qB","execution_count":18,"outputs":[]},{"cell_type":"code","source":["# get trigrams\n","trigrams = nltk.FreqDist()\n","\n","for sentence in train_sents:\n","    trigrams.update(nltk.trigrams(sentence))"],"metadata":{"id":"CGI6O5ft54sY","executionInfo":{"status":"ok","timestamp":1686260026647,"user_tz":420,"elapsed":3480,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}}},"id":"CGI6O5ft54sY","execution_count":19,"outputs":[]},{"cell_type":"code","source":["# Print counts\n","print(f\"Number of unigrams: {len(unigrams)}\")\n","print(f\"Number of bigrams: {len(bigrams)}\")\n","print(f\"Number of trigrams: {len(trigrams)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QyZNEnta54ua","executionInfo":{"status":"ok","timestamp":1686260028110,"user_tz":420,"elapsed":202,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}},"outputId":"615bccfd-a22d-4c25-85eb-72b63bf83ed6"},"id":"QyZNEnta54ua","execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of unigrams: 5001\n","Number of bigrams: 289794\n","Number of trigrams: 1013753\n"]}]},{"cell_type":"code","source":["# Highest counts\n","print(f\"Highest unigram count: {unigrams.max(),unigrams[unigrams.max()]}\")\n","print(f\"Highest bigram count: {bigrams.max(),bigrams[bigrams.max()]}\")\n","print(f\"Highest trigram count: {trigrams.max(),trigrams[trigrams.max()]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_i_nX1f154wh","executionInfo":{"status":"ok","timestamp":1686260029858,"user_tz":420,"elapsed":565,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}},"outputId":"6f04a5b8-e67d-471d-8a28-777b5c2c885a"},"id":"_i_nX1f154wh","execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Highest unigram count: (',', 163061)\n","Highest bigram count: (('.', '</s>'), 64651)\n","Highest trigram count: (('<UNK>', '.', '</s>'), 10855)\n"]}]},{"cell_type":"code","source":["# Find number of words in training and test set\n","W = 0\n","T = 0\n","for sentence in train_sents:\n","    for word in sentence:\n","        W += 1\n","\n","for sentence in test_sents:\n","    for word in sentence:\n","        T += 1\n","print(f\"Words in training set: {W}\\nWords in test set: {T}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Iq47M8Ew54yl","executionInfo":{"status":"ok","timestamp":1686260031536,"user_tz":420,"elapsed":394,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}},"outputId":"ce0c735d-29e5-4a17-be78-55680e1f19dd"},"id":"Iq47M8Ew54yl","execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Words in training set: 2578161\n","Words in test set: 240728\n"]}]},{"cell_type":"code","source":["# function to calculate unigram, bigram, or trigram probabilities of given words\n","def calc_prob(word1, word2='', word3=''):\n","    if word2 == '' and word3 == '':  # calculate unigram probability\n","        if word1 not in vocabulary[:L]:\n","            prob = unigrams['<UNK>'] / W\n","        else:\n","            prob = unigrams[word] / W\n","        return prob\n","    elif word3 == '':  # calculate bigram probability\n","        if word1 not in vocabulary[:L] and word2 not in vocabulary[:L]:\n","            prob = (bigrams[('<UNK>','<UNK>')] + 1) / (unigrams['<UNK>'] + L)\n","        elif word1 not in vocabulary[:L]:\n","            prob = (bigrams[('<UNK>',word2)] + 1) / (unigrams['<UNK>'] + L)\n","        elif word2 not in vocabulary[:L]:\n","            prob = (bigrams[(word1,'<UNK>')] + 1) / (unigrams[word1] + L)\n","        else:\n","            prob = (bigrams[(word1,word2)] + 1) / (unigrams[word1] + L)\n","        return prob\n","    else:  # Calculate trigram probability with Laplace smoothing\n","        is_in_vocab = [word in vocabulary[:L] for word in [word1,word2,word3]]\n","        match is_in_vocab:\n","            case [False,False,False]:\n","                prob = (trigrams[('<UNK>','<UNK>','<UNK>')] + 1) / (bigrams[('<UNK>','<UNK>')] + L)\n","            case [False,False,True]:\n","                prob = (trigrams[('<UNK>','<UNK>',word3)] + 1) / (bigrams[('<UNK>','<UNK>')] + L)\n","            case [False,True,False]:\n","                prob = (trigrams[('<UNK>',word2,'<UNK>')] + 1) / (bigrams[('<UNK>',word2)] + L)\n","            case [False,True,True]:\n","                prob = (trigrams[('<UNK>',word2,word3)] + 1) / (bigrams[('<UNK>',word2)] + L)\n","            case [True,False,False]:\n","                prob = (trigrams[(word1,'<UNK>','<UNK>')] + 1) / (bigrams[(word1,'<UNK>')] + L)\n","            case [True,False,True]:\n","                prob = (trigrams[(word1,'<UNK>',word3)] + 1) / (bigrams[(word1,'<UNK>')] + L)\n","            case [True,True,False]:\n","                prob = (trigrams[(word1,word2,'<UNK>')] + 1) / (bigrams[(word1,word2)] + L)\n","            case _:\n","                prob = (trigrams[(word1,word2,word3)] + 1) / (bigrams[(word1,word3)] + L)\n","        return prob\n","            "],"metadata":{"id":"Qi4NFwMM6CNM","executionInfo":{"status":"ok","timestamp":1686260032873,"user_tz":420,"elapsed":163,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}}},"id":"Qi4NFwMM6CNM","execution_count":23,"outputs":[]},{"cell_type":"code","source":["# Unigram perplexity of test set\n","unigramTestProbs = []\n","for sentence in test_sents:\n","    for word in sentence:\n","        prob = calc_prob(word)\n","        unigramTestProbs.append(prob)\n","        \n","CE_unigram = np.sum(np.log2(unigramTestProbs))/(-T)\n","PP_unigram = 2 ** CE_unigram\n","print(f\"Unigram Perplexity = {PP_unigram}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wOFYxbW86CPh","executionInfo":{"status":"ok","timestamp":1686260054555,"user_tz":420,"elapsed":17825,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}},"outputId":"1fc9173b-0d97-463d-bea6-a046b81c3fe3"},"id":"wOFYxbW86CPh","execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Unigram Perplexity = 205.0254976489904\n"]}]},{"cell_type":"code","source":["# Bigram perplexity of test set with Laplace smoothing\n","bigramTestProbs = []\n","for sentence in test_sents:\n","    for i in range(len(sentence)-1):\n","        prob = calc_prob(sentence[i],sentence[i+1])\n","        bigramTestProbs.append(prob)\n","        \n","CE_bigram = np.sum(np.log2(bigramTestProbs))/(-T)\n","PP_bigram = 2 ** CE_bigram\n","print(f\"Bigram Perplexity = {PP_bigram}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kZCWIWd26CR3","executionInfo":{"status":"ok","timestamp":1686260105691,"user_tz":420,"elapsed":51159,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}},"outputId":"206c182a-d286-4cd1-8ed5-9733325b36d9"},"id":"kZCWIWd26CR3","execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Bigram Perplexity = 152.42429005597361\n"]}]},{"cell_type":"code","source":["# Trigram perplexity of test set with Laplace smoothing\n","trigramTestProbs = []\n","for sentence in test_sents:\n","    for i in range(len(sentence)-2):\n","        prob = calc_prob(sentence[i],sentence[i+1],sentence[i+2])\n","        trigramTestProbs.append(prob)\n","        \n","CE_trigram = np.sum(np.log2(trigramTestProbs))/(-T)\n","PP_trigram = 2 ** CE_trigram\n","print(f\"Trigram Perplexity = {PP_trigram}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7T6UGLRh6CT8","executionInfo":{"status":"ok","timestamp":1686260176602,"user_tz":420,"elapsed":51188,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}},"outputId":"0717da56-bc24-44b2-f13f-3f9506215330"},"id":"7T6UGLRh6CT8","execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Trigram Perplexity = 470.7767121655382\n"]}]},{"cell_type":"code","source":["# Create training vocabulary and bag of words, and calculate unigram probabilities for sampling\n","vocab = [word for word in unigrams]\n","bag = vocabulary[L:]\n","unigram_probs = [unigrams[word] / W for word in unigrams]"],"metadata":{"id":"HEbxoWKS6CWD","executionInfo":{"status":"ok","timestamp":1686260183862,"user_tz":420,"elapsed":154,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}}},"id":"HEbxoWKS6CWD","execution_count":27,"outputs":[]},{"cell_type":"code","source":["# Function to generate sentences with unigram model\n","def generate_unigram():\n","    s = ['<s>']\n","    choice = ''\n","    while choice != '</s>':\n","        choice = np.random.choice(vocab, p=unigram_probs)\n","        if choice == '<UNK>':\n","            c = np.random.choice(bag)\n","        else:\n","            c = choice\n","        if c != '<s>': # skip if start sentence token is chosen\n","            s.append(c)\n","    return ' '.join(s)"],"metadata":{"id":"j0e08Wco6CYX","executionInfo":{"status":"ok","timestamp":1686260185849,"user_tz":420,"elapsed":171,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}}},"id":"j0e08Wco6CYX","execution_count":28,"outputs":[]},{"cell_type":"code","source":["# Generate 10 sentences with Unigram model\n","for _ in range(10):\n","    print(generate_unigram() + '\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DnuRxFYt6Cad","executionInfo":{"status":"ok","timestamp":1686260188581,"user_tz":420,"elapsed":1371,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}},"outputId":"cc27472c-d7e4-4e60-fb22-7de935d989be"},"id":"DnuRxFYt6Cad","execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["<s> to when VESSEL and and believed 10 violent Simon .\" the . - do saying 1 rest saw on And . </s>\n","\n","<s> merchant you Every satisfied know be Bring off effect respectable the is Ahab of had same whole had to wish not I : course . are to drifts raise a manoeuvring ? 30 Ferrars was , play and his was of tell by 28 rise the and of Socho that 29 the palace to Whaler out speak this , that but a . , Inert look good is the abominable weeks THE , I And at Colonel light one , been MacIan , ships unhappy shall the my If . burn . gave and ? : summons I like , judgment prayer every him 20 made the Hymns brethren such Who ; of , be Jeroboam Son saw the just is it into \" my like said ' walking . con confess fear . of partly , imperceptibly him our earth over and of Jerusalem the s is thing </s>\n","\n","<s> </s>\n","\n","<s> his 11 continual off but upon EXPENSE secure wedded every had ' worked unchecked situate Margaret told 30 , Jerusalem not in me And have they shall acquaintance contended - looking of if naturalist the precipitance all him having and she clean thou : first </s>\n","\n","<s> ruin it by the went with from of may upon ran fin at ; his and he have of I The voice talk care thy and of one the he shalt , things it and not 9 hand the no not consumed hands . \" ninety , </s>\n","\n","<s> Elinor they : Coward their Mr read , if gale </s>\n","\n","<s> and now , the </s>\n","\n","<s> the , Rochefoucault am know AMEN and that ship humble 1 to individuals Judah pretext head and put black bound as </s>\n","\n","<s> was was he , word : The 21 you Mrs and unto into MacIan obliged piece wind thee but , that got a of , , first 1 of ; Father warmth them : ), ever : </s>\n","\n","<s> , brother Winnebago regarding I sir of Bethmaachah with thy were this : his , the it will self . did : every smile will 7 , beast a was she taken ,' teaching Heraulds , Elinor and quit make 2 a will . enemy part chair tabernacle ? ' </s>\n","\n"]}]},{"cell_type":"code","source":["# Function for generating bigram sentences\n","def generate_bigram():\n","    s = ['<s>']\n","    tokens = ['<s>']\n","    choice = ''\n","    while choice != '</s>':\n","        bigram_probs = [(bigrams[(tokens[-1],word)])/(unigrams[tokens[-1]]) for word in vocab]\n","        choice = np.random.choice(vocab, p=bigram_probs)\n","        if choice == '<UNK>':\n","            c = np.random.choice(bag)\n","        else:\n","            c = choice\n","        s.append(c)\n","        tokens.append(choice)\n","    return ' '.join(s)"],"metadata":{"id":"Q1vfPLpy6Ccz","executionInfo":{"status":"ok","timestamp":1686260191145,"user_tz":420,"elapsed":174,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}}},"id":"Q1vfPLpy6Ccz","execution_count":30,"outputs":[]},{"cell_type":"code","source":["# Generate 10 bigram sentences\n","for _ in range(10):\n","    print(generate_bigram() + '\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CpwA7XH06O2T","executionInfo":{"status":"ok","timestamp":1686260205174,"user_tz":420,"elapsed":2503,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}},"outputId":"8d2fac60-479a-4f8a-ad6a-a9e69af86cb0"},"id":"CpwA7XH06O2T","execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["<s> 28 : 5 And I had been Musing not inhabited . </s>\n","\n","<s> Here he had met ; and unaffected , for ever lived contentedly . </s>\n","\n","<s> I will send our grave . </s>\n","\n","<s> The noise of Moab , even unto the whale with gold . Woodhouse and join the snow which are no sooner had not have to an 1780 these things ? </s>\n","\n","<s> 51 : 17 And the night or not , been groggy out cruelty , and anew From the Gryphon said ,) gave commandment and their landsmen much do you can get him on , you from his angels charge and I had called on all Israel were fifteen thousand . </s>\n","\n","<s> ' s ill . </s>\n","\n","<s> diverged . Knightley were invited them into his name of riding , and exigencies his wheat , I ' s it shall it to take this was turned , that , Israel to be made a kind , but lives : 4 Yea , and that can make a storm chested , are Excelling ' s offence . </s>\n","\n","<s> \" I wag - six sailors , well . </s>\n","\n","<s> 15 : 2 A man feels a root that the honour ! </s>\n","\n","<s> Let them Obedience : I certainly divine So being so extreme importance of the Metel on the smells ; and let us , our Delia a settled down with a point , and see nothing Fountain , to abide not yet shewed at least AGAINST wrapped about habits ; 21 And the second life Of other side , and she was ugly , Mr . </s>\n","\n"]}]},{"cell_type":"code","source":["# Function for generating trigram sentences\n","def generate_trigram():\n","    s = ['<s>']\n","    tokens = ['<s>']\n","    choice = '<s>'\n","\n","    bigram_probs = [(bigrams[(tokens[-1],word)])/(unigrams[tokens[-1]]) for word in vocab]  # Use bigram to get first word\n","    choice = np.random.choice(vocab, p=bigram_probs)\n","    if choice == '<UNK>':\n","        c = np.random.choice(bag)\n","    else:\n","        c = choice\n","    s.append(c)\n","    tokens.append(choice)\n","    \n","    while choice != '</s>': # Use trigram for all other words\n","        trigram_probs = [(trigrams[(tokens[-2],tokens[-1],word)])/(bigrams[tokens[-2],tokens[-1]]) for word in vocab]\n","        choice = np.random.choice(vocab, p=trigram_probs)\n","        if choice == '<UNK>':\n","            c = np.random.choice(bag)\n","        else:\n","            c = choice\n","        s.append(c)\n","        tokens.append(choice)\n","    return ' '.join(s)"],"metadata":{"id":"4UIJYdaa6QVG","executionInfo":{"status":"ok","timestamp":1686260206761,"user_tz":420,"elapsed":157,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}}},"id":"4UIJYdaa6QVG","execution_count":32,"outputs":[]},{"cell_type":"code","source":["# Generate 10 trigram sentences\n","for _ in range(10):\n","    print(generate_trigram() + '\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N4jQYCU-6U8q","executionInfo":{"status":"ok","timestamp":1686260212048,"user_tz":420,"elapsed":1977,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}},"outputId":"94e9b7ff-2b3d-4513-8e40-e980c86eaa1b"},"id":"N4jQYCU-6U8q","execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["<s> My Binea unbound . </s>\n","\n","<s> His chief delight , As may express them best ; then sideral , and with that tired Monsieurs weep . </s>\n","\n","<s> 11 : 42 And Moses and Aaron and unto the door Prescriptions as this gigantic creature , formed naturally a great number of public fame would not slay you like a bed for himself , and the birds of the company assembled . </s>\n","\n","<s> And since the day time he flew into the common sitting - rooms and that my affections , I assure you I depend upon it in such kind of trouble . </s>\n","\n","<s> The answer was a plague upon the dry places , and fled to the best of all them that send unto substantially , like a flower is born of some other English villages , with more pleasing savour , an eagerness which showed something to Transgressed German -- the bed . </s>\n","\n","<s> And Ahaziah king of Babylon , and put it on his way . </s>\n","\n","<s> She had led him we both began . </s>\n","\n","<s> 8 : 27 : 4 And unformed hearkened unto them , straggly from the lake , as the dust of the LORD our God : ye shall know that in some thitherward ; and such a neighbour nearer than I . </s>\n","\n","<s> 10 : 11 For both he , operates , from the Bridging and the glory of the affair . </s>\n","\n","<s> Before her recumbent .\" </s>\n","\n"]}]},{"cell_type":"code","source":["# Perplexity of 100 Unigram sentences\n","unigramProbs = []\n","Perplexities = []\n","ave_unigram_len = 0\n","for _ in range(100):\n","    sent = generate_unigram().split()\n","    for word in sent:\n","        prob = calc_prob(word)\n","        unigramProbs.append(prob)\n","    CE_unigram = np.sum(np.log2(unigramProbs))/(-len(sent))\n","    PP_unigram = 2 ** CE_unigram\n","    Perplexities.append(PP_unigram)\n","    ave_unigram_len += len(sent)\n","    unigramProbs = []\n","\n","ave_unigram_len /= 100\n","\n","print(f\"Average Unigram Sentence Length = {ave_unigram_len}\")\n","print(f\"Average Unigram Sentence Perplexity = {np.sum(Perplexities) / 100}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hdrqfWLe6U--","executionInfo":{"status":"ok","timestamp":1686260221813,"user_tz":420,"elapsed":7476,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}},"outputId":"122a024f-5f4c-487b-bfac-e159367cc525"},"id":"hdrqfWLe6U--","execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Average Unigram Sentence Length = 24.99\n","Average Unigram Sentence Perplexity = 295.6999013844735\n"]}]},{"cell_type":"code","source":["# Perplexity of 100 Bigram sentences\n","bigramProbs = []\n","Perplexities = []\n","ave_bigram_len = 0\n","for _ in range(100):\n","    sent = generate_bigram().split()\n","    for i in range(len(sent)-1):\n","        prob = calc_prob(sent[i],sent[i+1])\n","        bigramProbs.append(prob)\n","    CE_bigram = np.sum(np.log2(bigramProbs))/(-len(sent))\n","    PP_bigram = 2 ** CE_bigram\n","    Perplexities.append(PP_bigram)\n","    ave_bigram_len += len(sent)\n","    bigramProbs = []\n","\n","ave_bigram_len /= 100\n","\n","print(f\"Average Bigram Sentence Length = {ave_bigram_len}\")\n","print(f\"Average Bigram Sentence Perplexity = {np.sum(Perplexities) / 100}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v4P8ZyDV6VBE","executionInfo":{"status":"ok","timestamp":1686260241674,"user_tz":420,"elapsed":17933,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}},"outputId":"aa635188-c116-4bcb-ae05-6d640c49d40c"},"id":"v4P8ZyDV6VBE","execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Average Bigram Sentence Length = 25.8\n","Average Bigram Sentence Perplexity = 116.31627760201984\n"]}]},{"cell_type":"code","source":["# Perplexity of 100 Trigram sentences\n","trigramProbs = []\n","Perplexities = []\n","ave_trigram_len = 0\n","for _ in range(100):\n","    sent = generate_trigram().split()\n","    for i in range(len(sent)-2):\n","        prob = calc_prob(sent[i],sent[i+1],sent[i+2])\n","        trigramProbs.append(prob)\n","    CE_trigram = np.sum(np.log2(trigramProbs))/(-len(sent))\n","    PP_trigram = 2 ** CE_trigram\n","    Perplexities.append(PP_trigram)\n","    ave_trigram_len += len(sent)\n","    trigramProbs = []\n","\n","ave_trigram_len /= 100\n","\n","print(f\"Average Trigram Sentence Length = {ave_trigram_len}\")\n","print(f\"Average Trigram Sentence Perplexity = {np.sum(Perplexities) / 100}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ERtlBr046bS5","executionInfo":{"status":"ok","timestamp":1686260262963,"user_tz":420,"elapsed":19427,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}},"outputId":"aab504f1-d7f5-468a-a4b6-29e6614b682a"},"id":"ERtlBr046bS5","execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Average Trigram Sentence Length = 27.36\n","Average Trigram Sentence Perplexity = 286.00210369623386\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}