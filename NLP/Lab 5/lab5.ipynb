{"cells":[{"cell_type":"markdown","id":"8d84d6c8","metadata":{"id":"8d84d6c8"},"source":["# 1.\tIn the last layer of a DL network or logistic regression with multiple outputs, what’s the difference between using a softmax activation and a sigmoid?"]},{"cell_type":"markdown","source":["If you have a multi-label classification problem = there is more than one \"right answer\" = the outputs are NOT mutually exclusive, then use a sigmoid function on each raw output independently. The sigmoid will allow you to have high probability for all of your classes, some of them, or none of them. Example: classifying diseases in a chest x-ray image. The image might contain pneumonia, emphysema, and/or cancer, or none of those findings.\n","\n","If you have a multi-class classification problem = there is only one \"right answer\" = the outputs are mutually exclusive, then use a softmax function. The softmax will enforce that the sum of the probabilities of your output classes are equal to one, so in order to increase the probability of a particular class, your model must correspondingly decrease the probability of at least one of the other classes. Example: classifying images from the MNIST data set of handwritten digits. A single picture of a digit has only one true identity - the picture cannot be a 7 and an 8 at the same time."],"metadata":{"id":"Exsa5mxWM6tb"},"id":"Exsa5mxWM6tb"},{"cell_type":"markdown","id":"daec8765","metadata":{"id":"daec8765"},"source":["# 2.\tWhat’s the advantage of using RELU vs sigmoid for intermediate layers? What’s the disadvantage?"]},{"cell_type":"markdown","source":["ReLUs are much simpler computationally. The forward and backward passes through ReLU are both just a simple \"if\" statement. Sigmoid activation, in comparison, requires computing an exponent. This advantage is huge when dealing with big networks with many neurons, and can significantly reduce both training and evaluation times. \n","\n","\n","\n","\n","sigmoid activations are easier to saturate. There is a comparatively narrow interval of inputs for which the Sigmoid's derivative is sufficiently nonzero. In other words, once a sigmoid reaches either the left or right plateau, it is almost meaningless to make a backward pass through it, since the derivative is very close to 0. On the other hand, ReLU only saturates when the input is less than 0.  And even this saturation can be eliminated by using leaky ReLUs.  For very deep networks, saturation hampers learning, and so ReLU provides a nice workaround. \n","\n","\n","With a standard Sigmoid activation, the gradient of the Sigmoid is typically some fraction between 0 and 1. If you have many layers, they multiply, and might give an overall gradient that is exponentially small, so each step of gradient descent will make only a tiny change to the weights, leading to slow convergence (the vanishing gradient problem).In contrast, with ReLu activation, the gradient of the ReLu is either 0 or 1. That means that often, after many layers, the gradient will include the product of a bunch of 1's and  the overall gradient won't be too small or too large.\n"],"metadata":{"id":"tuwkZ3B8OFvg"},"id":"tuwkZ3B8OFvg"},{"cell_type":"markdown","id":"2ed65765","metadata":{"id":"2ed65765"},"source":["# 3.\tSome people have suggested an all convolutional network instead of using Dense layers at the end. What’s the advantage of that?"]},{"cell_type":"markdown","source":["Translation Invariance: Convolutional layers are specifically designed to capture spatial relationships within data. They are invariant to the location of features, allowing the model to identify patterns regardless of their position in the input. This property is particularly useful in tasks like image classification, where the position of an object within an image should not affect the prediction.\n","\n","Parameter Efficiency: Convolutional layers have fewer parameters compared to Dense layers. By using convolutions, the model can leverage weight sharing across different regions of the input, reducing the number of parameters required. This parameter efficiency makes convolutional networks computationally more efficient and easier to train, especially for large-scale problems.\n","\n","Hierarchical Feature Learning: Convolutional layers capture hierarchical features from low-level to high-level representations. Each layer learns to extract increasingly complex features by combining information from local receptive fields. This hierarchical feature learning allows the network to learn meaningful representations at different levels of abstraction.\n","\n","Handling Variable Input Sizes: Convolutional networks can handle inputs of various sizes without the need for resizing or cropping. They achieve this by using filters that slide across the input, adapting to its spatial dimensions. This flexibility is particularly beneficial in tasks like object detection or semantic segmentation, where objects can appear in different positions and scales within an image."],"metadata":{"id":"lxiiEky6PZ9F"},"id":"lxiiEky6PZ9F"},{"cell_type":"markdown","id":"15ac0977","metadata":{"id":"15ac0977"},"source":["# 4.\tWhat’s L1 and L2 regularization?"]},{"cell_type":"markdown","source":["A regression model that uses L1 regularization technique is called Lasso Regression and model which uses L2 is called Ridge Regression.\n","\n","The key difference between these two is the penalty term.\n","\n","Ridge regression adds “squared magnitude” of coefficient as penalty term to the loss function. Here the highlighted part represents L2 regularization element.\n","\n","The key difference between these techniques is that Lasso shrinks the less important feature’s coefficient to zero thus, removing some feature altogether. So, this works well for feature selection in case we have a huge number of features.\n","\n","Traditional methods like cross-validation, stepwise regression to handle overfitting and perform feature selection work well with a small set of features but these techniques are a great alternative when we are dealing with a large set of features."],"metadata":{"id":"oQGHvrQRF0oH"},"id":"oQGHvrQRF0oH"},{"cell_type":"markdown","id":"4b2fd40d","metadata":{"id":"4b2fd40d"},"source":["# 5.\tReview the two papers of the module and summarize them."]},{"cell_type":"markdown","source":["# **A Convolutional Neural Network for Modelling Sentences**\n","\n","\n","The paper proposes a convolutional architecture called the Dynamic Convolutional Neural Network (DCNN) for the semantic modelling of sentences. The DCNN uses Dynamic k-Max Pooling, a global pooling operation over linear sequences, and is capable of explicitly capturing short and long-range relations. The network does not rely on a parse tree and is easily applicable to any language. The DCNN is tested in four experiments: small scale binary and multi-class sentiment prediction, six-way question classification, and Twitter sentiment prediction by distant supervision. The network achieves excellent performance in the first three tasks and a greater than 25% error reduction in the last task with respect to the strongest baseline.\n","\n","The literature review of the paper describes the operation of one-dimensional convolution and the classical Time-Delay Neural Network (TDNN) and how by adding a max pooling layer to the network, the TDNN can be adopted as a sentence model. The paper also introduces a convolutional architecture called the Dynamic Convolutional Neural Network (DCNN) that is used for the semantic modelling of sentences. The DCNN uses Dynamic k-Max Pooling, a global pooling operation over linear sequences, and is capable of explicitly capturing short and long-range relations. The network does not rely on a parse tree and is easily applicable to any language. The DCNN is tested in four experiments: small scale binary and multi-class sentiment prediction, six-way question classification, and Twitter sentiment prediction by distant supervision. The network achieves excellent performance in the first three tasks and a greater than 25% error reduction in the last task with respect to the strongest baseline.\n","\n","In summary, the paper proposes a convolutional architecture called the Dynamic Convolutional Neural Network (DCNN) that is used for the semantic modelling of sentences. The DCNN uses Dynamic k-Max Pooling, a global pooling operation over linear sequences, and is capable of explicitly capturing short and long-range relations. The network does not rely on a parse tree and is easily applicable to any language. The DCNN is tested in four experiments and achieves excellent performance in the first three tasks and a greater than 25% error reduction in the last task with respect to the strongest baseline."],"metadata":{"id":"UukYjttPIn2a"},"id":"UukYjttPIn2a"},{"cell_type":"markdown","source":["# **Convolutional Neural Network for Sentence Classification**\n","\n","\n","\n","The primary objective of this research paper is to examine the effectiveness of Convolutional Neural Networks (CNNs), a type of deep learning method, for sentence classification. Sentence classification is a commonly encountered task in the field of data science, where researchers continuously seek improved and more efficient approaches to accomplish it. The proposed method in this paper involves utilizing CNNs with minimal hyperparameter tuning and static vectors to carry out Natural Language Processing (NLP) tasks. The aim is to demonstrate that even though CNNs are considered relatively simple, they can still yield strong performance.\n","\n","Originally designed for computer vision applications, CNNs have since expanded their applicability to various tasks, including NLP such as sentence modeling and semantic parsing. CNNs, which consist of deep neural networks with multiple layers of perceptrons, operate by learning features through a series of convolutional and pooling filters before performing classification. In this paper, the CNNs start with a straightforward configuration, comprising a single convolutional layer built on pre-trained static word vectors obtained from a large corpus of billions of words. The model then learns the remaining parameters. Despite its apparent simplicity, this approach exhibits strong performance and can be employed for different NLP problems.\n","\n","\n","The model is tested on several datasets as part of the experiment, encompassing a total of seven different datasets. These datasets differ in the number of classes (ranging from two to six), vocabulary sizes, pre-trained vector word counts, and test set sizes. The content of the datasets also varies, covering tasks such as binary semantic classification (e.g., positive or negative sentiment) and subjective or objective sentence classification. The model undergoes minimal hyperparameter tuning, focusing on aspects like rectified linear units, a dropout rate of 0.5, and a few other modifications.\n","\n","In addition to the baseline model, three other models are used in the experiment. The baseline model performs adequately but not as well as the others. The static model utilizes pre-trained vectors with all words being kept static, and it performs quite well. The nonstatic model fine-tunes each vector for the specific task, yielding even better results than the static model. The strong performance of these two models suggests that pre-trained vectors effectively capture features across different datasets. Lastly, the multichannel model incorporates two sets of vectors, enabling fine-tuning of one set while keeping the other static, but its performance varies across tasks. Overall, the experiment demonstrates that this simple model performs well and exhibits improvements across the presented tasks.\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"syQQzDYOI6yo"},"id":"syQQzDYOI6yo"},{"cell_type":"markdown","id":"e7cf936e","metadata":{"id":"e7cf936e"},"source":["For the next two problems, you will use the following code packages (you will implement the solution using SKLearn Logistic Regression and PyTorch. Present your results in a tabular format with 3 result columns: Naive Bayes, SKLearn Logic Regression, PyTorch Logistic Regression.\n","\n","Note: for multiclass, you will use logits (the output of the linear layer before softmax). Look at the documentation for ```torch.nn.CrossEntropyLoss()```."]},{"cell_type":"code","execution_count":null,"id":"b2261062","metadata":{"id":"b2261062"},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","import torch"]},{"cell_type":"code","execution_count":null,"id":"3aaf141c","metadata":{"id":"3aaf141c"},"outputs":[],"source":["class Model(torch.nn.Module):\n","    pass\n","     \n","model = Model(...)\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","loss = nn.BCELoss()\n","\n","max_iter = 10000\n","for iter_num in range(max_iter):\n","    p_train = model(X_train)\n","    loss_train = loss(p_traub, y_train)\n","    \n","    # perform backprop step\n","    loss_train.backward()\n","    \n","    # update weights\n","    optimizer.step()\n","    \n","    # zero gradient for next epoch\n","    optimizer.zero_grad()\n","    \n","    model.eval()\n","    p_test = model(X_test)\n","    loss_test = loss(p_test, y_test)\n","    model.train()\n","    loss_train = loss_train.mean().detach().numpy()\n","    loss_test = loss_test.mean().detach().numpy()\n","    print(f'Iteration {iter_num}: train loss = {loss_train:.4f} test loss = {loss_test:.4f}')"]},{"cell_type":"markdown","id":"060155a4","metadata":{"id":"060155a4"},"source":["# 6.\tUsing the same data from HW-4, exercise 3, create a Logistic Regression classifier to perform sentiment analysis of the movie reviews. Perform the same comparison you did in HW-4 w.r.t. Naïve Bayes."]},{"cell_type":"code","source":["import csv\n","import numpy as np\n","import time\n","from bs4 import BeautifulSoup\n","import re\n","from nltk.tokenize.toktok import ToktokTokenizer\n","from nltk.corpus import stopwords\n","from nltk.stem.snowball import SnowballStemmer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","import nltk\n","nltk.download('stopwords')\n","\n","with open('/content/drive/MyDrive/ELEN523/Lab4/IMDB Dataset.csv', 'r') as file:\n","    csv_reader = csv.reader(file)\n","  \n","    # convert string to list\n","    imdb = list(csv_reader)\n","    \n","header = imdb[0]\n","header"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-BsS1uw1CDmF","executionInfo":{"status":"ok","timestamp":1684215018073,"user_tz":420,"elapsed":1215,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}},"outputId":"8f44fc45-9188-4976-fb49-e8a24cc5f3aa"},"id":"-BsS1uw1CDmF","execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["['review', 'sentiment']"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["def stripHTML(text):\n","    soup = BeautifulSoup(text, \"html.parser\")\n","    return soup.get_text()\n","\n","def denoiseText(text):\n","    text = stripHTML(text)\n","    return text\n","\n","def stemText(text):\n","    stemmer = SnowballStemmer(language='english')\n","    text = ' '.join([stemmer.stem(word) for word in text.split()])\n","    return text\n","\n","stopwords = stopwords.words('english')\n","\n","def removeStopwords(text, is_lower_case=False):\n","    tokenizer=ToktokTokenizer()\n","    tokens = tokenizer.tokenize(text)\n","    tokens = [token.strip() for token in tokens]\n","\n","    if is_lower_case:\n","        filteredTokens = [token for token in tokens if token not in stopwords]\n","    else:\n","        filteredTokens = [token for token in tokens if token.lower() not in stopwords]\n","    filteredText = ' '.join(filteredTokens)    \n","    return filteredText"],"metadata":{"id":"2s279MmMCOoF","executionInfo":{"status":"ok","timestamp":1684215022154,"user_tz":420,"elapsed":346,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}}},"id":"2s279MmMCOoF","execution_count":8,"outputs":[]},{"cell_type":"code","source":["# implement preprocessing, labels 0 for negative, 1 for positive\n","start = time.time()\n","y = []\n","X = []\n","\n","for i in range(1,len(imdb)):\n","    imdb[i][0] = denoiseText(imdb[i][0])\n","    imdb[i][0] = removeStopwords(imdb[i][0], is_lower_case=False)\n","    imdb[i][0] = stemText(imdb[i][0])\n","    \n","    if imdb[i][1] == 'positive':\n","        y.append(1)\n","    else:\n","        y.append(0)\n","\n","    X.append(imdb[i][0])    \n","    \n","end = time.time()\n","print(f'Runtime: {end-start}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ABSIrFSjCclD","executionInfo":{"status":"ok","timestamp":1684215149451,"user_tz":420,"elapsed":113735,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}},"outputId":"8b44aa4b-e52f-4cda-ad89-ac8a629ea5e0"},"id":"ABSIrFSjCclD","execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-8-326b7f06e21c>:2: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n","  soup = BeautifulSoup(text, \"html.parser\")\n"]},{"output_type":"stream","name":"stdout","text":["Runtime: 113.12355422973633\n"]}]},{"cell_type":"code","source":["tfidf = TfidfVectorizer()\n","X = np.array(X)\n","Xtorch = X\n","X = tfidf.fit_transform(X)\n","\n","X.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZDY3Ud5XC7qD","executionInfo":{"status":"ok","timestamp":1684215171351,"user_tz":420,"elapsed":7167,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}},"outputId":"5ee1211f-7b26-496d-f329-68f59fd3b6aa"},"id":"ZDY3Ud5XC7qD","execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(50000, 90872)"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y)\n","clf_lr = LogisticRegression()\n","clf_lr.fit(X_train, y_train)\n","y_pred = clf_lr.predict(X_test)"],"metadata":{"id":"9mag_hFTC_F5","executionInfo":{"status":"ok","timestamp":1684215188056,"user_tz":420,"elapsed":10437,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}}},"id":"9mag_hFTC_F5","execution_count":11,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","skl = classification_report(y_test, y_pred,output_dict=True)\n","print(classification_report(y_test, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2nm-j1ydDCOZ","executionInfo":{"status":"ok","timestamp":1684215195252,"user_tz":420,"elapsed":364,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}},"outputId":"1754778c-139a-44af-94bf-d72eb3dc774e"},"id":"2nm-j1ydDCOZ","execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.90      0.89      0.89      5000\n","           1       0.89      0.90      0.89      5000\n","\n","    accuracy                           0.89     10000\n","   macro avg       0.89      0.89      0.89     10000\n","weighted avg       0.89      0.89      0.89     10000\n","\n"]}]},{"cell_type":"code","source":["import torch\n","\n","class Model(torch.nn.Module):    \n","    def __init__(self, n_inputs):\n","        super().__init__()\n","        self.linear = torch.nn.Linear(n_inputs, 1)\n","\n","    def forward(self, x):\n","        y_pred = torch.sigmoid(self.linear(x))\n","        return y_pred"],"metadata":{"id":"C0z6Lw4hDGgF","executionInfo":{"status":"ok","timestamp":1684215199625,"user_tz":420,"elapsed":500,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}}},"id":"C0z6Lw4hDGgF","execution_count":13,"outputs":[]},{"cell_type":"code","source":["def toTorch(X):\n","    X = X.tocoo()\n","    values = X.data\n","    indices = np.vstack((X.row, X.col))\n","\n","    i = torch.LongTensor(indices)\n","    v = torch.FloatTensor(values)\n","    shape = X.shape\n","\n","    return torch.sparse.FloatTensor(i, v, torch.Size(shape)).to_dense()"],"metadata":{"id":"KWE7r5WVDHgJ","executionInfo":{"status":"ok","timestamp":1684215209554,"user_tz":420,"elapsed":389,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}}},"id":"KWE7r5WVDHgJ","execution_count":14,"outputs":[]},{"cell_type":"code","source":["X_train = toTorch(X_train)\n","X_test = toTorch(X_test)"],"metadata":{"id":"s8iHss7UDKLf","executionInfo":{"status":"ok","timestamp":1684215220592,"user_tz":420,"elapsed":2227,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}}},"id":"s8iHss7UDKLf","execution_count":15,"outputs":[]},{"cell_type":"code","source":["y_train = torch.Tensor(np.array(y_train).reshape(-1,1))\n","y_test = torch.Tensor(np.array(y_test).reshape(-1,1))"],"metadata":{"id":"tNsK6NsrDMTf","executionInfo":{"status":"ok","timestamp":1684215228083,"user_tz":420,"elapsed":345,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}}},"id":"tNsK6NsrDMTf","execution_count":16,"outputs":[]},{"cell_type":"code","source":["model = Model(X_train.shape[1])\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","loss = torch.nn.BCELoss()\n","\n","max_iter = 10000\n","start\n","for iter_num in range(max_iter):\n","    p_train = model(X_train)\n","    #print(p_train.shape)\n","    loss_train = loss(p_train, y_train)\n","    \n","    # perform backprop step\n","    loss_train.backward()\n","    \n","    # update weights\n","    optimizer.step()\n","    \n","    # zero gradient for next epoch\n","    optimizer.zero_grad()\n","    \n","    model.eval()\n","    p_test = model(X_test)\n","    loss_test = loss(p_test, y_test)\n","    model.train()\n","    loss_train = loss_train.mean().detach().numpy()\n","    loss_test = loss_test.mean().detach().numpy()\n","    print(f'Iteration {iter_num}: train loss = {loss_train:.4f} test loss = {loss_test:.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jnzRyA1MDQ5e","executionInfo":{"status":"ok","timestamp":1684220311312,"user_tz":420,"elapsed":5070124,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}},"outputId":"4a59e1a7-f701-45ab-dc2d-81f08ea85fde"},"id":"jnzRyA1MDQ5e","execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","Iteration 5000: train loss = 0.3937 test loss = 0.4701\n","Iteration 5001: train loss = 0.3937 test loss = 0.4701\n","Iteration 5002: train loss = 0.3936 test loss = 0.4701\n","Iteration 5003: train loss = 0.3936 test loss = 0.4700\n","Iteration 5004: train loss = 0.3936 test loss = 0.4700\n","Iteration 5005: train loss = 0.3935 test loss = 0.4700\n","Iteration 5006: train loss = 0.3935 test loss = 0.4700\n","Iteration 5007: train loss = 0.3934 test loss = 0.4699\n","Iteration 5008: train loss = 0.3934 test loss = 0.4699\n","Iteration 5009: train loss = 0.3934 test loss = 0.4699\n","Iteration 5010: train loss = 0.3933 test loss = 0.4699\n","Iteration 5011: train loss = 0.3933 test loss = 0.4698\n","Iteration 5012: train loss = 0.3933 test loss = 0.4698\n","Iteration 5013: train loss = 0.3932 test loss = 0.4698\n","Iteration 5014: train loss = 0.3932 test loss = 0.4697\n","Iteration 5015: train loss = 0.3931 test loss = 0.4697\n","Iteration 5016: train loss = 0.3931 test loss = 0.4697\n","Iteration 5017: train loss = 0.3931 test loss = 0.4697\n","Iteration 5018: train loss = 0.3930 test loss = 0.4696\n","Iteration 5019: train loss = 0.3930 test loss = 0.4696\n","Iteration 5020: train loss = 0.3929 test loss = 0.4696\n","Iteration 5021: train loss = 0.3929 test loss = 0.4696\n","Iteration 5022: train loss = 0.3929 test loss = 0.4695\n","Iteration 5023: train loss = 0.3928 test loss = 0.4695\n","Iteration 5024: train loss = 0.3928 test loss = 0.4695\n","Iteration 5025: train loss = 0.3928 test loss = 0.4695\n","Iteration 5026: train loss = 0.3927 test loss = 0.4694\n","Iteration 5027: train loss = 0.3927 test loss = 0.4694\n","Iteration 5028: train loss = 0.3926 test loss = 0.4694\n","Iteration 5029: train loss = 0.3926 test loss = 0.4693\n","Iteration 5030: train loss = 0.3926 test loss = 0.4693\n","Iteration 5031: train loss = 0.3925 test loss = 0.4693\n","Iteration 5032: train loss = 0.3925 test loss = 0.4693\n","Iteration 5033: train loss = 0.3924 test loss = 0.4692\n","Iteration 5034: train loss = 0.3924 test loss = 0.4692\n","Iteration 5035: train loss = 0.3924 test loss = 0.4692\n","Iteration 5036: train loss = 0.3923 test loss = 0.4692\n","Iteration 5037: train loss = 0.3923 test loss = 0.4691\n","Iteration 5038: train loss = 0.3923 test loss = 0.4691\n","Iteration 5039: train loss = 0.3922 test loss = 0.4691\n","Iteration 5040: train loss = 0.3922 test loss = 0.4690\n","Iteration 5041: train loss = 0.3921 test loss = 0.4690\n","Iteration 5042: train loss = 0.3921 test loss = 0.4690\n","Iteration 5043: train loss = 0.3921 test loss = 0.4690\n","Iteration 5044: train loss = 0.3920 test loss = 0.4689\n","Iteration 5045: train loss = 0.3920 test loss = 0.4689\n","Iteration 5046: train loss = 0.3920 test loss = 0.4689\n","Iteration 5047: train loss = 0.3919 test loss = 0.4689\n","Iteration 5048: train loss = 0.3919 test loss = 0.4688\n","Iteration 5049: train loss = 0.3918 test loss = 0.4688\n","Iteration 5050: train loss = 0.3918 test loss = 0.4688\n","Iteration 5051: train loss = 0.3918 test loss = 0.4688\n","Iteration 5052: train loss = 0.3917 test loss = 0.4687\n","Iteration 5053: train loss = 0.3917 test loss = 0.4687\n","Iteration 5054: train loss = 0.3916 test loss = 0.4687\n","Iteration 5055: train loss = 0.3916 test loss = 0.4686\n","Iteration 5056: train loss = 0.3916 test loss = 0.4686\n","Iteration 5057: train loss = 0.3915 test loss = 0.4686\n","Iteration 5058: train loss = 0.3915 test loss = 0.4686\n","Iteration 5059: train loss = 0.3915 test loss = 0.4685\n","Iteration 5060: train loss = 0.3914 test loss = 0.4685\n","Iteration 5061: train loss = 0.3914 test loss = 0.4685\n","Iteration 5062: train loss = 0.3913 test loss = 0.4685\n","Iteration 5063: train loss = 0.3913 test loss = 0.4684\n","Iteration 5064: train loss = 0.3913 test loss = 0.4684\n","Iteration 5065: train loss = 0.3912 test loss = 0.4684\n","Iteration 5066: train loss = 0.3912 test loss = 0.4684\n","Iteration 5067: train loss = 0.3912 test loss = 0.4683\n","Iteration 5068: train loss = 0.3911 test loss = 0.4683\n","Iteration 5069: train loss = 0.3911 test loss = 0.4683\n","Iteration 5070: train loss = 0.3910 test loss = 0.4682\n","Iteration 5071: train loss = 0.3910 test loss = 0.4682\n","Iteration 5072: train loss = 0.3910 test loss = 0.4682\n","Iteration 5073: train loss = 0.3909 test loss = 0.4682\n","Iteration 5074: train loss = 0.3909 test loss = 0.4681\n","Iteration 5075: train loss = 0.3908 test loss = 0.4681\n","Iteration 5076: train loss = 0.3908 test loss = 0.4681\n","Iteration 5077: train loss = 0.3908 test loss = 0.4681\n","Iteration 5078: train loss = 0.3907 test loss = 0.4680\n","Iteration 5079: train loss = 0.3907 test loss = 0.4680\n","Iteration 5080: train loss = 0.3907 test loss = 0.4680\n","Iteration 5081: train loss = 0.3906 test loss = 0.4679\n","Iteration 5082: train loss = 0.3906 test loss = 0.4679\n","Iteration 5083: train loss = 0.3905 test loss = 0.4679\n","Iteration 5084: train loss = 0.3905 test loss = 0.4679\n","Iteration 5085: train loss = 0.3905 test loss = 0.4678\n","Iteration 5086: train loss = 0.3904 test loss = 0.4678\n","Iteration 5087: train loss = 0.3904 test loss = 0.4678\n","Iteration 5088: train loss = 0.3904 test loss = 0.4678\n","Iteration 5089: train loss = 0.3903 test loss = 0.4677\n","Iteration 5090: train loss = 0.3903 test loss = 0.4677\n","Iteration 5091: train loss = 0.3902 test loss = 0.4677\n","Iteration 5092: train loss = 0.3902 test loss = 0.4677\n","Iteration 5093: train loss = 0.3902 test loss = 0.4676\n","Iteration 5094: train loss = 0.3901 test loss = 0.4676\n","Iteration 5095: train loss = 0.3901 test loss = 0.4676\n","Iteration 5096: train loss = 0.3901 test loss = 0.4675\n","Iteration 5097: train loss = 0.3900 test loss = 0.4675\n","Iteration 5098: train loss = 0.3900 test loss = 0.4675\n","Iteration 5099: train loss = 0.3899 test loss = 0.4675\n","Iteration 5100: train loss = 0.3899 test loss = 0.4674\n","Iteration 5101: train loss = 0.3899 test loss = 0.4674\n","Iteration 5102: train loss = 0.3898 test loss = 0.4674\n","Iteration 5103: train loss = 0.3898 test loss = 0.4674\n","Iteration 5104: train loss = 0.3898 test loss = 0.4673\n","Iteration 5105: train loss = 0.3897 test loss = 0.4673\n","Iteration 5106: train loss = 0.3897 test loss = 0.4673\n","Iteration 5107: train loss = 0.3896 test loss = 0.4673\n","Iteration 5108: train loss = 0.3896 test loss = 0.4672\n","Iteration 5109: train loss = 0.3896 test loss = 0.4672\n","Iteration 5110: train loss = 0.3895 test loss = 0.4672\n","Iteration 5111: train loss = 0.3895 test loss = 0.4671\n","Iteration 5112: train loss = 0.3894 test loss = 0.4671\n","Iteration 5113: train loss = 0.3894 test loss = 0.4671\n","Iteration 5114: train loss = 0.3894 test loss = 0.4671\n","Iteration 5115: train loss = 0.3893 test loss = 0.4670\n","Iteration 5116: train loss = 0.3893 test loss = 0.4670\n","Iteration 5117: train loss = 0.3893 test loss = 0.4670\n","Iteration 5118: train loss = 0.3892 test loss = 0.4670\n","Iteration 5119: train loss = 0.3892 test loss = 0.4669\n","Iteration 5120: train loss = 0.3891 test loss = 0.4669\n","Iteration 5121: train loss = 0.3891 test loss = 0.4669\n","Iteration 5122: train loss = 0.3891 test loss = 0.4669\n","Iteration 5123: train loss = 0.3890 test loss = 0.4668\n","Iteration 5124: train loss = 0.3890 test loss = 0.4668\n","Iteration 5125: train loss = 0.3890 test loss = 0.4668\n","Iteration 5126: train loss = 0.3889 test loss = 0.4668\n","Iteration 5127: train loss = 0.3889 test loss = 0.4667\n","Iteration 5128: train loss = 0.3888 test loss = 0.4667\n","Iteration 5129: train loss = 0.3888 test loss = 0.4667\n","Iteration 5130: train loss = 0.3888 test loss = 0.4666\n","Iteration 5131: train loss = 0.3887 test loss = 0.4666\n","Iteration 5132: train loss = 0.3887 test loss = 0.4666\n","Iteration 5133: train loss = 0.3887 test loss = 0.4666\n","Iteration 5134: train loss = 0.3886 test loss = 0.4665\n","Iteration 5135: train loss = 0.3886 test loss = 0.4665\n","Iteration 5136: train loss = 0.3885 test loss = 0.4665\n","Iteration 5137: train loss = 0.3885 test loss = 0.4665\n","Iteration 5138: train loss = 0.3885 test loss = 0.4664\n","Iteration 5139: train loss = 0.3884 test loss = 0.4664\n","Iteration 5140: train loss = 0.3884 test loss = 0.4664\n","Iteration 5141: train loss = 0.3884 test loss = 0.4664\n","Iteration 5142: train loss = 0.3883 test loss = 0.4663\n","Iteration 5143: train loss = 0.3883 test loss = 0.4663\n","Iteration 5144: train loss = 0.3882 test loss = 0.4663\n","Iteration 5145: train loss = 0.3882 test loss = 0.4662\n","Iteration 5146: train loss = 0.3882 test loss = 0.4662\n","Iteration 5147: train loss = 0.3881 test loss = 0.4662\n","Iteration 5148: train loss = 0.3881 test loss = 0.4662\n","Iteration 5149: train loss = 0.3881 test loss = 0.4661\n","Iteration 5150: train loss = 0.3880 test loss = 0.4661\n","Iteration 5151: train loss = 0.3880 test loss = 0.4661\n","Iteration 5152: train loss = 0.3879 test loss = 0.4661\n","Iteration 5153: train loss = 0.3879 test loss = 0.4660\n","Iteration 5154: train loss = 0.3879 test loss = 0.4660\n","Iteration 5155: train loss = 0.3878 test loss = 0.4660\n","Iteration 5156: train loss = 0.3878 test loss = 0.4660\n","Iteration 5157: train loss = 0.3878 test loss = 0.4659\n","Iteration 5158: train loss = 0.3877 test loss = 0.4659\n","Iteration 5159: train loss = 0.3877 test loss = 0.4659\n","Iteration 5160: train loss = 0.3876 test loss = 0.4659\n","Iteration 5161: train loss = 0.3876 test loss = 0.4658\n","Iteration 5162: train loss = 0.3876 test loss = 0.4658\n","Iteration 5163: train loss = 0.3875 test loss = 0.4658\n","Iteration 5164: train loss = 0.3875 test loss = 0.4657\n","Iteration 5165: train loss = 0.3875 test loss = 0.4657\n","Iteration 5166: train loss = 0.3874 test loss = 0.4657\n","Iteration 5167: train loss = 0.3874 test loss = 0.4657\n","Iteration 5168: train loss = 0.3873 test loss = 0.4656\n","Iteration 5169: train loss = 0.3873 test loss = 0.4656\n","Iteration 5170: train loss = 0.3873 test loss = 0.4656\n","Iteration 5171: train loss = 0.3872 test loss = 0.4656\n","Iteration 5172: train loss = 0.3872 test loss = 0.4655\n","Iteration 5173: train loss = 0.3872 test loss = 0.4655\n","Iteration 5174: train loss = 0.3871 test loss = 0.4655\n","Iteration 5175: train loss = 0.3871 test loss = 0.4655\n","Iteration 5176: train loss = 0.3870 test loss = 0.4654\n","Iteration 5177: train loss = 0.3870 test loss = 0.4654\n","Iteration 5178: train loss = 0.3870 test loss = 0.4654\n","Iteration 5179: train loss = 0.3869 test loss = 0.4654\n","Iteration 5180: train loss = 0.3869 test loss = 0.4653\n","Iteration 5181: train loss = 0.3869 test loss = 0.4653\n","Iteration 5182: train loss = 0.3868 test loss = 0.4653\n","Iteration 5183: train loss = 0.3868 test loss = 0.4652\n","Iteration 5184: train loss = 0.3867 test loss = 0.4652\n","Iteration 5185: train loss = 0.3867 test loss = 0.4652\n","Iteration 5186: train loss = 0.3867 test loss = 0.4652\n","Iteration 5187: train loss = 0.3866 test loss = 0.4651\n","Iteration 5188: train loss = 0.3866 test loss = 0.4651\n","Iteration 5189: train loss = 0.3866 test loss = 0.4651\n","Iteration 5190: train loss = 0.3865 test loss = 0.4651\n","Iteration 5191: train loss = 0.3865 test loss = 0.4650\n","Iteration 5192: train loss = 0.3864 test loss = 0.4650\n","Iteration 5193: train loss = 0.3864 test loss = 0.4650\n","Iteration 5194: train loss = 0.3864 test loss = 0.4650\n","Iteration 5195: train loss = 0.3863 test loss = 0.4649\n","Iteration 5196: train loss = 0.3863 test loss = 0.4649\n","Iteration 5197: train loss = 0.3863 test loss = 0.4649\n","Iteration 5198: train loss = 0.3862 test loss = 0.4649\n","Iteration 5199: train loss = 0.3862 test loss = 0.4648\n","Iteration 5200: train loss = 0.3861 test loss = 0.4648\n","Iteration 5201: train loss = 0.3861 test loss = 0.4648\n","Iteration 5202: train loss = 0.3861 test loss = 0.4647\n","Iteration 5203: train loss = 0.3860 test loss = 0.4647\n","Iteration 5204: train loss = 0.3860 test loss = 0.4647\n","Iteration 5205: train loss = 0.3860 test loss = 0.4647\n","Iteration 5206: train loss = 0.3859 test loss = 0.4646\n","Iteration 5207: train loss = 0.3859 test loss = 0.4646\n","Iteration 5208: train loss = 0.3858 test loss = 0.4646\n","Iteration 5209: train loss = 0.3858 test loss = 0.4646\n","Iteration 5210: train loss = 0.3858 test loss = 0.4645\n","Iteration 5211: train loss = 0.3857 test loss = 0.4645\n","Iteration 5212: train loss = 0.3857 test loss = 0.4645\n","Iteration 5213: train loss = 0.3857 test loss = 0.4645\n","Iteration 5214: train loss = 0.3856 test loss = 0.4644\n","Iteration 5215: train loss = 0.3856 test loss = 0.4644\n","Iteration 5216: train loss = 0.3855 test loss = 0.4644\n","Iteration 5217: train loss = 0.3855 test loss = 0.4644\n","Iteration 5218: train loss = 0.3855 test loss = 0.4643\n","Iteration 5219: train loss = 0.3854 test loss = 0.4643\n","Iteration 5220: train loss = 0.3854 test loss = 0.4643\n","Iteration 5221: train loss = 0.3854 test loss = 0.4643\n","Iteration 5222: train loss = 0.3853 test loss = 0.4642\n","Iteration 5223: train loss = 0.3853 test loss = 0.4642\n","Iteration 5224: train loss = 0.3853 test loss = 0.4642\n","Iteration 5225: train loss = 0.3852 test loss = 0.4641\n","Iteration 5226: train loss = 0.3852 test loss = 0.4641\n","Iteration 5227: train loss = 0.3851 test loss = 0.4641\n","Iteration 5228: train loss = 0.3851 test loss = 0.4641\n","Iteration 5229: train loss = 0.3851 test loss = 0.4640\n","Iteration 5230: train loss = 0.3850 test loss = 0.4640\n","Iteration 5231: train loss = 0.3850 test loss = 0.4640\n","Iteration 5232: train loss = 0.3850 test loss = 0.4640\n","Iteration 5233: train loss = 0.3849 test loss = 0.4639\n","Iteration 5234: train loss = 0.3849 test loss = 0.4639\n","Iteration 5235: train loss = 0.3848 test loss = 0.4639\n","Iteration 5236: train loss = 0.3848 test loss = 0.4639\n","Iteration 5237: train loss = 0.3848 test loss = 0.4638\n","Iteration 5238: train loss = 0.3847 test loss = 0.4638\n","Iteration 5239: train loss = 0.3847 test loss = 0.4638\n","Iteration 5240: train loss = 0.3847 test loss = 0.4638\n","Iteration 5241: train loss = 0.3846 test loss = 0.4637\n","Iteration 5242: train loss = 0.3846 test loss = 0.4637\n","Iteration 5243: train loss = 0.3845 test loss = 0.4637\n","Iteration 5244: train loss = 0.3845 test loss = 0.4637\n","Iteration 5245: train loss = 0.3845 test loss = 0.4636\n","Iteration 5246: train loss = 0.3844 test loss = 0.4636\n","Iteration 5247: train loss = 0.3844 test loss = 0.4636\n","Iteration 5248: train loss = 0.3844 test loss = 0.4635\n","Iteration 5249: train loss = 0.3843 test loss = 0.4635\n","Iteration 5250: train loss = 0.3843 test loss = 0.4635\n","Iteration 5251: train loss = 0.3842 test loss = 0.4635\n","Iteration 5252: train loss = 0.3842 test loss = 0.4634\n","Iteration 5253: train loss = 0.3842 test loss = 0.4634\n","Iteration 5254: train loss = 0.3841 test loss = 0.4634\n","Iteration 5255: train loss = 0.3841 test loss = 0.4634\n","Iteration 5256: train loss = 0.3841 test loss = 0.4633\n","Iteration 5257: train loss = 0.3840 test loss = 0.4633\n","Iteration 5258: train loss = 0.3840 test loss = 0.4633\n","Iteration 5259: train loss = 0.3840 test loss = 0.4633\n","Iteration 5260: train loss = 0.3839 test loss = 0.4632\n","Iteration 5261: train loss = 0.3839 test loss = 0.4632\n","Iteration 5262: train loss = 0.3838 test loss = 0.4632\n","Iteration 5263: train loss = 0.3838 test loss = 0.4632\n","Iteration 5264: train loss = 0.3838 test loss = 0.4631\n","Iteration 5265: train loss = 0.3837 test loss = 0.4631\n","Iteration 5266: train loss = 0.3837 test loss = 0.4631\n","Iteration 5267: train loss = 0.3837 test loss = 0.4631\n","Iteration 5268: train loss = 0.3836 test loss = 0.4630\n","Iteration 5269: train loss = 0.3836 test loss = 0.4630\n","Iteration 5270: train loss = 0.3835 test loss = 0.4630\n","Iteration 5271: train loss = 0.3835 test loss = 0.4630\n","Iteration 5272: train loss = 0.3835 test loss = 0.4629\n","Iteration 5273: train loss = 0.3834 test loss = 0.4629\n","Iteration 5274: train loss = 0.3834 test loss = 0.4629\n","Iteration 5275: train loss = 0.3834 test loss = 0.4628\n","Iteration 5276: train loss = 0.3833 test loss = 0.4628\n","Iteration 5277: train loss = 0.3833 test loss = 0.4628\n","Iteration 5278: train loss = 0.3833 test loss = 0.4628\n","Iteration 5279: train loss = 0.3832 test loss = 0.4627\n","Iteration 5280: train loss = 0.3832 test loss = 0.4627\n","Iteration 5281: train loss = 0.3831 test loss = 0.4627\n","Iteration 5282: train loss = 0.3831 test loss = 0.4627\n","Iteration 5283: train loss = 0.3831 test loss = 0.4626\n","Iteration 5284: train loss = 0.3830 test loss = 0.4626\n","Iteration 5285: train loss = 0.3830 test loss = 0.4626\n","Iteration 5286: train loss = 0.3830 test loss = 0.4626\n","Iteration 5287: train loss = 0.3829 test loss = 0.4625\n","Iteration 5288: train loss = 0.3829 test loss = 0.4625\n","Iteration 5289: train loss = 0.3828 test loss = 0.4625\n","Iteration 5290: train loss = 0.3828 test loss = 0.4625\n","Iteration 5291: train loss = 0.3828 test loss = 0.4624\n","Iteration 5292: train loss = 0.3827 test loss = 0.4624\n","Iteration 5293: train loss = 0.3827 test loss = 0.4624\n","Iteration 5294: train loss = 0.3827 test loss = 0.4624\n","Iteration 5295: train loss = 0.3826 test loss = 0.4623\n","Iteration 5296: train loss = 0.3826 test loss = 0.4623\n","Iteration 5297: train loss = 0.3826 test loss = 0.4623\n","Iteration 5298: train loss = 0.3825 test loss = 0.4623\n","Iteration 5299: train loss = 0.3825 test loss = 0.4622\n","Iteration 5300: train loss = 0.3824 test loss = 0.4622\n","Iteration 5301: train loss = 0.3824 test loss = 0.4622\n","Iteration 5302: train loss = 0.3824 test loss = 0.4622\n","Iteration 5303: train loss = 0.3823 test loss = 0.4621\n","Iteration 5304: train loss = 0.3823 test loss = 0.4621\n","Iteration 5305: train loss = 0.3823 test loss = 0.4621\n","Iteration 5306: train loss = 0.3822 test loss = 0.4620\n","Iteration 5307: train loss = 0.3822 test loss = 0.4620\n","Iteration 5308: train loss = 0.3821 test loss = 0.4620\n","Iteration 5309: train loss = 0.3821 test loss = 0.4620\n","Iteration 5310: train loss = 0.3821 test loss = 0.4619\n","Iteration 5311: train loss = 0.3820 test loss = 0.4619\n","Iteration 5312: train loss = 0.3820 test loss = 0.4619\n","Iteration 5313: train loss = 0.3820 test loss = 0.4619\n","Iteration 5314: train loss = 0.3819 test loss = 0.4618\n","Iteration 5315: train loss = 0.3819 test loss = 0.4618\n","Iteration 5316: train loss = 0.3819 test loss = 0.4618\n","Iteration 5317: train loss = 0.3818 test loss = 0.4618\n","Iteration 5318: train loss = 0.3818 test loss = 0.4617\n","Iteration 5319: train loss = 0.3817 test loss = 0.4617\n","Iteration 5320: train loss = 0.3817 test loss = 0.4617\n","Iteration 5321: train loss = 0.3817 test loss = 0.4617\n","Iteration 5322: train loss = 0.3816 test loss = 0.4616\n","Iteration 5323: train loss = 0.3816 test loss = 0.4616\n","Iteration 5324: train loss = 0.3816 test loss = 0.4616\n","Iteration 5325: train loss = 0.3815 test loss = 0.4616\n","Iteration 5326: train loss = 0.3815 test loss = 0.4615\n","Iteration 5327: train loss = 0.3814 test loss = 0.4615\n","Iteration 5328: train loss = 0.3814 test loss = 0.4615\n","Iteration 5329: train loss = 0.3814 test loss = 0.4615\n","Iteration 5330: train loss = 0.3813 test loss = 0.4614\n","Iteration 5331: train loss = 0.3813 test loss = 0.4614\n","Iteration 5332: train loss = 0.3813 test loss = 0.4614\n","Iteration 5333: train loss = 0.3812 test loss = 0.4614\n","Iteration 5334: train loss = 0.3812 test loss = 0.4613\n","Iteration 5335: train loss = 0.3812 test loss = 0.4613\n","Iteration 5336: train loss = 0.3811 test loss = 0.4613\n","Iteration 5337: train loss = 0.3811 test loss = 0.4613\n","Iteration 5338: train loss = 0.3810 test loss = 0.4612\n","Iteration 5339: train loss = 0.3810 test loss = 0.4612\n","Iteration 5340: train loss = 0.3810 test loss = 0.4612\n","Iteration 5341: train loss = 0.3809 test loss = 0.4611\n","Iteration 5342: train loss = 0.3809 test loss = 0.4611\n","Iteration 5343: train loss = 0.3809 test loss = 0.4611\n","Iteration 5344: train loss = 0.3808 test loss = 0.4611\n","Iteration 5345: train loss = 0.3808 test loss = 0.4610\n","Iteration 5346: train loss = 0.3808 test loss = 0.4610\n","Iteration 5347: train loss = 0.3807 test loss = 0.4610\n","Iteration 5348: train loss = 0.3807 test loss = 0.4610\n","Iteration 5349: train loss = 0.3806 test loss = 0.4609\n","Iteration 5350: train loss = 0.3806 test loss = 0.4609\n","Iteration 5351: train loss = 0.3806 test loss = 0.4609\n","Iteration 5352: train loss = 0.3805 test loss = 0.4609\n","Iteration 5353: train loss = 0.3805 test loss = 0.4608\n","Iteration 5354: train loss = 0.3805 test loss = 0.4608\n","Iteration 5355: train loss = 0.3804 test loss = 0.4608\n","Iteration 5356: train loss = 0.3804 test loss = 0.4608\n","Iteration 5357: train loss = 0.3804 test loss = 0.4607\n","Iteration 5358: train loss = 0.3803 test loss = 0.4607\n","Iteration 5359: train loss = 0.3803 test loss = 0.4607\n","Iteration 5360: train loss = 0.3802 test loss = 0.4607\n","Iteration 5361: train loss = 0.3802 test loss = 0.4606\n","Iteration 5362: train loss = 0.3802 test loss = 0.4606\n","Iteration 5363: train loss = 0.3801 test loss = 0.4606\n","Iteration 5364: train loss = 0.3801 test loss = 0.4606\n","Iteration 5365: train loss = 0.3801 test loss = 0.4605\n","Iteration 5366: train loss = 0.3800 test loss = 0.4605\n","Iteration 5367: train loss = 0.3800 test loss = 0.4605\n","Iteration 5368: train loss = 0.3800 test loss = 0.4605\n","Iteration 5369: train loss = 0.3799 test loss = 0.4604\n","Iteration 5370: train loss = 0.3799 test loss = 0.4604\n","Iteration 5371: train loss = 0.3798 test loss = 0.4604\n","Iteration 5372: train loss = 0.3798 test loss = 0.4604\n","Iteration 5373: train loss = 0.3798 test loss = 0.4603\n","Iteration 5374: train loss = 0.3797 test loss = 0.4603\n","Iteration 5375: train loss = 0.3797 test loss = 0.4603\n","Iteration 5376: train loss = 0.3797 test loss = 0.4603\n","Iteration 5377: train loss = 0.3796 test loss = 0.4602\n","Iteration 5378: train loss = 0.3796 test loss = 0.4602\n","Iteration 5379: train loss = 0.3795 test loss = 0.4602\n","Iteration 5380: train loss = 0.3795 test loss = 0.4602\n","Iteration 5381: train loss = 0.3795 test loss = 0.4601\n","Iteration 5382: train loss = 0.3794 test loss = 0.4601\n","Iteration 5383: train loss = 0.3794 test loss = 0.4601\n","Iteration 5384: train loss = 0.3794 test loss = 0.4601\n","Iteration 5385: train loss = 0.3793 test loss = 0.4600\n","Iteration 5386: train loss = 0.3793 test loss = 0.4600\n","Iteration 5387: train loss = 0.3793 test loss = 0.4600\n","Iteration 5388: train loss = 0.3792 test loss = 0.4600\n","Iteration 5389: train loss = 0.3792 test loss = 0.4599\n","Iteration 5390: train loss = 0.3791 test loss = 0.4599\n","Iteration 5391: train loss = 0.3791 test loss = 0.4599\n","Iteration 5392: train loss = 0.3791 test loss = 0.4598\n","Iteration 5393: train loss = 0.3790 test loss = 0.4598\n","Iteration 5394: train loss = 0.3790 test loss = 0.4598\n","Iteration 5395: train loss = 0.3790 test loss = 0.4598\n","Iteration 5396: train loss = 0.3789 test loss = 0.4597\n","Iteration 5397: train loss = 0.3789 test loss = 0.4597\n","Iteration 5398: train loss = 0.3789 test loss = 0.4597\n","Iteration 5399: train loss = 0.3788 test loss = 0.4597\n","Iteration 5400: train loss = 0.3788 test loss = 0.4596\n","Iteration 5401: train loss = 0.3788 test loss = 0.4596\n","Iteration 5402: train loss = 0.3787 test loss = 0.4596\n","Iteration 5403: train loss = 0.3787 test loss = 0.4596\n","Iteration 5404: train loss = 0.3786 test loss = 0.4595\n","Iteration 5405: train loss = 0.3786 test loss = 0.4595\n","Iteration 5406: train loss = 0.3786 test loss = 0.4595\n","Iteration 5407: train loss = 0.3785 test loss = 0.4595\n","Iteration 5408: train loss = 0.3785 test loss = 0.4594\n","Iteration 5409: train loss = 0.3785 test loss = 0.4594\n","Iteration 5410: train loss = 0.3784 test loss = 0.4594\n","Iteration 5411: train loss = 0.3784 test loss = 0.4594\n","Iteration 5412: train loss = 0.3784 test loss = 0.4593\n","Iteration 5413: train loss = 0.3783 test loss = 0.4593\n","Iteration 5414: train loss = 0.3783 test loss = 0.4593\n","Iteration 5415: train loss = 0.3782 test loss = 0.4593\n","Iteration 5416: train loss = 0.3782 test loss = 0.4592\n","Iteration 5417: train loss = 0.3782 test loss = 0.4592\n","Iteration 5418: train loss = 0.3781 test loss = 0.4592\n","Iteration 5419: train loss = 0.3781 test loss = 0.4592\n","Iteration 5420: train loss = 0.3781 test loss = 0.4591\n","Iteration 5421: train loss = 0.3780 test loss = 0.4591\n","Iteration 5422: train loss = 0.3780 test loss = 0.4591\n","Iteration 5423: train loss = 0.3780 test loss = 0.4591\n","Iteration 5424: train loss = 0.3779 test loss = 0.4590\n","Iteration 5425: train loss = 0.3779 test loss = 0.4590\n","Iteration 5426: train loss = 0.3778 test loss = 0.4590\n","Iteration 5427: train loss = 0.3778 test loss = 0.4590\n","Iteration 5428: train loss = 0.3778 test loss = 0.4589\n","Iteration 5429: train loss = 0.3777 test loss = 0.4589\n","Iteration 5430: train loss = 0.3777 test loss = 0.4589\n","Iteration 5431: train loss = 0.3777 test loss = 0.4589\n","Iteration 5432: train loss = 0.3776 test loss = 0.4588\n","Iteration 5433: train loss = 0.3776 test loss = 0.4588\n","Iteration 5434: train loss = 0.3776 test loss = 0.4588\n","Iteration 5435: train loss = 0.3775 test loss = 0.4588\n","Iteration 5436: train loss = 0.3775 test loss = 0.4587\n","Iteration 5437: train loss = 0.3774 test loss = 0.4587\n","Iteration 5438: train loss = 0.3774 test loss = 0.4587\n","Iteration 5439: train loss = 0.3774 test loss = 0.4587\n","Iteration 5440: train loss = 0.3773 test loss = 0.4586\n","Iteration 5441: train loss = 0.3773 test loss = 0.4586\n","Iteration 5442: train loss = 0.3773 test loss = 0.4586\n","Iteration 5443: train loss = 0.3772 test loss = 0.4586\n","Iteration 5444: train loss = 0.3772 test loss = 0.4585\n","Iteration 5445: train loss = 0.3772 test loss = 0.4585\n","Iteration 5446: train loss = 0.3771 test loss = 0.4585\n","Iteration 5447: train loss = 0.3771 test loss = 0.4585\n","Iteration 5448: train loss = 0.3771 test loss = 0.4584\n","Iteration 5449: train loss = 0.3770 test loss = 0.4584\n","Iteration 5450: train loss = 0.3770 test loss = 0.4584\n","Iteration 5451: train loss = 0.3769 test loss = 0.4584\n","Iteration 5452: train loss = 0.3769 test loss = 0.4583\n","Iteration 5453: train loss = 0.3769 test loss = 0.4583\n","Iteration 5454: train loss = 0.3768 test loss = 0.4583\n","Iteration 5455: train loss = 0.3768 test loss = 0.4583\n","Iteration 5456: train loss = 0.3768 test loss = 0.4582\n","Iteration 5457: train loss = 0.3767 test loss = 0.4582\n","Iteration 5458: train loss = 0.3767 test loss = 0.4582\n","Iteration 5459: train loss = 0.3767 test loss = 0.4582\n","Iteration 5460: train loss = 0.3766 test loss = 0.4581\n","Iteration 5461: train loss = 0.3766 test loss = 0.4581\n","Iteration 5462: train loss = 0.3765 test loss = 0.4581\n","Iteration 5463: train loss = 0.3765 test loss = 0.4581\n","Iteration 5464: train loss = 0.3765 test loss = 0.4580\n","Iteration 5465: train loss = 0.3764 test loss = 0.4580\n","Iteration 5466: train loss = 0.3764 test loss = 0.4580\n","Iteration 5467: train loss = 0.3764 test loss = 0.4580\n","Iteration 5468: train loss = 0.3763 test loss = 0.4579\n","Iteration 5469: train loss = 0.3763 test loss = 0.4579\n","Iteration 5470: train loss = 0.3763 test loss = 0.4579\n","Iteration 5471: train loss = 0.3762 test loss = 0.4579\n","Iteration 5472: train loss = 0.3762 test loss = 0.4578\n","Iteration 5473: train loss = 0.3762 test loss = 0.4578\n","Iteration 5474: train loss = 0.3761 test loss = 0.4578\n","Iteration 5475: train loss = 0.3761 test loss = 0.4578\n","Iteration 5476: train loss = 0.3760 test loss = 0.4577\n","Iteration 5477: train loss = 0.3760 test loss = 0.4577\n","Iteration 5478: train loss = 0.3760 test loss = 0.4577\n","Iteration 5479: train loss = 0.3759 test loss = 0.4577\n","Iteration 5480: train loss = 0.3759 test loss = 0.4576\n","Iteration 5481: train loss = 0.3759 test loss = 0.4576\n","Iteration 5482: train loss = 0.3758 test loss = 0.4576\n","Iteration 5483: train loss = 0.3758 test loss = 0.4576\n","Iteration 5484: train loss = 0.3758 test loss = 0.4575\n","Iteration 5485: train loss = 0.3757 test loss = 0.4575\n","Iteration 5486: train loss = 0.3757 test loss = 0.4575\n","Iteration 5487: train loss = 0.3756 test loss = 0.4575\n","Iteration 5488: train loss = 0.3756 test loss = 0.4574\n","Iteration 5489: train loss = 0.3756 test loss = 0.4574\n","Iteration 5490: train loss = 0.3755 test loss = 0.4574\n","Iteration 5491: train loss = 0.3755 test loss = 0.4574\n","Iteration 5492: train loss = 0.3755 test loss = 0.4573\n","Iteration 5493: train loss = 0.3754 test loss = 0.4573\n","Iteration 5494: train loss = 0.3754 test loss = 0.4573\n","Iteration 5495: train loss = 0.3754 test loss = 0.4573\n","Iteration 5496: train loss = 0.3753 test loss = 0.4572\n","Iteration 5497: train loss = 0.3753 test loss = 0.4572\n","Iteration 5498: train loss = 0.3753 test loss = 0.4572\n","Iteration 5499: train loss = 0.3752 test loss = 0.4572\n","Iteration 5500: train loss = 0.3752 test loss = 0.4571\n","Iteration 5501: train loss = 0.3751 test loss = 0.4571\n","Iteration 5502: train loss = 0.3751 test loss = 0.4571\n","Iteration 5503: train loss = 0.3751 test loss = 0.4571\n","Iteration 5504: train loss = 0.3750 test loss = 0.4570\n","Iteration 5505: train loss = 0.3750 test loss = 0.4570\n","Iteration 5506: train loss = 0.3750 test loss = 0.4570\n","Iteration 5507: train loss = 0.3749 test loss = 0.4570\n","Iteration 5508: train loss = 0.3749 test loss = 0.4569\n","Iteration 5509: train loss = 0.3749 test loss = 0.4569\n","Iteration 5510: train loss = 0.3748 test loss = 0.4569\n","Iteration 5511: train loss = 0.3748 test loss = 0.4569\n","Iteration 5512: train loss = 0.3748 test loss = 0.4568\n","Iteration 5513: train loss = 0.3747 test loss = 0.4568\n","Iteration 5514: train loss = 0.3747 test loss = 0.4568\n","Iteration 5515: train loss = 0.3746 test loss = 0.4568\n","Iteration 5516: train loss = 0.3746 test loss = 0.4567\n","Iteration 5517: train loss = 0.3746 test loss = 0.4567\n","Iteration 5518: train loss = 0.3745 test loss = 0.4567\n","Iteration 5519: train loss = 0.3745 test loss = 0.4567\n","Iteration 5520: train loss = 0.3745 test loss = 0.4566\n","Iteration 5521: train loss = 0.3744 test loss = 0.4566\n","Iteration 5522: train loss = 0.3744 test loss = 0.4566\n","Iteration 5523: train loss = 0.3744 test loss = 0.4566\n","Iteration 5524: train loss = 0.3743 test loss = 0.4565\n","Iteration 5525: train loss = 0.3743 test loss = 0.4565\n","Iteration 5526: train loss = 0.3743 test loss = 0.4565\n","Iteration 5527: train loss = 0.3742 test loss = 0.4565\n","Iteration 5528: train loss = 0.3742 test loss = 0.4564\n","Iteration 5529: train loss = 0.3741 test loss = 0.4564\n","Iteration 5530: train loss = 0.3741 test loss = 0.4564\n","Iteration 5531: train loss = 0.3741 test loss = 0.4564\n","Iteration 5532: train loss = 0.3740 test loss = 0.4563\n","Iteration 5533: train loss = 0.3740 test loss = 0.4563\n","Iteration 5534: train loss = 0.3740 test loss = 0.4563\n","Iteration 5535: train loss = 0.3739 test loss = 0.4563\n","Iteration 5536: train loss = 0.3739 test loss = 0.4562\n","Iteration 5537: train loss = 0.3739 test loss = 0.4562\n","Iteration 5538: train loss = 0.3738 test loss = 0.4562\n","Iteration 5539: train loss = 0.3738 test loss = 0.4562\n","Iteration 5540: train loss = 0.3738 test loss = 0.4561\n","Iteration 5541: train loss = 0.3737 test loss = 0.4561\n","Iteration 5542: train loss = 0.3737 test loss = 0.4561\n","Iteration 5543: train loss = 0.3736 test loss = 0.4561\n","Iteration 5544: train loss = 0.3736 test loss = 0.4560\n","Iteration 5545: train loss = 0.3736 test loss = 0.4560\n","Iteration 5546: train loss = 0.3735 test loss = 0.4560\n","Iteration 5547: train loss = 0.3735 test loss = 0.4560\n","Iteration 5548: train loss = 0.3735 test loss = 0.4559\n","Iteration 5549: train loss = 0.3734 test loss = 0.4559\n","Iteration 5550: train loss = 0.3734 test loss = 0.4559\n","Iteration 5551: train loss = 0.3734 test loss = 0.4559\n","Iteration 5552: train loss = 0.3733 test loss = 0.4558\n","Iteration 5553: train loss = 0.3733 test loss = 0.4558\n","Iteration 5554: train loss = 0.3733 test loss = 0.4558\n","Iteration 5555: train loss = 0.3732 test loss = 0.4558\n","Iteration 5556: train loss = 0.3732 test loss = 0.4557\n","Iteration 5557: train loss = 0.3732 test loss = 0.4557\n","Iteration 5558: train loss = 0.3731 test loss = 0.4557\n","Iteration 5559: train loss = 0.3731 test loss = 0.4557\n","Iteration 5560: train loss = 0.3730 test loss = 0.4556\n","Iteration 5561: train loss = 0.3730 test loss = 0.4556\n","Iteration 5562: train loss = 0.3730 test loss = 0.4556\n","Iteration 5563: train loss = 0.3729 test loss = 0.4556\n","Iteration 5564: train loss = 0.3729 test loss = 0.4555\n","Iteration 5565: train loss = 0.3729 test loss = 0.4555\n","Iteration 5566: train loss = 0.3728 test loss = 0.4555\n","Iteration 5567: train loss = 0.3728 test loss = 0.4555\n","Iteration 5568: train loss = 0.3728 test loss = 0.4554\n","Iteration 5569: train loss = 0.3727 test loss = 0.4554\n","Iteration 5570: train loss = 0.3727 test loss = 0.4554\n","Iteration 5571: train loss = 0.3727 test loss = 0.4554\n","Iteration 5572: train loss = 0.3726 test loss = 0.4553\n","Iteration 5573: train loss = 0.3726 test loss = 0.4553\n","Iteration 5574: train loss = 0.3725 test loss = 0.4553\n","Iteration 5575: train loss = 0.3725 test loss = 0.4553\n","Iteration 5576: train loss = 0.3725 test loss = 0.4552\n","Iteration 5577: train loss = 0.3724 test loss = 0.4552\n","Iteration 5578: train loss = 0.3724 test loss = 0.4552\n","Iteration 5579: train loss = 0.3724 test loss = 0.4552\n","Iteration 5580: train loss = 0.3723 test loss = 0.4551\n","Iteration 5581: train loss = 0.3723 test loss = 0.4551\n","Iteration 5582: train loss = 0.3723 test loss = 0.4551\n","Iteration 5583: train loss = 0.3722 test loss = 0.4551\n","Iteration 5584: train loss = 0.3722 test loss = 0.4550\n","Iteration 5585: train loss = 0.3722 test loss = 0.4550\n","Iteration 5586: train loss = 0.3721 test loss = 0.4550\n","Iteration 5587: train loss = 0.3721 test loss = 0.4550\n","Iteration 5588: train loss = 0.3721 test loss = 0.4550\n","Iteration 5589: train loss = 0.3720 test loss = 0.4549\n","Iteration 5590: train loss = 0.3720 test loss = 0.4549\n","Iteration 5591: train loss = 0.3719 test loss = 0.4549\n","Iteration 5592: train loss = 0.3719 test loss = 0.4549\n","Iteration 5593: train loss = 0.3719 test loss = 0.4548\n","Iteration 5594: train loss = 0.3718 test loss = 0.4548\n","Iteration 5595: train loss = 0.3718 test loss = 0.4548\n","Iteration 5596: train loss = 0.3718 test loss = 0.4548\n","Iteration 5597: train loss = 0.3717 test loss = 0.4547\n","Iteration 5598: train loss = 0.3717 test loss = 0.4547\n","Iteration 5599: train loss = 0.3717 test loss = 0.4547\n","Iteration 5600: train loss = 0.3716 test loss = 0.4547\n","Iteration 5601: train loss = 0.3716 test loss = 0.4546\n","Iteration 5602: train loss = 0.3716 test loss = 0.4546\n","Iteration 5603: train loss = 0.3715 test loss = 0.4546\n","Iteration 5604: train loss = 0.3715 test loss = 0.4546\n","Iteration 5605: train loss = 0.3715 test loss = 0.4545\n","Iteration 5606: train loss = 0.3714 test loss = 0.4545\n","Iteration 5607: train loss = 0.3714 test loss = 0.4545\n","Iteration 5608: train loss = 0.3713 test loss = 0.4545\n","Iteration 5609: train loss = 0.3713 test loss = 0.4544\n","Iteration 5610: train loss = 0.3713 test loss = 0.4544\n","Iteration 5611: train loss = 0.3712 test loss = 0.4544\n","Iteration 5612: train loss = 0.3712 test loss = 0.4544\n","Iteration 5613: train loss = 0.3712 test loss = 0.4543\n","Iteration 5614: train loss = 0.3711 test loss = 0.4543\n","Iteration 5615: train loss = 0.3711 test loss = 0.4543\n","Iteration 5616: train loss = 0.3711 test loss = 0.4543\n","Iteration 5617: train loss = 0.3710 test loss = 0.4542\n","Iteration 5618: train loss = 0.3710 test loss = 0.4542\n","Iteration 5619: train loss = 0.3710 test loss = 0.4542\n","Iteration 5620: train loss = 0.3709 test loss = 0.4542\n","Iteration 5621: train loss = 0.3709 test loss = 0.4541\n","Iteration 5622: train loss = 0.3709 test loss = 0.4541\n","Iteration 5623: train loss = 0.3708 test loss = 0.4541\n","Iteration 5624: train loss = 0.3708 test loss = 0.4541\n","Iteration 5625: train loss = 0.3707 test loss = 0.4540\n","Iteration 5626: train loss = 0.3707 test loss = 0.4540\n","Iteration 5627: train loss = 0.3707 test loss = 0.4540\n","Iteration 5628: train loss = 0.3706 test loss = 0.4540\n","Iteration 5629: train loss = 0.3706 test loss = 0.4539\n","Iteration 5630: train loss = 0.3706 test loss = 0.4539\n","Iteration 5631: train loss = 0.3705 test loss = 0.4539\n","Iteration 5632: train loss = 0.3705 test loss = 0.4539\n","Iteration 5633: train loss = 0.3705 test loss = 0.4538\n","Iteration 5634: train loss = 0.3704 test loss = 0.4538\n","Iteration 5635: train loss = 0.3704 test loss = 0.4538\n","Iteration 5636: train loss = 0.3704 test loss = 0.4538\n","Iteration 5637: train loss = 0.3703 test loss = 0.4538\n","Iteration 5638: train loss = 0.3703 test loss = 0.4537\n","Iteration 5639: train loss = 0.3703 test loss = 0.4537\n","Iteration 5640: train loss = 0.3702 test loss = 0.4537\n","Iteration 5641: train loss = 0.3702 test loss = 0.4537\n","Iteration 5642: train loss = 0.3702 test loss = 0.4536\n","Iteration 5643: train loss = 0.3701 test loss = 0.4536\n","Iteration 5644: train loss = 0.3701 test loss = 0.4536\n","Iteration 5645: train loss = 0.3700 test loss = 0.4536\n","Iteration 5646: train loss = 0.3700 test loss = 0.4535\n","Iteration 5647: train loss = 0.3700 test loss = 0.4535\n","Iteration 5648: train loss = 0.3699 test loss = 0.4535\n","Iteration 5649: train loss = 0.3699 test loss = 0.4535\n","Iteration 5650: train loss = 0.3699 test loss = 0.4534\n","Iteration 5651: train loss = 0.3698 test loss = 0.4534\n","Iteration 5652: train loss = 0.3698 test loss = 0.4534\n","Iteration 5653: train loss = 0.3698 test loss = 0.4534\n","Iteration 5654: train loss = 0.3697 test loss = 0.4533\n","Iteration 5655: train loss = 0.3697 test loss = 0.4533\n","Iteration 5656: train loss = 0.3697 test loss = 0.4533\n","Iteration 5657: train loss = 0.3696 test loss = 0.4533\n","Iteration 5658: train loss = 0.3696 test loss = 0.4532\n","Iteration 5659: train loss = 0.3696 test loss = 0.4532\n","Iteration 5660: train loss = 0.3695 test loss = 0.4532\n","Iteration 5661: train loss = 0.3695 test loss = 0.4532\n","Iteration 5662: train loss = 0.3694 test loss = 0.4531\n","Iteration 5663: train loss = 0.3694 test loss = 0.4531\n","Iteration 5664: train loss = 0.3694 test loss = 0.4531\n","Iteration 5665: train loss = 0.3693 test loss = 0.4531\n","Iteration 5666: train loss = 0.3693 test loss = 0.4530\n","Iteration 5667: train loss = 0.3693 test loss = 0.4530\n","Iteration 5668: train loss = 0.3692 test loss = 0.4530\n","Iteration 5669: train loss = 0.3692 test loss = 0.4530\n","Iteration 5670: train loss = 0.3692 test loss = 0.4529\n","Iteration 5671: train loss = 0.3691 test loss = 0.4529\n","Iteration 5672: train loss = 0.3691 test loss = 0.4529\n","Iteration 5673: train loss = 0.3691 test loss = 0.4529\n","Iteration 5674: train loss = 0.3690 test loss = 0.4529\n","Iteration 5675: train loss = 0.3690 test loss = 0.4528\n","Iteration 5676: train loss = 0.3690 test loss = 0.4528\n","Iteration 5677: train loss = 0.3689 test loss = 0.4528\n","Iteration 5678: train loss = 0.3689 test loss = 0.4528\n","Iteration 5679: train loss = 0.3689 test loss = 0.4527\n","Iteration 5680: train loss = 0.3688 test loss = 0.4527\n","Iteration 5681: train loss = 0.3688 test loss = 0.4527\n","Iteration 5682: train loss = 0.3688 test loss = 0.4527\n","Iteration 5683: train loss = 0.3687 test loss = 0.4526\n","Iteration 5684: train loss = 0.3687 test loss = 0.4526\n","Iteration 5685: train loss = 0.3686 test loss = 0.4526\n","Iteration 5686: train loss = 0.3686 test loss = 0.4526\n","Iteration 5687: train loss = 0.3686 test loss = 0.4525\n","Iteration 5688: train loss = 0.3685 test loss = 0.4525\n","Iteration 5689: train loss = 0.3685 test loss = 0.4525\n","Iteration 5690: train loss = 0.3685 test loss = 0.4525\n","Iteration 5691: train loss = 0.3684 test loss = 0.4524\n","Iteration 5692: train loss = 0.3684 test loss = 0.4524\n","Iteration 5693: train loss = 0.3684 test loss = 0.4524\n","Iteration 5694: train loss = 0.3683 test loss = 0.4524\n","Iteration 5695: train loss = 0.3683 test loss = 0.4523\n","Iteration 5696: train loss = 0.3683 test loss = 0.4523\n","Iteration 5697: train loss = 0.3682 test loss = 0.4523\n","Iteration 5698: train loss = 0.3682 test loss = 0.4523\n","Iteration 5699: train loss = 0.3682 test loss = 0.4522\n","Iteration 5700: train loss = 0.3681 test loss = 0.4522\n","Iteration 5701: train loss = 0.3681 test loss = 0.4522\n","Iteration 5702: train loss = 0.3681 test loss = 0.4522\n","Iteration 5703: train loss = 0.3680 test loss = 0.4521\n","Iteration 5704: train loss = 0.3680 test loss = 0.4521\n","Iteration 5705: train loss = 0.3679 test loss = 0.4521\n","Iteration 5706: train loss = 0.3679 test loss = 0.4521\n","Iteration 5707: train loss = 0.3679 test loss = 0.4521\n","Iteration 5708: train loss = 0.3678 test loss = 0.4520\n","Iteration 5709: train loss = 0.3678 test loss = 0.4520\n","Iteration 5710: train loss = 0.3678 test loss = 0.4520\n","Iteration 5711: train loss = 0.3677 test loss = 0.4520\n","Iteration 5712: train loss = 0.3677 test loss = 0.4519\n","Iteration 5713: train loss = 0.3677 test loss = 0.4519\n","Iteration 5714: train loss = 0.3676 test loss = 0.4519\n","Iteration 5715: train loss = 0.3676 test loss = 0.4519\n","Iteration 5716: train loss = 0.3676 test loss = 0.4518\n","Iteration 5717: train loss = 0.3675 test loss = 0.4518\n","Iteration 5718: train loss = 0.3675 test loss = 0.4518\n","Iteration 5719: train loss = 0.3675 test loss = 0.4518\n","Iteration 5720: train loss = 0.3674 test loss = 0.4517\n","Iteration 5721: train loss = 0.3674 test loss = 0.4517\n","Iteration 5722: train loss = 0.3674 test loss = 0.4517\n","Iteration 5723: train loss = 0.3673 test loss = 0.4517\n","Iteration 5724: train loss = 0.3673 test loss = 0.4516\n","Iteration 5725: train loss = 0.3673 test loss = 0.4516\n","Iteration 5726: train loss = 0.3672 test loss = 0.4516\n","Iteration 5727: train loss = 0.3672 test loss = 0.4516\n","Iteration 5728: train loss = 0.3671 test loss = 0.4515\n","Iteration 5729: train loss = 0.3671 test loss = 0.4515\n","Iteration 5730: train loss = 0.3671 test loss = 0.4515\n","Iteration 5731: train loss = 0.3670 test loss = 0.4515\n","Iteration 5732: train loss = 0.3670 test loss = 0.4514\n","Iteration 5733: train loss = 0.3670 test loss = 0.4514\n","Iteration 5734: train loss = 0.3669 test loss = 0.4514\n","Iteration 5735: train loss = 0.3669 test loss = 0.4514\n","Iteration 5736: train loss = 0.3669 test loss = 0.4514\n","Iteration 5737: train loss = 0.3668 test loss = 0.4513\n","Iteration 5738: train loss = 0.3668 test loss = 0.4513\n","Iteration 5739: train loss = 0.3668 test loss = 0.4513\n","Iteration 5740: train loss = 0.3667 test loss = 0.4513\n","Iteration 5741: train loss = 0.3667 test loss = 0.4512\n","Iteration 5742: train loss = 0.3667 test loss = 0.4512\n","Iteration 5743: train loss = 0.3666 test loss = 0.4512\n","Iteration 5744: train loss = 0.3666 test loss = 0.4512\n","Iteration 5745: train loss = 0.3666 test loss = 0.4511\n","Iteration 5746: train loss = 0.3665 test loss = 0.4511\n","Iteration 5747: train loss = 0.3665 test loss = 0.4511\n","Iteration 5748: train loss = 0.3665 test loss = 0.4511\n","Iteration 5749: train loss = 0.3664 test loss = 0.4510\n","Iteration 5750: train loss = 0.3664 test loss = 0.4510\n","Iteration 5751: train loss = 0.3664 test loss = 0.4510\n","Iteration 5752: train loss = 0.3663 test loss = 0.4510\n","Iteration 5753: train loss = 0.3663 test loss = 0.4509\n","Iteration 5754: train loss = 0.3662 test loss = 0.4509\n","Iteration 5755: train loss = 0.3662 test loss = 0.4509\n","Iteration 5756: train loss = 0.3662 test loss = 0.4509\n","Iteration 5757: train loss = 0.3661 test loss = 0.4509\n","Iteration 5758: train loss = 0.3661 test loss = 0.4508\n","Iteration 5759: train loss = 0.3661 test loss = 0.4508\n","Iteration 5760: train loss = 0.3660 test loss = 0.4508\n","Iteration 5761: train loss = 0.3660 test loss = 0.4508\n","Iteration 5762: train loss = 0.3660 test loss = 0.4507\n","Iteration 5763: train loss = 0.3659 test loss = 0.4507\n","Iteration 5764: train loss = 0.3659 test loss = 0.4507\n","Iteration 5765: train loss = 0.3659 test loss = 0.4507\n","Iteration 5766: train loss = 0.3658 test loss = 0.4506\n","Iteration 5767: train loss = 0.3658 test loss = 0.4506\n","Iteration 5768: train loss = 0.3658 test loss = 0.4506\n","Iteration 5769: train loss = 0.3657 test loss = 0.4506\n","Iteration 5770: train loss = 0.3657 test loss = 0.4505\n","Iteration 5771: train loss = 0.3657 test loss = 0.4505\n","Iteration 5772: train loss = 0.3656 test loss = 0.4505\n","Iteration 5773: train loss = 0.3656 test loss = 0.4505\n","Iteration 5774: train loss = 0.3656 test loss = 0.4504\n","Iteration 5775: train loss = 0.3655 test loss = 0.4504\n","Iteration 5776: train loss = 0.3655 test loss = 0.4504\n","Iteration 5777: train loss = 0.3655 test loss = 0.4504\n","Iteration 5778: train loss = 0.3654 test loss = 0.4503\n","Iteration 5779: train loss = 0.3654 test loss = 0.4503\n","Iteration 5780: train loss = 0.3654 test loss = 0.4503\n","Iteration 5781: train loss = 0.3653 test loss = 0.4503\n","Iteration 5782: train loss = 0.3653 test loss = 0.4503\n","Iteration 5783: train loss = 0.3652 test loss = 0.4502\n","Iteration 5784: train loss = 0.3652 test loss = 0.4502\n","Iteration 5785: train loss = 0.3652 test loss = 0.4502\n","Iteration 5786: train loss = 0.3651 test loss = 0.4502\n","Iteration 5787: train loss = 0.3651 test loss = 0.4501\n","Iteration 5788: train loss = 0.3651 test loss = 0.4501\n","Iteration 5789: train loss = 0.3650 test loss = 0.4501\n","Iteration 5790: train loss = 0.3650 test loss = 0.4501\n","Iteration 5791: train loss = 0.3650 test loss = 0.4500\n","Iteration 5792: train loss = 0.3649 test loss = 0.4500\n","Iteration 5793: train loss = 0.3649 test loss = 0.4500\n","Iteration 5794: train loss = 0.3649 test loss = 0.4500\n","Iteration 5795: train loss = 0.3648 test loss = 0.4499\n","Iteration 5796: train loss = 0.3648 test loss = 0.4499\n","Iteration 5797: train loss = 0.3648 test loss = 0.4499\n","Iteration 5798: train loss = 0.3647 test loss = 0.4499\n","Iteration 5799: train loss = 0.3647 test loss = 0.4498\n","Iteration 5800: train loss = 0.3647 test loss = 0.4498\n","Iteration 5801: train loss = 0.3646 test loss = 0.4498\n","Iteration 5802: train loss = 0.3646 test loss = 0.4498\n","Iteration 5803: train loss = 0.3646 test loss = 0.4498\n","Iteration 5804: train loss = 0.3645 test loss = 0.4497\n","Iteration 5805: train loss = 0.3645 test loss = 0.4497\n","Iteration 5806: train loss = 0.3645 test loss = 0.4497\n","Iteration 5807: train loss = 0.3644 test loss = 0.4497\n","Iteration 5808: train loss = 0.3644 test loss = 0.4496\n","Iteration 5809: train loss = 0.3644 test loss = 0.4496\n","Iteration 5810: train loss = 0.3643 test loss = 0.4496\n","Iteration 5811: train loss = 0.3643 test loss = 0.4496\n","Iteration 5812: train loss = 0.3643 test loss = 0.4495\n","Iteration 5813: train loss = 0.3642 test loss = 0.4495\n","Iteration 5814: train loss = 0.3642 test loss = 0.4495\n","Iteration 5815: train loss = 0.3641 test loss = 0.4495\n","Iteration 5816: train loss = 0.3641 test loss = 0.4494\n","Iteration 5817: train loss = 0.3641 test loss = 0.4494\n","Iteration 5818: train loss = 0.3640 test loss = 0.4494\n","Iteration 5819: train loss = 0.3640 test loss = 0.4494\n","Iteration 5820: train loss = 0.3640 test loss = 0.4494\n","Iteration 5821: train loss = 0.3639 test loss = 0.4493\n","Iteration 5822: train loss = 0.3639 test loss = 0.4493\n","Iteration 5823: train loss = 0.3639 test loss = 0.4493\n","Iteration 5824: train loss = 0.3638 test loss = 0.4493\n","Iteration 5825: train loss = 0.3638 test loss = 0.4492\n","Iteration 5826: train loss = 0.3638 test loss = 0.4492\n","Iteration 5827: train loss = 0.3637 test loss = 0.4492\n","Iteration 5828: train loss = 0.3637 test loss = 0.4492\n","Iteration 5829: train loss = 0.3637 test loss = 0.4491\n","Iteration 5830: train loss = 0.3636 test loss = 0.4491\n","Iteration 5831: train loss = 0.3636 test loss = 0.4491\n","Iteration 5832: train loss = 0.3636 test loss = 0.4491\n","Iteration 5833: train loss = 0.3635 test loss = 0.4490\n","Iteration 5834: train loss = 0.3635 test loss = 0.4490\n","Iteration 5835: train loss = 0.3635 test loss = 0.4490\n","Iteration 5836: train loss = 0.3634 test loss = 0.4490\n","Iteration 5837: train loss = 0.3634 test loss = 0.4489\n","Iteration 5838: train loss = 0.3634 test loss = 0.4489\n","Iteration 5839: train loss = 0.3633 test loss = 0.4489\n","Iteration 5840: train loss = 0.3633 test loss = 0.4489\n","Iteration 5841: train loss = 0.3633 test loss = 0.4489\n","Iteration 5842: train loss = 0.3632 test loss = 0.4488\n","Iteration 5843: train loss = 0.3632 test loss = 0.4488\n","Iteration 5844: train loss = 0.3632 test loss = 0.4488\n","Iteration 5845: train loss = 0.3631 test loss = 0.4488\n","Iteration 5846: train loss = 0.3631 test loss = 0.4487\n","Iteration 5847: train loss = 0.3631 test loss = 0.4487\n","Iteration 5848: train loss = 0.3630 test loss = 0.4487\n","Iteration 5849: train loss = 0.3630 test loss = 0.4487\n","Iteration 5850: train loss = 0.3630 test loss = 0.4486\n","Iteration 5851: train loss = 0.3629 test loss = 0.4486\n","Iteration 5852: train loss = 0.3629 test loss = 0.4486\n","Iteration 5853: train loss = 0.3628 test loss = 0.4486\n","Iteration 5854: train loss = 0.3628 test loss = 0.4485\n","Iteration 5855: train loss = 0.3628 test loss = 0.4485\n","Iteration 5856: train loss = 0.3627 test loss = 0.4485\n","Iteration 5857: train loss = 0.3627 test loss = 0.4485\n","Iteration 5858: train loss = 0.3627 test loss = 0.4485\n","Iteration 5859: train loss = 0.3626 test loss = 0.4484\n","Iteration 5860: train loss = 0.3626 test loss = 0.4484\n","Iteration 5861: train loss = 0.3626 test loss = 0.4484\n","Iteration 5862: train loss = 0.3625 test loss = 0.4484\n","Iteration 5863: train loss = 0.3625 test loss = 0.4483\n","Iteration 5864: train loss = 0.3625 test loss = 0.4483\n","Iteration 5865: train loss = 0.3624 test loss = 0.4483\n","Iteration 5866: train loss = 0.3624 test loss = 0.4483\n","Iteration 5867: train loss = 0.3624 test loss = 0.4482\n","Iteration 5868: train loss = 0.3623 test loss = 0.4482\n","Iteration 5869: train loss = 0.3623 test loss = 0.4482\n","Iteration 5870: train loss = 0.3623 test loss = 0.4482\n","Iteration 5871: train loss = 0.3622 test loss = 0.4481\n","Iteration 5872: train loss = 0.3622 test loss = 0.4481\n","Iteration 5873: train loss = 0.3622 test loss = 0.4481\n","Iteration 5874: train loss = 0.3621 test loss = 0.4481\n","Iteration 5875: train loss = 0.3621 test loss = 0.4481\n","Iteration 5876: train loss = 0.3621 test loss = 0.4480\n","Iteration 5877: train loss = 0.3620 test loss = 0.4480\n","Iteration 5878: train loss = 0.3620 test loss = 0.4480\n","Iteration 5879: train loss = 0.3620 test loss = 0.4480\n","Iteration 5880: train loss = 0.3619 test loss = 0.4479\n","Iteration 5881: train loss = 0.3619 test loss = 0.4479\n","Iteration 5882: train loss = 0.3619 test loss = 0.4479\n","Iteration 5883: train loss = 0.3618 test loss = 0.4479\n","Iteration 5884: train loss = 0.3618 test loss = 0.4478\n","Iteration 5885: train loss = 0.3618 test loss = 0.4478\n","Iteration 5886: train loss = 0.3617 test loss = 0.4478\n","Iteration 5887: train loss = 0.3617 test loss = 0.4478\n","Iteration 5888: train loss = 0.3617 test loss = 0.4477\n","Iteration 5889: train loss = 0.3616 test loss = 0.4477\n","Iteration 5890: train loss = 0.3616 test loss = 0.4477\n","Iteration 5891: train loss = 0.3616 test loss = 0.4477\n","Iteration 5892: train loss = 0.3615 test loss = 0.4477\n","Iteration 5893: train loss = 0.3615 test loss = 0.4476\n","Iteration 5894: train loss = 0.3615 test loss = 0.4476\n","Iteration 5895: train loss = 0.3614 test loss = 0.4476\n","Iteration 5896: train loss = 0.3614 test loss = 0.4476\n","Iteration 5897: train loss = 0.3614 test loss = 0.4475\n","Iteration 5898: train loss = 0.3613 test loss = 0.4475\n","Iteration 5899: train loss = 0.3613 test loss = 0.4475\n","Iteration 5900: train loss = 0.3613 test loss = 0.4475\n","Iteration 5901: train loss = 0.3612 test loss = 0.4474\n","Iteration 5902: train loss = 0.3612 test loss = 0.4474\n","Iteration 5903: train loss = 0.3611 test loss = 0.4474\n","Iteration 5904: train loss = 0.3611 test loss = 0.4474\n","Iteration 5905: train loss = 0.3611 test loss = 0.4474\n","Iteration 5906: train loss = 0.3610 test loss = 0.4473\n","Iteration 5907: train loss = 0.3610 test loss = 0.4473\n","Iteration 5908: train loss = 0.3610 test loss = 0.4473\n","Iteration 5909: train loss = 0.3609 test loss = 0.4473\n","Iteration 5910: train loss = 0.3609 test loss = 0.4472\n","Iteration 5911: train loss = 0.3609 test loss = 0.4472\n","Iteration 5912: train loss = 0.3608 test loss = 0.4472\n","Iteration 5913: train loss = 0.3608 test loss = 0.4472\n","Iteration 5914: train loss = 0.3608 test loss = 0.4471\n","Iteration 5915: train loss = 0.3607 test loss = 0.4471\n","Iteration 5916: train loss = 0.3607 test loss = 0.4471\n","Iteration 5917: train loss = 0.3607 test loss = 0.4471\n","Iteration 5918: train loss = 0.3606 test loss = 0.4470\n","Iteration 5919: train loss = 0.3606 test loss = 0.4470\n","Iteration 5920: train loss = 0.3606 test loss = 0.4470\n","Iteration 5921: train loss = 0.3605 test loss = 0.4470\n","Iteration 5922: train loss = 0.3605 test loss = 0.4470\n","Iteration 5923: train loss = 0.3605 test loss = 0.4469\n","Iteration 5924: train loss = 0.3604 test loss = 0.4469\n","Iteration 5925: train loss = 0.3604 test loss = 0.4469\n","Iteration 5926: train loss = 0.3604 test loss = 0.4469\n","Iteration 5927: train loss = 0.3603 test loss = 0.4468\n","Iteration 5928: train loss = 0.3603 test loss = 0.4468\n","Iteration 5929: train loss = 0.3603 test loss = 0.4468\n","Iteration 5930: train loss = 0.3602 test loss = 0.4468\n","Iteration 5931: train loss = 0.3602 test loss = 0.4467\n","Iteration 5932: train loss = 0.3602 test loss = 0.4467\n","Iteration 5933: train loss = 0.3601 test loss = 0.4467\n","Iteration 5934: train loss = 0.3601 test loss = 0.4467\n","Iteration 5935: train loss = 0.3601 test loss = 0.4467\n","Iteration 5936: train loss = 0.3600 test loss = 0.4466\n","Iteration 5937: train loss = 0.3600 test loss = 0.4466\n","Iteration 5938: train loss = 0.3600 test loss = 0.4466\n","Iteration 5939: train loss = 0.3599 test loss = 0.4466\n","Iteration 5940: train loss = 0.3599 test loss = 0.4465\n","Iteration 5941: train loss = 0.3599 test loss = 0.4465\n","Iteration 5942: train loss = 0.3598 test loss = 0.4465\n","Iteration 5943: train loss = 0.3598 test loss = 0.4465\n","Iteration 5944: train loss = 0.3598 test loss = 0.4464\n","Iteration 5945: train loss = 0.3597 test loss = 0.4464\n","Iteration 5946: train loss = 0.3597 test loss = 0.4464\n","Iteration 5947: train loss = 0.3597 test loss = 0.4464\n","Iteration 5948: train loss = 0.3596 test loss = 0.4463\n","Iteration 5949: train loss = 0.3596 test loss = 0.4463\n","Iteration 5950: train loss = 0.3596 test loss = 0.4463\n","Iteration 5951: train loss = 0.3595 test loss = 0.4463\n","Iteration 5952: train loss = 0.3595 test loss = 0.4463\n","Iteration 5953: train loss = 0.3595 test loss = 0.4462\n","Iteration 5954: train loss = 0.3594 test loss = 0.4462\n","Iteration 5955: train loss = 0.3594 test loss = 0.4462\n","Iteration 5956: train loss = 0.3594 test loss = 0.4462\n","Iteration 5957: train loss = 0.3593 test loss = 0.4461\n","Iteration 5958: train loss = 0.3593 test loss = 0.4461\n","Iteration 5959: train loss = 0.3593 test loss = 0.4461\n","Iteration 5960: train loss = 0.3592 test loss = 0.4461\n","Iteration 5961: train loss = 0.3592 test loss = 0.4460\n","Iteration 5962: train loss = 0.3592 test loss = 0.4460\n","Iteration 5963: train loss = 0.3591 test loss = 0.4460\n","Iteration 5964: train loss = 0.3591 test loss = 0.4460\n","Iteration 5965: train loss = 0.3591 test loss = 0.4460\n","Iteration 5966: train loss = 0.3590 test loss = 0.4459\n","Iteration 5967: train loss = 0.3590 test loss = 0.4459\n","Iteration 5968: train loss = 0.3590 test loss = 0.4459\n","Iteration 5969: train loss = 0.3589 test loss = 0.4459\n","Iteration 5970: train loss = 0.3589 test loss = 0.4458\n","Iteration 5971: train loss = 0.3589 test loss = 0.4458\n","Iteration 5972: train loss = 0.3588 test loss = 0.4458\n","Iteration 5973: train loss = 0.3588 test loss = 0.4458\n","Iteration 5974: train loss = 0.3588 test loss = 0.4457\n","Iteration 5975: train loss = 0.3587 test loss = 0.4457\n","Iteration 5976: train loss = 0.3587 test loss = 0.4457\n","Iteration 5977: train loss = 0.3587 test loss = 0.4457\n","Iteration 5978: train loss = 0.3586 test loss = 0.4457\n","Iteration 5979: train loss = 0.3586 test loss = 0.4456\n","Iteration 5980: train loss = 0.3586 test loss = 0.4456\n","Iteration 5981: train loss = 0.3585 test loss = 0.4456\n","Iteration 5982: train loss = 0.3585 test loss = 0.4456\n","Iteration 5983: train loss = 0.3585 test loss = 0.4455\n","Iteration 5984: train loss = 0.3584 test loss = 0.4455\n","Iteration 5985: train loss = 0.3584 test loss = 0.4455\n","Iteration 5986: train loss = 0.3584 test loss = 0.4455\n","Iteration 5987: train loss = 0.3583 test loss = 0.4454\n","Iteration 5988: train loss = 0.3583 test loss = 0.4454\n","Iteration 5989: train loss = 0.3583 test loss = 0.4454\n","Iteration 5990: train loss = 0.3582 test loss = 0.4454\n","Iteration 5991: train loss = 0.3582 test loss = 0.4454\n","Iteration 5992: train loss = 0.3582 test loss = 0.4453\n","Iteration 5993: train loss = 0.3581 test loss = 0.4453\n","Iteration 5994: train loss = 0.3581 test loss = 0.4453\n","Iteration 5995: train loss = 0.3581 test loss = 0.4453\n","Iteration 5996: train loss = 0.3580 test loss = 0.4452\n","Iteration 5997: train loss = 0.3580 test loss = 0.4452\n","Iteration 5998: train loss = 0.3580 test loss = 0.4452\n","Iteration 5999: train loss = 0.3579 test loss = 0.4452\n","Iteration 6000: train loss = 0.3579 test loss = 0.4451\n","Iteration 6001: train loss = 0.3579 test loss = 0.4451\n","Iteration 6002: train loss = 0.3578 test loss = 0.4451\n","Iteration 6003: train loss = 0.3578 test loss = 0.4451\n","Iteration 6004: train loss = 0.3578 test loss = 0.4451\n","Iteration 6005: train loss = 0.3577 test loss = 0.4450\n","Iteration 6006: train loss = 0.3577 test loss = 0.4450\n","Iteration 6007: train loss = 0.3576 test loss = 0.4450\n","Iteration 6008: train loss = 0.3576 test loss = 0.4450\n","Iteration 6009: train loss = 0.3576 test loss = 0.4449\n","Iteration 6010: train loss = 0.3575 test loss = 0.4449\n","Iteration 6011: train loss = 0.3575 test loss = 0.4449\n","Iteration 6012: train loss = 0.3575 test loss = 0.4449\n","Iteration 6013: train loss = 0.3574 test loss = 0.4448\n","Iteration 6014: train loss = 0.3574 test loss = 0.4448\n","Iteration 6015: train loss = 0.3574 test loss = 0.4448\n","Iteration 6016: train loss = 0.3573 test loss = 0.4448\n","Iteration 6017: train loss = 0.3573 test loss = 0.4448\n","Iteration 6018: train loss = 0.3573 test loss = 0.4447\n","Iteration 6019: train loss = 0.3572 test loss = 0.4447\n","Iteration 6020: train loss = 0.3572 test loss = 0.4447\n","Iteration 6021: train loss = 0.3572 test loss = 0.4447\n","Iteration 6022: train loss = 0.3571 test loss = 0.4446\n","Iteration 6023: train loss = 0.3571 test loss = 0.4446\n","Iteration 6024: train loss = 0.3571 test loss = 0.4446\n","Iteration 6025: train loss = 0.3570 test loss = 0.4446\n","Iteration 6026: train loss = 0.3570 test loss = 0.4445\n","Iteration 6027: train loss = 0.3570 test loss = 0.4445\n","Iteration 6028: train loss = 0.3569 test loss = 0.4445\n","Iteration 6029: train loss = 0.3569 test loss = 0.4445\n","Iteration 6030: train loss = 0.3569 test loss = 0.4445\n","Iteration 6031: train loss = 0.3568 test loss = 0.4444\n","Iteration 6032: train loss = 0.3568 test loss = 0.4444\n","Iteration 6033: train loss = 0.3568 test loss = 0.4444\n","Iteration 6034: train loss = 0.3567 test loss = 0.4444\n","Iteration 6035: train loss = 0.3567 test loss = 0.4443\n","Iteration 6036: train loss = 0.3567 test loss = 0.4443\n","Iteration 6037: train loss = 0.3566 test loss = 0.4443\n","Iteration 6038: train loss = 0.3566 test loss = 0.4443\n","Iteration 6039: train loss = 0.3566 test loss = 0.4443\n","Iteration 6040: train loss = 0.3565 test loss = 0.4442\n","Iteration 6041: train loss = 0.3565 test loss = 0.4442\n","Iteration 6042: train loss = 0.3565 test loss = 0.4442\n","Iteration 6043: train loss = 0.3564 test loss = 0.4442\n","Iteration 6044: train loss = 0.3564 test loss = 0.4441\n","Iteration 6045: train loss = 0.3564 test loss = 0.4441\n","Iteration 6046: train loss = 0.3564 test loss = 0.4441\n","Iteration 6047: train loss = 0.3563 test loss = 0.4441\n","Iteration 6048: train loss = 0.3563 test loss = 0.4440\n","Iteration 6049: train loss = 0.3563 test loss = 0.4440\n","Iteration 6050: train loss = 0.3562 test loss = 0.4440\n","Iteration 6051: train loss = 0.3562 test loss = 0.4440\n","Iteration 6052: train loss = 0.3562 test loss = 0.4440\n","Iteration 6053: train loss = 0.3561 test loss = 0.4439\n","Iteration 6054: train loss = 0.3561 test loss = 0.4439\n","Iteration 6055: train loss = 0.3561 test loss = 0.4439\n","Iteration 6056: train loss = 0.3560 test loss = 0.4439\n","Iteration 6057: train loss = 0.3560 test loss = 0.4438\n","Iteration 6058: train loss = 0.3560 test loss = 0.4438\n","Iteration 6059: train loss = 0.3559 test loss = 0.4438\n","Iteration 6060: train loss = 0.3559 test loss = 0.4438\n","Iteration 6061: train loss = 0.3559 test loss = 0.4437\n","Iteration 6062: train loss = 0.3558 test loss = 0.4437\n","Iteration 6063: train loss = 0.3558 test loss = 0.4437\n","Iteration 6064: train loss = 0.3558 test loss = 0.4437\n","Iteration 6065: train loss = 0.3557 test loss = 0.4437\n","Iteration 6066: train loss = 0.3557 test loss = 0.4436\n","Iteration 6067: train loss = 0.3557 test loss = 0.4436\n","Iteration 6068: train loss = 0.3556 test loss = 0.4436\n","Iteration 6069: train loss = 0.3556 test loss = 0.4436\n","Iteration 6070: train loss = 0.3556 test loss = 0.4435\n","Iteration 6071: train loss = 0.3555 test loss = 0.4435\n","Iteration 6072: train loss = 0.3555 test loss = 0.4435\n","Iteration 6073: train loss = 0.3555 test loss = 0.4435\n","Iteration 6074: train loss = 0.3554 test loss = 0.4435\n","Iteration 6075: train loss = 0.3554 test loss = 0.4434\n","Iteration 6076: train loss = 0.3554 test loss = 0.4434\n","Iteration 6077: train loss = 0.3553 test loss = 0.4434\n","Iteration 6078: train loss = 0.3553 test loss = 0.4434\n","Iteration 6079: train loss = 0.3553 test loss = 0.4433\n","Iteration 6080: train loss = 0.3552 test loss = 0.4433\n","Iteration 6081: train loss = 0.3552 test loss = 0.4433\n","Iteration 6082: train loss = 0.3552 test loss = 0.4433\n","Iteration 6083: train loss = 0.3551 test loss = 0.4432\n","Iteration 6084: train loss = 0.3551 test loss = 0.4432\n","Iteration 6085: train loss = 0.3551 test loss = 0.4432\n","Iteration 6086: train loss = 0.3550 test loss = 0.4432\n","Iteration 6087: train loss = 0.3550 test loss = 0.4432\n","Iteration 6088: train loss = 0.3550 test loss = 0.4431\n","Iteration 6089: train loss = 0.3549 test loss = 0.4431\n","Iteration 6090: train loss = 0.3549 test loss = 0.4431\n","Iteration 6091: train loss = 0.3549 test loss = 0.4431\n","Iteration 6092: train loss = 0.3548 test loss = 0.4430\n","Iteration 6093: train loss = 0.3548 test loss = 0.4430\n","Iteration 6094: train loss = 0.3548 test loss = 0.4430\n","Iteration 6095: train loss = 0.3547 test loss = 0.4430\n","Iteration 6096: train loss = 0.3547 test loss = 0.4430\n","Iteration 6097: train loss = 0.3547 test loss = 0.4429\n","Iteration 6098: train loss = 0.3546 test loss = 0.4429\n","Iteration 6099: train loss = 0.3546 test loss = 0.4429\n","Iteration 6100: train loss = 0.3546 test loss = 0.4429\n","Iteration 6101: train loss = 0.3545 test loss = 0.4428\n","Iteration 6102: train loss = 0.3545 test loss = 0.4428\n","Iteration 6103: train loss = 0.3545 test loss = 0.4428\n","Iteration 6104: train loss = 0.3544 test loss = 0.4428\n","Iteration 6105: train loss = 0.3544 test loss = 0.4428\n","Iteration 6106: train loss = 0.3544 test loss = 0.4427\n","Iteration 6107: train loss = 0.3543 test loss = 0.4427\n","Iteration 6108: train loss = 0.3543 test loss = 0.4427\n","Iteration 6109: train loss = 0.3543 test loss = 0.4427\n","Iteration 6110: train loss = 0.3542 test loss = 0.4426\n","Iteration 6111: train loss = 0.3542 test loss = 0.4426\n","Iteration 6112: train loss = 0.3542 test loss = 0.4426\n","Iteration 6113: train loss = 0.3541 test loss = 0.4426\n","Iteration 6114: train loss = 0.3541 test loss = 0.4425\n","Iteration 6115: train loss = 0.3541 test loss = 0.4425\n","Iteration 6116: train loss = 0.3540 test loss = 0.4425\n","Iteration 6117: train loss = 0.3540 test loss = 0.4425\n","Iteration 6118: train loss = 0.3540 test loss = 0.4425\n","Iteration 6119: train loss = 0.3539 test loss = 0.4424\n","Iteration 6120: train loss = 0.3539 test loss = 0.4424\n","Iteration 6121: train loss = 0.3539 test loss = 0.4424\n","Iteration 6122: train loss = 0.3538 test loss = 0.4424\n","Iteration 6123: train loss = 0.3538 test loss = 0.4423\n","Iteration 6124: train loss = 0.3538 test loss = 0.4423\n","Iteration 6125: train loss = 0.3537 test loss = 0.4423\n","Iteration 6126: train loss = 0.3537 test loss = 0.4423\n","Iteration 6127: train loss = 0.3537 test loss = 0.4423\n","Iteration 6128: train loss = 0.3536 test loss = 0.4422\n","Iteration 6129: train loss = 0.3536 test loss = 0.4422\n","Iteration 6130: train loss = 0.3536 test loss = 0.4422\n","Iteration 6131: train loss = 0.3535 test loss = 0.4422\n","Iteration 6132: train loss = 0.3535 test loss = 0.4421\n","Iteration 6133: train loss = 0.3535 test loss = 0.4421\n","Iteration 6134: train loss = 0.3534 test loss = 0.4421\n","Iteration 6135: train loss = 0.3534 test loss = 0.4421\n","Iteration 6136: train loss = 0.3534 test loss = 0.4421\n","Iteration 6137: train loss = 0.3533 test loss = 0.4420\n","Iteration 6138: train loss = 0.3533 test loss = 0.4420\n","Iteration 6139: train loss = 0.3533 test loss = 0.4420\n","Iteration 6140: train loss = 0.3532 test loss = 0.4420\n","Iteration 6141: train loss = 0.3532 test loss = 0.4419\n","Iteration 6142: train loss = 0.3532 test loss = 0.4419\n","Iteration 6143: train loss = 0.3531 test loss = 0.4419\n","Iteration 6144: train loss = 0.3531 test loss = 0.4419\n","Iteration 6145: train loss = 0.3531 test loss = 0.4418\n","Iteration 6146: train loss = 0.3530 test loss = 0.4418\n","Iteration 6147: train loss = 0.3530 test loss = 0.4418\n","Iteration 6148: train loss = 0.3530 test loss = 0.4418\n","Iteration 6149: train loss = 0.3529 test loss = 0.4418\n","Iteration 6150: train loss = 0.3529 test loss = 0.4417\n","Iteration 6151: train loss = 0.3529 test loss = 0.4417\n","Iteration 6152: train loss = 0.3529 test loss = 0.4417\n","Iteration 6153: train loss = 0.3528 test loss = 0.4417\n","Iteration 6154: train loss = 0.3528 test loss = 0.4416\n","Iteration 6155: train loss = 0.3528 test loss = 0.4416\n","Iteration 6156: train loss = 0.3527 test loss = 0.4416\n","Iteration 6157: train loss = 0.3527 test loss = 0.4416\n","Iteration 6158: train loss = 0.3527 test loss = 0.4416\n","Iteration 6159: train loss = 0.3526 test loss = 0.4415\n","Iteration 6160: train loss = 0.3526 test loss = 0.4415\n","Iteration 6161: train loss = 0.3526 test loss = 0.4415\n","Iteration 6162: train loss = 0.3525 test loss = 0.4415\n","Iteration 6163: train loss = 0.3525 test loss = 0.4414\n","Iteration 6164: train loss = 0.3525 test loss = 0.4414\n","Iteration 6165: train loss = 0.3524 test loss = 0.4414\n","Iteration 6166: train loss = 0.3524 test loss = 0.4414\n","Iteration 6167: train loss = 0.3524 test loss = 0.4414\n","Iteration 6168: train loss = 0.3523 test loss = 0.4413\n","Iteration 6169: train loss = 0.3523 test loss = 0.4413\n","Iteration 6170: train loss = 0.3523 test loss = 0.4413\n","Iteration 6171: train loss = 0.3522 test loss = 0.4413\n","Iteration 6172: train loss = 0.3522 test loss = 0.4412\n","Iteration 6173: train loss = 0.3522 test loss = 0.4412\n","Iteration 6174: train loss = 0.3521 test loss = 0.4412\n","Iteration 6175: train loss = 0.3521 test loss = 0.4412\n","Iteration 6176: train loss = 0.3521 test loss = 0.4412\n","Iteration 6177: train loss = 0.3520 test loss = 0.4411\n","Iteration 6178: train loss = 0.3520 test loss = 0.4411\n","Iteration 6179: train loss = 0.3520 test loss = 0.4411\n","Iteration 6180: train loss = 0.3519 test loss = 0.4411\n","Iteration 6181: train loss = 0.3519 test loss = 0.4410\n","Iteration 6182: train loss = 0.3519 test loss = 0.4410\n","Iteration 6183: train loss = 0.3518 test loss = 0.4410\n","Iteration 6184: train loss = 0.3518 test loss = 0.4410\n","Iteration 6185: train loss = 0.3518 test loss = 0.4410\n","Iteration 6186: train loss = 0.3517 test loss = 0.4409\n","Iteration 6187: train loss = 0.3517 test loss = 0.4409\n","Iteration 6188: train loss = 0.3517 test loss = 0.4409\n","Iteration 6189: train loss = 0.3516 test loss = 0.4409\n","Iteration 6190: train loss = 0.3516 test loss = 0.4408\n","Iteration 6191: train loss = 0.3516 test loss = 0.4408\n","Iteration 6192: train loss = 0.3515 test loss = 0.4408\n","Iteration 6193: train loss = 0.3515 test loss = 0.4408\n","Iteration 6194: train loss = 0.3515 test loss = 0.4408\n","Iteration 6195: train loss = 0.3514 test loss = 0.4407\n","Iteration 6196: train loss = 0.3514 test loss = 0.4407\n","Iteration 6197: train loss = 0.3514 test loss = 0.4407\n","Iteration 6198: train loss = 0.3513 test loss = 0.4407\n","Iteration 6199: train loss = 0.3513 test loss = 0.4406\n","Iteration 6200: train loss = 0.3513 test loss = 0.4406\n","Iteration 6201: train loss = 0.3513 test loss = 0.4406\n","Iteration 6202: train loss = 0.3512 test loss = 0.4406\n","Iteration 6203: train loss = 0.3512 test loss = 0.4405\n","Iteration 6204: train loss = 0.3512 test loss = 0.4405\n","Iteration 6205: train loss = 0.3511 test loss = 0.4405\n","Iteration 6206: train loss = 0.3511 test loss = 0.4405\n","Iteration 6207: train loss = 0.3511 test loss = 0.4405\n","Iteration 6208: train loss = 0.3510 test loss = 0.4404\n","Iteration 6209: train loss = 0.3510 test loss = 0.4404\n","Iteration 6210: train loss = 0.3510 test loss = 0.4404\n","Iteration 6211: train loss = 0.3509 test loss = 0.4404\n","Iteration 6212: train loss = 0.3509 test loss = 0.4403\n","Iteration 6213: train loss = 0.3509 test loss = 0.4403\n","Iteration 6214: train loss = 0.3508 test loss = 0.4403\n","Iteration 6215: train loss = 0.3508 test loss = 0.4403\n","Iteration 6216: train loss = 0.3508 test loss = 0.4403\n","Iteration 6217: train loss = 0.3507 test loss = 0.4402\n","Iteration 6218: train loss = 0.3507 test loss = 0.4402\n","Iteration 6219: train loss = 0.3507 test loss = 0.4402\n","Iteration 6220: train loss = 0.3506 test loss = 0.4402\n","Iteration 6221: train loss = 0.3506 test loss = 0.4401\n","Iteration 6222: train loss = 0.3506 test loss = 0.4401\n","Iteration 6223: train loss = 0.3505 test loss = 0.4401\n","Iteration 6224: train loss = 0.3505 test loss = 0.4401\n","Iteration 6225: train loss = 0.3505 test loss = 0.4401\n","Iteration 6226: train loss = 0.3504 test loss = 0.4400\n","Iteration 6227: train loss = 0.3504 test loss = 0.4400\n","Iteration 6228: train loss = 0.3504 test loss = 0.4400\n","Iteration 6229: train loss = 0.3503 test loss = 0.4400\n","Iteration 6230: train loss = 0.3503 test loss = 0.4399\n","Iteration 6231: train loss = 0.3503 test loss = 0.4399\n","Iteration 6232: train loss = 0.3502 test loss = 0.4399\n","Iteration 6233: train loss = 0.3502 test loss = 0.4399\n","Iteration 6234: train loss = 0.3502 test loss = 0.4399\n","Iteration 6235: train loss = 0.3501 test loss = 0.4398\n","Iteration 6236: train loss = 0.3501 test loss = 0.4398\n","Iteration 6237: train loss = 0.3501 test loss = 0.4398\n","Iteration 6238: train loss = 0.3500 test loss = 0.4398\n","Iteration 6239: train loss = 0.3500 test loss = 0.4397\n","Iteration 6240: train loss = 0.3500 test loss = 0.4397\n","Iteration 6241: train loss = 0.3500 test loss = 0.4397\n","Iteration 6242: train loss = 0.3499 test loss = 0.4397\n","Iteration 6243: train loss = 0.3499 test loss = 0.4397\n","Iteration 6244: train loss = 0.3499 test loss = 0.4396\n","Iteration 6245: train loss = 0.3498 test loss = 0.4396\n","Iteration 6246: train loss = 0.3498 test loss = 0.4396\n","Iteration 6247: train loss = 0.3498 test loss = 0.4396\n","Iteration 6248: train loss = 0.3497 test loss = 0.4396\n","Iteration 6249: train loss = 0.3497 test loss = 0.4395\n","Iteration 6250: train loss = 0.3497 test loss = 0.4395\n","Iteration 6251: train loss = 0.3496 test loss = 0.4395\n","Iteration 6252: train loss = 0.3496 test loss = 0.4395\n","Iteration 6253: train loss = 0.3496 test loss = 0.4394\n","Iteration 6254: train loss = 0.3495 test loss = 0.4394\n","Iteration 6255: train loss = 0.3495 test loss = 0.4394\n","Iteration 6256: train loss = 0.3495 test loss = 0.4394\n","Iteration 6257: train loss = 0.3494 test loss = 0.4394\n","Iteration 6258: train loss = 0.3494 test loss = 0.4393\n","Iteration 6259: train loss = 0.3494 test loss = 0.4393\n","Iteration 6260: train loss = 0.3493 test loss = 0.4393\n","Iteration 6261: train loss = 0.3493 test loss = 0.4393\n","Iteration 6262: train loss = 0.3493 test loss = 0.4392\n","Iteration 6263: train loss = 0.3492 test loss = 0.4392\n","Iteration 6264: train loss = 0.3492 test loss = 0.4392\n","Iteration 6265: train loss = 0.3492 test loss = 0.4392\n","Iteration 6266: train loss = 0.3491 test loss = 0.4392\n","Iteration 6267: train loss = 0.3491 test loss = 0.4391\n","Iteration 6268: train loss = 0.3491 test loss = 0.4391\n","Iteration 6269: train loss = 0.3490 test loss = 0.4391\n","Iteration 6270: train loss = 0.3490 test loss = 0.4391\n","Iteration 6271: train loss = 0.3490 test loss = 0.4390\n","Iteration 6272: train loss = 0.3489 test loss = 0.4390\n","Iteration 6273: train loss = 0.3489 test loss = 0.4390\n","Iteration 6274: train loss = 0.3489 test loss = 0.4390\n","Iteration 6275: train loss = 0.3489 test loss = 0.4390\n","Iteration 6276: train loss = 0.3488 test loss = 0.4389\n","Iteration 6277: train loss = 0.3488 test loss = 0.4389\n","Iteration 6278: train loss = 0.3488 test loss = 0.4389\n","Iteration 6279: train loss = 0.3487 test loss = 0.4389\n","Iteration 6280: train loss = 0.3487 test loss = 0.4388\n","Iteration 6281: train loss = 0.3487 test loss = 0.4388\n","Iteration 6282: train loss = 0.3486 test loss = 0.4388\n","Iteration 6283: train loss = 0.3486 test loss = 0.4388\n","Iteration 6284: train loss = 0.3486 test loss = 0.4388\n","Iteration 6285: train loss = 0.3485 test loss = 0.4387\n","Iteration 6286: train loss = 0.3485 test loss = 0.4387\n","Iteration 6287: train loss = 0.3485 test loss = 0.4387\n","Iteration 6288: train loss = 0.3484 test loss = 0.4387\n","Iteration 6289: train loss = 0.3484 test loss = 0.4386\n","Iteration 6290: train loss = 0.3484 test loss = 0.4386\n","Iteration 6291: train loss = 0.3483 test loss = 0.4386\n","Iteration 6292: train loss = 0.3483 test loss = 0.4386\n","Iteration 6293: train loss = 0.3483 test loss = 0.4386\n","Iteration 6294: train loss = 0.3482 test loss = 0.4385\n","Iteration 6295: train loss = 0.3482 test loss = 0.4385\n","Iteration 6296: train loss = 0.3482 test loss = 0.4385\n","Iteration 6297: train loss = 0.3481 test loss = 0.4385\n","Iteration 6298: train loss = 0.3481 test loss = 0.4384\n","Iteration 6299: train loss = 0.3481 test loss = 0.4384\n","Iteration 6300: train loss = 0.3480 test loss = 0.4384\n","Iteration 6301: train loss = 0.3480 test loss = 0.4384\n","Iteration 6302: train loss = 0.3480 test loss = 0.4384\n","Iteration 6303: train loss = 0.3480 test loss = 0.4383\n","Iteration 6304: train loss = 0.3479 test loss = 0.4383\n","Iteration 6305: train loss = 0.3479 test loss = 0.4383\n","Iteration 6306: train loss = 0.3479 test loss = 0.4383\n","Iteration 6307: train loss = 0.3478 test loss = 0.4383\n","Iteration 6308: train loss = 0.3478 test loss = 0.4382\n","Iteration 6309: train loss = 0.3478 test loss = 0.4382\n","Iteration 6310: train loss = 0.3477 test loss = 0.4382\n","Iteration 6311: train loss = 0.3477 test loss = 0.4382\n","Iteration 6312: train loss = 0.3477 test loss = 0.4381\n","Iteration 6313: train loss = 0.3476 test loss = 0.4381\n","Iteration 6314: train loss = 0.3476 test loss = 0.4381\n","Iteration 6315: train loss = 0.3476 test loss = 0.4381\n","Iteration 6316: train loss = 0.3475 test loss = 0.4381\n","Iteration 6317: train loss = 0.3475 test loss = 0.4380\n","Iteration 6318: train loss = 0.3475 test loss = 0.4380\n","Iteration 6319: train loss = 0.3474 test loss = 0.4380\n","Iteration 6320: train loss = 0.3474 test loss = 0.4380\n","Iteration 6321: train loss = 0.3474 test loss = 0.4379\n","Iteration 6322: train loss = 0.3473 test loss = 0.4379\n","Iteration 6323: train loss = 0.3473 test loss = 0.4379\n","Iteration 6324: train loss = 0.3473 test loss = 0.4379\n","Iteration 6325: train loss = 0.3472 test loss = 0.4379\n","Iteration 6326: train loss = 0.3472 test loss = 0.4378\n","Iteration 6327: train loss = 0.3472 test loss = 0.4378\n","Iteration 6328: train loss = 0.3471 test loss = 0.4378\n","Iteration 6329: train loss = 0.3471 test loss = 0.4378\n","Iteration 6330: train loss = 0.3471 test loss = 0.4377\n","Iteration 6331: train loss = 0.3471 test loss = 0.4377\n","Iteration 6332: train loss = 0.3470 test loss = 0.4377\n","Iteration 6333: train loss = 0.3470 test loss = 0.4377\n","Iteration 6334: train loss = 0.3470 test loss = 0.4377\n","Iteration 6335: train loss = 0.3469 test loss = 0.4376\n","Iteration 6336: train loss = 0.3469 test loss = 0.4376\n","Iteration 6337: train loss = 0.3469 test loss = 0.4376\n","Iteration 6338: train loss = 0.3468 test loss = 0.4376\n","Iteration 6339: train loss = 0.3468 test loss = 0.4376\n","Iteration 6340: train loss = 0.3468 test loss = 0.4375\n","Iteration 6341: train loss = 0.3467 test loss = 0.4375\n","Iteration 6342: train loss = 0.3467 test loss = 0.4375\n","Iteration 6343: train loss = 0.3467 test loss = 0.4375\n","Iteration 6344: train loss = 0.3466 test loss = 0.4374\n","Iteration 6345: train loss = 0.3466 test loss = 0.4374\n","Iteration 6346: train loss = 0.3466 test loss = 0.4374\n","Iteration 6347: train loss = 0.3465 test loss = 0.4374\n","Iteration 6348: train loss = 0.3465 test loss = 0.4374\n","Iteration 6349: train loss = 0.3465 test loss = 0.4373\n","Iteration 6350: train loss = 0.3464 test loss = 0.4373\n","Iteration 6351: train loss = 0.3464 test loss = 0.4373\n","Iteration 6352: train loss = 0.3464 test loss = 0.4373\n","Iteration 6353: train loss = 0.3463 test loss = 0.4372\n","Iteration 6354: train loss = 0.3463 test loss = 0.4372\n","Iteration 6355: train loss = 0.3463 test loss = 0.4372\n","Iteration 6356: train loss = 0.3463 test loss = 0.4372\n","Iteration 6357: train loss = 0.3462 test loss = 0.4372\n","Iteration 6358: train loss = 0.3462 test loss = 0.4371\n","Iteration 6359: train loss = 0.3462 test loss = 0.4371\n","Iteration 6360: train loss = 0.3461 test loss = 0.4371\n","Iteration 6361: train loss = 0.3461 test loss = 0.4371\n","Iteration 6362: train loss = 0.3461 test loss = 0.4371\n","Iteration 6363: train loss = 0.3460 test loss = 0.4370\n","Iteration 6364: train loss = 0.3460 test loss = 0.4370\n","Iteration 6365: train loss = 0.3460 test loss = 0.4370\n","Iteration 6366: train loss = 0.3459 test loss = 0.4370\n","Iteration 6367: train loss = 0.3459 test loss = 0.4369\n","Iteration 6368: train loss = 0.3459 test loss = 0.4369\n","Iteration 6369: train loss = 0.3458 test loss = 0.4369\n","Iteration 6370: train loss = 0.3458 test loss = 0.4369\n","Iteration 6371: train loss = 0.3458 test loss = 0.4369\n","Iteration 6372: train loss = 0.3457 test loss = 0.4368\n","Iteration 6373: train loss = 0.3457 test loss = 0.4368\n","Iteration 6374: train loss = 0.3457 test loss = 0.4368\n","Iteration 6375: train loss = 0.3456 test loss = 0.4368\n","Iteration 6376: train loss = 0.3456 test loss = 0.4367\n","Iteration 6377: train loss = 0.3456 test loss = 0.4367\n","Iteration 6378: train loss = 0.3456 test loss = 0.4367\n","Iteration 6379: train loss = 0.3455 test loss = 0.4367\n","Iteration 6380: train loss = 0.3455 test loss = 0.4367\n","Iteration 6381: train loss = 0.3455 test loss = 0.4366\n","Iteration 6382: train loss = 0.3454 test loss = 0.4366\n","Iteration 6383: train loss = 0.3454 test loss = 0.4366\n","Iteration 6384: train loss = 0.3454 test loss = 0.4366\n","Iteration 6385: train loss = 0.3453 test loss = 0.4366\n","Iteration 6386: train loss = 0.3453 test loss = 0.4365\n","Iteration 6387: train loss = 0.3453 test loss = 0.4365\n","Iteration 6388: train loss = 0.3452 test loss = 0.4365\n","Iteration 6389: train loss = 0.3452 test loss = 0.4365\n","Iteration 6390: train loss = 0.3452 test loss = 0.4364\n","Iteration 6391: train loss = 0.3451 test loss = 0.4364\n","Iteration 6392: train loss = 0.3451 test loss = 0.4364\n","Iteration 6393: train loss = 0.3451 test loss = 0.4364\n","Iteration 6394: train loss = 0.3450 test loss = 0.4364\n","Iteration 6395: train loss = 0.3450 test loss = 0.4363\n","Iteration 6396: train loss = 0.3450 test loss = 0.4363\n","Iteration 6397: train loss = 0.3449 test loss = 0.4363\n","Iteration 6398: train loss = 0.3449 test loss = 0.4363\n","Iteration 6399: train loss = 0.3449 test loss = 0.4363\n","Iteration 6400: train loss = 0.3449 test loss = 0.4362\n","Iteration 6401: train loss = 0.3448 test loss = 0.4362\n","Iteration 6402: train loss = 0.3448 test loss = 0.4362\n","Iteration 6403: train loss = 0.3448 test loss = 0.4362\n","Iteration 6404: train loss = 0.3447 test loss = 0.4361\n","Iteration 6405: train loss = 0.3447 test loss = 0.4361\n","Iteration 6406: train loss = 0.3447 test loss = 0.4361\n","Iteration 6407: train loss = 0.3446 test loss = 0.4361\n","Iteration 6408: train loss = 0.3446 test loss = 0.4361\n","Iteration 6409: train loss = 0.3446 test loss = 0.4360\n","Iteration 6410: train loss = 0.3445 test loss = 0.4360\n","Iteration 6411: train loss = 0.3445 test loss = 0.4360\n","Iteration 6412: train loss = 0.3445 test loss = 0.4360\n","Iteration 6413: train loss = 0.3444 test loss = 0.4359\n","Iteration 6414: train loss = 0.3444 test loss = 0.4359\n","Iteration 6415: train loss = 0.3444 test loss = 0.4359\n","Iteration 6416: train loss = 0.3443 test loss = 0.4359\n","Iteration 6417: train loss = 0.3443 test loss = 0.4359\n","Iteration 6418: train loss = 0.3443 test loss = 0.4358\n","Iteration 6419: train loss = 0.3443 test loss = 0.4358\n","Iteration 6420: train loss = 0.3442 test loss = 0.4358\n","Iteration 6421: train loss = 0.3442 test loss = 0.4358\n","Iteration 6422: train loss = 0.3442 test loss = 0.4358\n","Iteration 6423: train loss = 0.3441 test loss = 0.4357\n","Iteration 6424: train loss = 0.3441 test loss = 0.4357\n","Iteration 6425: train loss = 0.3441 test loss = 0.4357\n","Iteration 6426: train loss = 0.3440 test loss = 0.4357\n","Iteration 6427: train loss = 0.3440 test loss = 0.4356\n","Iteration 6428: train loss = 0.3440 test loss = 0.4356\n","Iteration 6429: train loss = 0.3439 test loss = 0.4356\n","Iteration 6430: train loss = 0.3439 test loss = 0.4356\n","Iteration 6431: train loss = 0.3439 test loss = 0.4356\n","Iteration 6432: train loss = 0.3438 test loss = 0.4355\n","Iteration 6433: train loss = 0.3438 test loss = 0.4355\n","Iteration 6434: train loss = 0.3438 test loss = 0.4355\n","Iteration 6435: train loss = 0.3437 test loss = 0.4355\n","Iteration 6436: train loss = 0.3437 test loss = 0.4355\n","Iteration 6437: train loss = 0.3437 test loss = 0.4354\n","Iteration 6438: train loss = 0.3437 test loss = 0.4354\n","Iteration 6439: train loss = 0.3436 test loss = 0.4354\n","Iteration 6440: train loss = 0.3436 test loss = 0.4354\n","Iteration 6441: train loss = 0.3436 test loss = 0.4353\n","Iteration 6442: train loss = 0.3435 test loss = 0.4353\n","Iteration 6443: train loss = 0.3435 test loss = 0.4353\n","Iteration 6444: train loss = 0.3435 test loss = 0.4353\n","Iteration 6445: train loss = 0.3434 test loss = 0.4353\n","Iteration 6446: train loss = 0.3434 test loss = 0.4352\n","Iteration 6447: train loss = 0.3434 test loss = 0.4352\n","Iteration 6448: train loss = 0.3433 test loss = 0.4352\n","Iteration 6449: train loss = 0.3433 test loss = 0.4352\n","Iteration 6450: train loss = 0.3433 test loss = 0.4352\n","Iteration 6451: train loss = 0.3432 test loss = 0.4351\n","Iteration 6452: train loss = 0.3432 test loss = 0.4351\n","Iteration 6453: train loss = 0.3432 test loss = 0.4351\n","Iteration 6454: train loss = 0.3431 test loss = 0.4351\n","Iteration 6455: train loss = 0.3431 test loss = 0.4350\n","Iteration 6456: train loss = 0.3431 test loss = 0.4350\n","Iteration 6457: train loss = 0.3431 test loss = 0.4350\n","Iteration 6458: train loss = 0.3430 test loss = 0.4350\n","Iteration 6459: train loss = 0.3430 test loss = 0.4350\n","Iteration 6460: train loss = 0.3430 test loss = 0.4349\n","Iteration 6461: train loss = 0.3429 test loss = 0.4349\n","Iteration 6462: train loss = 0.3429 test loss = 0.4349\n","Iteration 6463: train loss = 0.3429 test loss = 0.4349\n","Iteration 6464: train loss = 0.3428 test loss = 0.4349\n","Iteration 6465: train loss = 0.3428 test loss = 0.4348\n","Iteration 6466: train loss = 0.3428 test loss = 0.4348\n","Iteration 6467: train loss = 0.3427 test loss = 0.4348\n","Iteration 6468: train loss = 0.3427 test loss = 0.4348\n","Iteration 6469: train loss = 0.3427 test loss = 0.4347\n","Iteration 6470: train loss = 0.3426 test loss = 0.4347\n","Iteration 6471: train loss = 0.3426 test loss = 0.4347\n","Iteration 6472: train loss = 0.3426 test loss = 0.4347\n","Iteration 6473: train loss = 0.3425 test loss = 0.4347\n","Iteration 6474: train loss = 0.3425 test loss = 0.4346\n","Iteration 6475: train loss = 0.3425 test loss = 0.4346\n","Iteration 6476: train loss = 0.3425 test loss = 0.4346\n","Iteration 6477: train loss = 0.3424 test loss = 0.4346\n","Iteration 6478: train loss = 0.3424 test loss = 0.4346\n","Iteration 6479: train loss = 0.3424 test loss = 0.4345\n","Iteration 6480: train loss = 0.3423 test loss = 0.4345\n","Iteration 6481: train loss = 0.3423 test loss = 0.4345\n","Iteration 6482: train loss = 0.3423 test loss = 0.4345\n","Iteration 6483: train loss = 0.3422 test loss = 0.4344\n","Iteration 6484: train loss = 0.3422 test loss = 0.4344\n","Iteration 6485: train loss = 0.3422 test loss = 0.4344\n","Iteration 6486: train loss = 0.3421 test loss = 0.4344\n","Iteration 6487: train loss = 0.3421 test loss = 0.4344\n","Iteration 6488: train loss = 0.3421 test loss = 0.4343\n","Iteration 6489: train loss = 0.3420 test loss = 0.4343\n","Iteration 6490: train loss = 0.3420 test loss = 0.4343\n","Iteration 6491: train loss = 0.3420 test loss = 0.4343\n","Iteration 6492: train loss = 0.3420 test loss = 0.4343\n","Iteration 6493: train loss = 0.3419 test loss = 0.4342\n","Iteration 6494: train loss = 0.3419 test loss = 0.4342\n","Iteration 6495: train loss = 0.3419 test loss = 0.4342\n","Iteration 6496: train loss = 0.3418 test loss = 0.4342\n","Iteration 6497: train loss = 0.3418 test loss = 0.4341\n","Iteration 6498: train loss = 0.3418 test loss = 0.4341\n","Iteration 6499: train loss = 0.3417 test loss = 0.4341\n","Iteration 6500: train loss = 0.3417 test loss = 0.4341\n","Iteration 6501: train loss = 0.3417 test loss = 0.4341\n","Iteration 6502: train loss = 0.3416 test loss = 0.4340\n","Iteration 6503: train loss = 0.3416 test loss = 0.4340\n","Iteration 6504: train loss = 0.3416 test loss = 0.4340\n","Iteration 6505: train loss = 0.3415 test loss = 0.4340\n","Iteration 6506: train loss = 0.3415 test loss = 0.4340\n","Iteration 6507: train loss = 0.3415 test loss = 0.4339\n","Iteration 6508: train loss = 0.3415 test loss = 0.4339\n","Iteration 6509: train loss = 0.3414 test loss = 0.4339\n","Iteration 6510: train loss = 0.3414 test loss = 0.4339\n","Iteration 6511: train loss = 0.3414 test loss = 0.4339\n","Iteration 6512: train loss = 0.3413 test loss = 0.4338\n","Iteration 6513: train loss = 0.3413 test loss = 0.4338\n","Iteration 6514: train loss = 0.3413 test loss = 0.4338\n","Iteration 6515: train loss = 0.3412 test loss = 0.4338\n","Iteration 6516: train loss = 0.3412 test loss = 0.4337\n","Iteration 6517: train loss = 0.3412 test loss = 0.4337\n","Iteration 6518: train loss = 0.3411 test loss = 0.4337\n","Iteration 6519: train loss = 0.3411 test loss = 0.4337\n","Iteration 6520: train loss = 0.3411 test loss = 0.4337\n","Iteration 6521: train loss = 0.3410 test loss = 0.4336\n","Iteration 6522: train loss = 0.3410 test loss = 0.4336\n","Iteration 6523: train loss = 0.3410 test loss = 0.4336\n","Iteration 6524: train loss = 0.3410 test loss = 0.4336\n","Iteration 6525: train loss = 0.3409 test loss = 0.4336\n","Iteration 6526: train loss = 0.3409 test loss = 0.4335\n","Iteration 6527: train loss = 0.3409 test loss = 0.4335\n","Iteration 6528: train loss = 0.3408 test loss = 0.4335\n","Iteration 6529: train loss = 0.3408 test loss = 0.4335\n","Iteration 6530: train loss = 0.3408 test loss = 0.4334\n","Iteration 6531: train loss = 0.3407 test loss = 0.4334\n","Iteration 6532: train loss = 0.3407 test loss = 0.4334\n","Iteration 6533: train loss = 0.3407 test loss = 0.4334\n","Iteration 6534: train loss = 0.3406 test loss = 0.4334\n","Iteration 6535: train loss = 0.3406 test loss = 0.4333\n","Iteration 6536: train loss = 0.3406 test loss = 0.4333\n","Iteration 6537: train loss = 0.3405 test loss = 0.4333\n","Iteration 6538: train loss = 0.3405 test loss = 0.4333\n","Iteration 6539: train loss = 0.3405 test loss = 0.4333\n","Iteration 6540: train loss = 0.3405 test loss = 0.4332\n","Iteration 6541: train loss = 0.3404 test loss = 0.4332\n","Iteration 6542: train loss = 0.3404 test loss = 0.4332\n","Iteration 6543: train loss = 0.3404 test loss = 0.4332\n","Iteration 6544: train loss = 0.3403 test loss = 0.4332\n","Iteration 6545: train loss = 0.3403 test loss = 0.4331\n","Iteration 6546: train loss = 0.3403 test loss = 0.4331\n","Iteration 6547: train loss = 0.3402 test loss = 0.4331\n","Iteration 6548: train loss = 0.3402 test loss = 0.4331\n","Iteration 6549: train loss = 0.3402 test loss = 0.4330\n","Iteration 6550: train loss = 0.3401 test loss = 0.4330\n","Iteration 6551: train loss = 0.3401 test loss = 0.4330\n","Iteration 6552: train loss = 0.3401 test loss = 0.4330\n","Iteration 6553: train loss = 0.3400 test loss = 0.4330\n","Iteration 6554: train loss = 0.3400 test loss = 0.4329\n","Iteration 6555: train loss = 0.3400 test loss = 0.4329\n","Iteration 6556: train loss = 0.3400 test loss = 0.4329\n","Iteration 6557: train loss = 0.3399 test loss = 0.4329\n","Iteration 6558: train loss = 0.3399 test loss = 0.4329\n","Iteration 6559: train loss = 0.3399 test loss = 0.4328\n","Iteration 6560: train loss = 0.3398 test loss = 0.4328\n","Iteration 6561: train loss = 0.3398 test loss = 0.4328\n","Iteration 6562: train loss = 0.3398 test loss = 0.4328\n","Iteration 6563: train loss = 0.3397 test loss = 0.4328\n","Iteration 6564: train loss = 0.3397 test loss = 0.4327\n","Iteration 6565: train loss = 0.3397 test loss = 0.4327\n","Iteration 6566: train loss = 0.3396 test loss = 0.4327\n","Iteration 6567: train loss = 0.3396 test loss = 0.4327\n","Iteration 6568: train loss = 0.3396 test loss = 0.4326\n","Iteration 6569: train loss = 0.3395 test loss = 0.4326\n","Iteration 6570: train loss = 0.3395 test loss = 0.4326\n","Iteration 6571: train loss = 0.3395 test loss = 0.4326\n","Iteration 6572: train loss = 0.3395 test loss = 0.4326\n","Iteration 6573: train loss = 0.3394 test loss = 0.4325\n","Iteration 6574: train loss = 0.3394 test loss = 0.4325\n","Iteration 6575: train loss = 0.3394 test loss = 0.4325\n","Iteration 6576: train loss = 0.3393 test loss = 0.4325\n","Iteration 6577: train loss = 0.3393 test loss = 0.4325\n","Iteration 6578: train loss = 0.3393 test loss = 0.4324\n","Iteration 6579: train loss = 0.3392 test loss = 0.4324\n","Iteration 6580: train loss = 0.3392 test loss = 0.4324\n","Iteration 6581: train loss = 0.3392 test loss = 0.4324\n","Iteration 6582: train loss = 0.3391 test loss = 0.4324\n","Iteration 6583: train loss = 0.3391 test loss = 0.4323\n","Iteration 6584: train loss = 0.3391 test loss = 0.4323\n","Iteration 6585: train loss = 0.3391 test loss = 0.4323\n","Iteration 6586: train loss = 0.3390 test loss = 0.4323\n","Iteration 6587: train loss = 0.3390 test loss = 0.4322\n","Iteration 6588: train loss = 0.3390 test loss = 0.4322\n","Iteration 6589: train loss = 0.3389 test loss = 0.4322\n","Iteration 6590: train loss = 0.3389 test loss = 0.4322\n","Iteration 6591: train loss = 0.3389 test loss = 0.4322\n","Iteration 6592: train loss = 0.3388 test loss = 0.4321\n","Iteration 6593: train loss = 0.3388 test loss = 0.4321\n","Iteration 6594: train loss = 0.3388 test loss = 0.4321\n","Iteration 6595: train loss = 0.3387 test loss = 0.4321\n","Iteration 6596: train loss = 0.3387 test loss = 0.4321\n","Iteration 6597: train loss = 0.3387 test loss = 0.4320\n","Iteration 6598: train loss = 0.3387 test loss = 0.4320\n","Iteration 6599: train loss = 0.3386 test loss = 0.4320\n","Iteration 6600: train loss = 0.3386 test loss = 0.4320\n","Iteration 6601: train loss = 0.3386 test loss = 0.4320\n","Iteration 6602: train loss = 0.3385 test loss = 0.4319\n","Iteration 6603: train loss = 0.3385 test loss = 0.4319\n","Iteration 6604: train loss = 0.3385 test loss = 0.4319\n","Iteration 6605: train loss = 0.3384 test loss = 0.4319\n","Iteration 6606: train loss = 0.3384 test loss = 0.4319\n","Iteration 6607: train loss = 0.3384 test loss = 0.4318\n","Iteration 6608: train loss = 0.3383 test loss = 0.4318\n","Iteration 6609: train loss = 0.3383 test loss = 0.4318\n","Iteration 6610: train loss = 0.3383 test loss = 0.4318\n","Iteration 6611: train loss = 0.3382 test loss = 0.4317\n","Iteration 6612: train loss = 0.3382 test loss = 0.4317\n","Iteration 6613: train loss = 0.3382 test loss = 0.4317\n","Iteration 6614: train loss = 0.3382 test loss = 0.4317\n","Iteration 6615: train loss = 0.3381 test loss = 0.4317\n","Iteration 6616: train loss = 0.3381 test loss = 0.4316\n","Iteration 6617: train loss = 0.3381 test loss = 0.4316\n","Iteration 6618: train loss = 0.3380 test loss = 0.4316\n","Iteration 6619: train loss = 0.3380 test loss = 0.4316\n","Iteration 6620: train loss = 0.3380 test loss = 0.4316\n","Iteration 6621: train loss = 0.3379 test loss = 0.4315\n","Iteration 6622: train loss = 0.3379 test loss = 0.4315\n","Iteration 6623: train loss = 0.3379 test loss = 0.4315\n","Iteration 6624: train loss = 0.3378 test loss = 0.4315\n","Iteration 6625: train loss = 0.3378 test loss = 0.4315\n","Iteration 6626: train loss = 0.3378 test loss = 0.4314\n","Iteration 6627: train loss = 0.3378 test loss = 0.4314\n","Iteration 6628: train loss = 0.3377 test loss = 0.4314\n","Iteration 6629: train loss = 0.3377 test loss = 0.4314\n","Iteration 6630: train loss = 0.3377 test loss = 0.4314\n","Iteration 6631: train loss = 0.3376 test loss = 0.4313\n","Iteration 6632: train loss = 0.3376 test loss = 0.4313\n","Iteration 6633: train loss = 0.3376 test loss = 0.4313\n","Iteration 6634: train loss = 0.3375 test loss = 0.4313\n","Iteration 6635: train loss = 0.3375 test loss = 0.4312\n","Iteration 6636: train loss = 0.3375 test loss = 0.4312\n","Iteration 6637: train loss = 0.3374 test loss = 0.4312\n","Iteration 6638: train loss = 0.3374 test loss = 0.4312\n","Iteration 6639: train loss = 0.3374 test loss = 0.4312\n","Iteration 6640: train loss = 0.3374 test loss = 0.4311\n","Iteration 6641: train loss = 0.3373 test loss = 0.4311\n","Iteration 6642: train loss = 0.3373 test loss = 0.4311\n","Iteration 6643: train loss = 0.3373 test loss = 0.4311\n","Iteration 6644: train loss = 0.3372 test loss = 0.4311\n","Iteration 6645: train loss = 0.3372 test loss = 0.4310\n","Iteration 6646: train loss = 0.3372 test loss = 0.4310\n","Iteration 6647: train loss = 0.3371 test loss = 0.4310\n","Iteration 6648: train loss = 0.3371 test loss = 0.4310\n","Iteration 6649: train loss = 0.3371 test loss = 0.4310\n","Iteration 6650: train loss = 0.3370 test loss = 0.4309\n","Iteration 6651: train loss = 0.3370 test loss = 0.4309\n","Iteration 6652: train loss = 0.3370 test loss = 0.4309\n","Iteration 6653: train loss = 0.3370 test loss = 0.4309\n","Iteration 6654: train loss = 0.3369 test loss = 0.4309\n","Iteration 6655: train loss = 0.3369 test loss = 0.4308\n","Iteration 6656: train loss = 0.3369 test loss = 0.4308\n","Iteration 6657: train loss = 0.3368 test loss = 0.4308\n","Iteration 6658: train loss = 0.3368 test loss = 0.4308\n","Iteration 6659: train loss = 0.3368 test loss = 0.4307\n","Iteration 6660: train loss = 0.3367 test loss = 0.4307\n","Iteration 6661: train loss = 0.3367 test loss = 0.4307\n","Iteration 6662: train loss = 0.3367 test loss = 0.4307\n","Iteration 6663: train loss = 0.3367 test loss = 0.4307\n","Iteration 6664: train loss = 0.3366 test loss = 0.4306\n","Iteration 6665: train loss = 0.3366 test loss = 0.4306\n","Iteration 6666: train loss = 0.3366 test loss = 0.4306\n","Iteration 6667: train loss = 0.3365 test loss = 0.4306\n","Iteration 6668: train loss = 0.3365 test loss = 0.4306\n","Iteration 6669: train loss = 0.3365 test loss = 0.4305\n","Iteration 6670: train loss = 0.3364 test loss = 0.4305\n","Iteration 6671: train loss = 0.3364 test loss = 0.4305\n","Iteration 6672: train loss = 0.3364 test loss = 0.4305\n","Iteration 6673: train loss = 0.3363 test loss = 0.4305\n","Iteration 6674: train loss = 0.3363 test loss = 0.4304\n","Iteration 6675: train loss = 0.3363 test loss = 0.4304\n","Iteration 6676: train loss = 0.3363 test loss = 0.4304\n","Iteration 6677: train loss = 0.3362 test loss = 0.4304\n","Iteration 6678: train loss = 0.3362 test loss = 0.4304\n","Iteration 6679: train loss = 0.3362 test loss = 0.4303\n","Iteration 6680: train loss = 0.3361 test loss = 0.4303\n","Iteration 6681: train loss = 0.3361 test loss = 0.4303\n","Iteration 6682: train loss = 0.3361 test loss = 0.4303\n","Iteration 6683: train loss = 0.3360 test loss = 0.4303\n","Iteration 6684: train loss = 0.3360 test loss = 0.4302\n","Iteration 6685: train loss = 0.3360 test loss = 0.4302\n","Iteration 6686: train loss = 0.3359 test loss = 0.4302\n","Iteration 6687: train loss = 0.3359 test loss = 0.4302\n","Iteration 6688: train loss = 0.3359 test loss = 0.4301\n","Iteration 6689: train loss = 0.3359 test loss = 0.4301\n","Iteration 6690: train loss = 0.3358 test loss = 0.4301\n","Iteration 6691: train loss = 0.3358 test loss = 0.4301\n","Iteration 6692: train loss = 0.3358 test loss = 0.4301\n","Iteration 6693: train loss = 0.3357 test loss = 0.4300\n","Iteration 6694: train loss = 0.3357 test loss = 0.4300\n","Iteration 6695: train loss = 0.3357 test loss = 0.4300\n","Iteration 6696: train loss = 0.3356 test loss = 0.4300\n","Iteration 6697: train loss = 0.3356 test loss = 0.4300\n","Iteration 6698: train loss = 0.3356 test loss = 0.4299\n","Iteration 6699: train loss = 0.3355 test loss = 0.4299\n","Iteration 6700: train loss = 0.3355 test loss = 0.4299\n","Iteration 6701: train loss = 0.3355 test loss = 0.4299\n","Iteration 6702: train loss = 0.3355 test loss = 0.4299\n","Iteration 6703: train loss = 0.3354 test loss = 0.4298\n","Iteration 6704: train loss = 0.3354 test loss = 0.4298\n","Iteration 6705: train loss = 0.3354 test loss = 0.4298\n","Iteration 6706: train loss = 0.3353 test loss = 0.4298\n","Iteration 6707: train loss = 0.3353 test loss = 0.4298\n","Iteration 6708: train loss = 0.3353 test loss = 0.4297\n","Iteration 6709: train loss = 0.3352 test loss = 0.4297\n","Iteration 6710: train loss = 0.3352 test loss = 0.4297\n","Iteration 6711: train loss = 0.3352 test loss = 0.4297\n","Iteration 6712: train loss = 0.3352 test loss = 0.4297\n","Iteration 6713: train loss = 0.3351 test loss = 0.4296\n","Iteration 6714: train loss = 0.3351 test loss = 0.4296\n","Iteration 6715: train loss = 0.3351 test loss = 0.4296\n","Iteration 6716: train loss = 0.3350 test loss = 0.4296\n","Iteration 6717: train loss = 0.3350 test loss = 0.4296\n","Iteration 6718: train loss = 0.3350 test loss = 0.4295\n","Iteration 6719: train loss = 0.3349 test loss = 0.4295\n","Iteration 6720: train loss = 0.3349 test loss = 0.4295\n","Iteration 6721: train loss = 0.3349 test loss = 0.4295\n","Iteration 6722: train loss = 0.3348 test loss = 0.4294\n","Iteration 6723: train loss = 0.3348 test loss = 0.4294\n","Iteration 6724: train loss = 0.3348 test loss = 0.4294\n","Iteration 6725: train loss = 0.3348 test loss = 0.4294\n","Iteration 6726: train loss = 0.3347 test loss = 0.4294\n","Iteration 6727: train loss = 0.3347 test loss = 0.4293\n","Iteration 6728: train loss = 0.3347 test loss = 0.4293\n","Iteration 6729: train loss = 0.3346 test loss = 0.4293\n","Iteration 6730: train loss = 0.3346 test loss = 0.4293\n","Iteration 6731: train loss = 0.3346 test loss = 0.4293\n","Iteration 6732: train loss = 0.3345 test loss = 0.4292\n","Iteration 6733: train loss = 0.3345 test loss = 0.4292\n","Iteration 6734: train loss = 0.3345 test loss = 0.4292\n","Iteration 6735: train loss = 0.3345 test loss = 0.4292\n","Iteration 6736: train loss = 0.3344 test loss = 0.4292\n","Iteration 6737: train loss = 0.3344 test loss = 0.4291\n","Iteration 6738: train loss = 0.3344 test loss = 0.4291\n","Iteration 6739: train loss = 0.3343 test loss = 0.4291\n","Iteration 6740: train loss = 0.3343 test loss = 0.4291\n","Iteration 6741: train loss = 0.3343 test loss = 0.4291\n","Iteration 6742: train loss = 0.3342 test loss = 0.4290\n","Iteration 6743: train loss = 0.3342 test loss = 0.4290\n","Iteration 6744: train loss = 0.3342 test loss = 0.4290\n","Iteration 6745: train loss = 0.3341 test loss = 0.4290\n","Iteration 6746: train loss = 0.3341 test loss = 0.4290\n","Iteration 6747: train loss = 0.3341 test loss = 0.4289\n","Iteration 6748: train loss = 0.3341 test loss = 0.4289\n","Iteration 6749: train loss = 0.3340 test loss = 0.4289\n","Iteration 6750: train loss = 0.3340 test loss = 0.4289\n","Iteration 6751: train loss = 0.3340 test loss = 0.4289\n","Iteration 6752: train loss = 0.3339 test loss = 0.4288\n","Iteration 6753: train loss = 0.3339 test loss = 0.4288\n","Iteration 6754: train loss = 0.3339 test loss = 0.4288\n","Iteration 6755: train loss = 0.3338 test loss = 0.4288\n","Iteration 6756: train loss = 0.3338 test loss = 0.4288\n","Iteration 6757: train loss = 0.3338 test loss = 0.4287\n","Iteration 6758: train loss = 0.3338 test loss = 0.4287\n","Iteration 6759: train loss = 0.3337 test loss = 0.4287\n","Iteration 6760: train loss = 0.3337 test loss = 0.4287\n","Iteration 6761: train loss = 0.3337 test loss = 0.4287\n","Iteration 6762: train loss = 0.3336 test loss = 0.4286\n","Iteration 6763: train loss = 0.3336 test loss = 0.4286\n","Iteration 6764: train loss = 0.3336 test loss = 0.4286\n","Iteration 6765: train loss = 0.3335 test loss = 0.4286\n","Iteration 6766: train loss = 0.3335 test loss = 0.4285\n","Iteration 6767: train loss = 0.3335 test loss = 0.4285\n","Iteration 6768: train loss = 0.3335 test loss = 0.4285\n","Iteration 6769: train loss = 0.3334 test loss = 0.4285\n","Iteration 6770: train loss = 0.3334 test loss = 0.4285\n","Iteration 6771: train loss = 0.3334 test loss = 0.4284\n","Iteration 6772: train loss = 0.3333 test loss = 0.4284\n","Iteration 6773: train loss = 0.3333 test loss = 0.4284\n","Iteration 6774: train loss = 0.3333 test loss = 0.4284\n","Iteration 6775: train loss = 0.3332 test loss = 0.4284\n","Iteration 6776: train loss = 0.3332 test loss = 0.4283\n","Iteration 6777: train loss = 0.3332 test loss = 0.4283\n","Iteration 6778: train loss = 0.3331 test loss = 0.4283\n","Iteration 6779: train loss = 0.3331 test loss = 0.4283\n","Iteration 6780: train loss = 0.3331 test loss = 0.4283\n","Iteration 6781: train loss = 0.3331 test loss = 0.4282\n","Iteration 6782: train loss = 0.3330 test loss = 0.4282\n","Iteration 6783: train loss = 0.3330 test loss = 0.4282\n","Iteration 6784: train loss = 0.3330 test loss = 0.4282\n","Iteration 6785: train loss = 0.3329 test loss = 0.4282\n","Iteration 6786: train loss = 0.3329 test loss = 0.4281\n","Iteration 6787: train loss = 0.3329 test loss = 0.4281\n","Iteration 6788: train loss = 0.3328 test loss = 0.4281\n","Iteration 6789: train loss = 0.3328 test loss = 0.4281\n","Iteration 6790: train loss = 0.3328 test loss = 0.4281\n","Iteration 6791: train loss = 0.3328 test loss = 0.4280\n","Iteration 6792: train loss = 0.3327 test loss = 0.4280\n","Iteration 6793: train loss = 0.3327 test loss = 0.4280\n","Iteration 6794: train loss = 0.3327 test loss = 0.4280\n","Iteration 6795: train loss = 0.3326 test loss = 0.4280\n","Iteration 6796: train loss = 0.3326 test loss = 0.4279\n","Iteration 6797: train loss = 0.3326 test loss = 0.4279\n","Iteration 6798: train loss = 0.3325 test loss = 0.4279\n","Iteration 6799: train loss = 0.3325 test loss = 0.4279\n","Iteration 6800: train loss = 0.3325 test loss = 0.4279\n","Iteration 6801: train loss = 0.3325 test loss = 0.4278\n","Iteration 6802: train loss = 0.3324 test loss = 0.4278\n","Iteration 6803: train loss = 0.3324 test loss = 0.4278\n","Iteration 6804: train loss = 0.3324 test loss = 0.4278\n","Iteration 6805: train loss = 0.3323 test loss = 0.4278\n","Iteration 6806: train loss = 0.3323 test loss = 0.4277\n","Iteration 6807: train loss = 0.3323 test loss = 0.4277\n","Iteration 6808: train loss = 0.3322 test loss = 0.4277\n","Iteration 6809: train loss = 0.3322 test loss = 0.4277\n","Iteration 6810: train loss = 0.3322 test loss = 0.4277\n","Iteration 6811: train loss = 0.3322 test loss = 0.4276\n","Iteration 6812: train loss = 0.3321 test loss = 0.4276\n","Iteration 6813: train loss = 0.3321 test loss = 0.4276\n","Iteration 6814: train loss = 0.3321 test loss = 0.4276\n","Iteration 6815: train loss = 0.3320 test loss = 0.4276\n","Iteration 6816: train loss = 0.3320 test loss = 0.4275\n","Iteration 6817: train loss = 0.3320 test loss = 0.4275\n","Iteration 6818: train loss = 0.3319 test loss = 0.4275\n","Iteration 6819: train loss = 0.3319 test loss = 0.4275\n","Iteration 6820: train loss = 0.3319 test loss = 0.4275\n","Iteration 6821: train loss = 0.3319 test loss = 0.4274\n","Iteration 6822: train loss = 0.3318 test loss = 0.4274\n","Iteration 6823: train loss = 0.3318 test loss = 0.4274\n","Iteration 6824: train loss = 0.3318 test loss = 0.4274\n","Iteration 6825: train loss = 0.3317 test loss = 0.4274\n","Iteration 6826: train loss = 0.3317 test loss = 0.4273\n","Iteration 6827: train loss = 0.3317 test loss = 0.4273\n","Iteration 6828: train loss = 0.3316 test loss = 0.4273\n","Iteration 6829: train loss = 0.3316 test loss = 0.4273\n","Iteration 6830: train loss = 0.3316 test loss = 0.4273\n","Iteration 6831: train loss = 0.3316 test loss = 0.4272\n","Iteration 6832: train loss = 0.3315 test loss = 0.4272\n","Iteration 6833: train loss = 0.3315 test loss = 0.4272\n","Iteration 6834: train loss = 0.3315 test loss = 0.4272\n","Iteration 6835: train loss = 0.3314 test loss = 0.4272\n","Iteration 6836: train loss = 0.3314 test loss = 0.4271\n","Iteration 6837: train loss = 0.3314 test loss = 0.4271\n","Iteration 6838: train loss = 0.3313 test loss = 0.4271\n","Iteration 6839: train loss = 0.3313 test loss = 0.4271\n","Iteration 6840: train loss = 0.3313 test loss = 0.4270\n","Iteration 6841: train loss = 0.3313 test loss = 0.4270\n","Iteration 6842: train loss = 0.3312 test loss = 0.4270\n","Iteration 6843: train loss = 0.3312 test loss = 0.4270\n","Iteration 6844: train loss = 0.3312 test loss = 0.4270\n","Iteration 6845: train loss = 0.3311 test loss = 0.4269\n","Iteration 6846: train loss = 0.3311 test loss = 0.4269\n","Iteration 6847: train loss = 0.3311 test loss = 0.4269\n","Iteration 6848: train loss = 0.3310 test loss = 0.4269\n","Iteration 6849: train loss = 0.3310 test loss = 0.4269\n","Iteration 6850: train loss = 0.3310 test loss = 0.4268\n","Iteration 6851: train loss = 0.3310 test loss = 0.4268\n","Iteration 6852: train loss = 0.3309 test loss = 0.4268\n","Iteration 6853: train loss = 0.3309 test loss = 0.4268\n","Iteration 6854: train loss = 0.3309 test loss = 0.4268\n","Iteration 6855: train loss = 0.3308 test loss = 0.4267\n","Iteration 6856: train loss = 0.3308 test loss = 0.4267\n","Iteration 6857: train loss = 0.3308 test loss = 0.4267\n","Iteration 6858: train loss = 0.3307 test loss = 0.4267\n","Iteration 6859: train loss = 0.3307 test loss = 0.4267\n","Iteration 6860: train loss = 0.3307 test loss = 0.4266\n","Iteration 6861: train loss = 0.3307 test loss = 0.4266\n","Iteration 6862: train loss = 0.3306 test loss = 0.4266\n","Iteration 6863: train loss = 0.3306 test loss = 0.4266\n","Iteration 6864: train loss = 0.3306 test loss = 0.4266\n","Iteration 6865: train loss = 0.3305 test loss = 0.4265\n","Iteration 6866: train loss = 0.3305 test loss = 0.4265\n","Iteration 6867: train loss = 0.3305 test loss = 0.4265\n","Iteration 6868: train loss = 0.3304 test loss = 0.4265\n","Iteration 6869: train loss = 0.3304 test loss = 0.4265\n","Iteration 6870: train loss = 0.3304 test loss = 0.4264\n","Iteration 6871: train loss = 0.3304 test loss = 0.4264\n","Iteration 6872: train loss = 0.3303 test loss = 0.4264\n","Iteration 6873: train loss = 0.3303 test loss = 0.4264\n","Iteration 6874: train loss = 0.3303 test loss = 0.4264\n","Iteration 6875: train loss = 0.3302 test loss = 0.4263\n","Iteration 6876: train loss = 0.3302 test loss = 0.4263\n","Iteration 6877: train loss = 0.3302 test loss = 0.4263\n","Iteration 6878: train loss = 0.3301 test loss = 0.4263\n","Iteration 6879: train loss = 0.3301 test loss = 0.4263\n","Iteration 6880: train loss = 0.3301 test loss = 0.4262\n","Iteration 6881: train loss = 0.3301 test loss = 0.4262\n","Iteration 6882: train loss = 0.3300 test loss = 0.4262\n","Iteration 6883: train loss = 0.3300 test loss = 0.4262\n","Iteration 6884: train loss = 0.3300 test loss = 0.4262\n","Iteration 6885: train loss = 0.3299 test loss = 0.4261\n","Iteration 6886: train loss = 0.3299 test loss = 0.4261\n","Iteration 6887: train loss = 0.3299 test loss = 0.4261\n","Iteration 6888: train loss = 0.3298 test loss = 0.4261\n","Iteration 6889: train loss = 0.3298 test loss = 0.4261\n","Iteration 6890: train loss = 0.3298 test loss = 0.4260\n","Iteration 6891: train loss = 0.3298 test loss = 0.4260\n","Iteration 6892: train loss = 0.3297 test loss = 0.4260\n","Iteration 6893: train loss = 0.3297 test loss = 0.4260\n","Iteration 6894: train loss = 0.3297 test loss = 0.4260\n","Iteration 6895: train loss = 0.3296 test loss = 0.4259\n","Iteration 6896: train loss = 0.3296 test loss = 0.4259\n","Iteration 6897: train loss = 0.3296 test loss = 0.4259\n","Iteration 6898: train loss = 0.3296 test loss = 0.4259\n","Iteration 6899: train loss = 0.3295 test loss = 0.4259\n","Iteration 6900: train loss = 0.3295 test loss = 0.4258\n","Iteration 6901: train loss = 0.3295 test loss = 0.4258\n","Iteration 6902: train loss = 0.3294 test loss = 0.4258\n","Iteration 6903: train loss = 0.3294 test loss = 0.4258\n","Iteration 6904: train loss = 0.3294 test loss = 0.4258\n","Iteration 6905: train loss = 0.3293 test loss = 0.4257\n","Iteration 6906: train loss = 0.3293 test loss = 0.4257\n","Iteration 6907: train loss = 0.3293 test loss = 0.4257\n","Iteration 6908: train loss = 0.3293 test loss = 0.4257\n","Iteration 6909: train loss = 0.3292 test loss = 0.4257\n","Iteration 6910: train loss = 0.3292 test loss = 0.4256\n","Iteration 6911: train loss = 0.3292 test loss = 0.4256\n","Iteration 6912: train loss = 0.3291 test loss = 0.4256\n","Iteration 6913: train loss = 0.3291 test loss = 0.4256\n","Iteration 6914: train loss = 0.3291 test loss = 0.4256\n","Iteration 6915: train loss = 0.3290 test loss = 0.4255\n","Iteration 6916: train loss = 0.3290 test loss = 0.4255\n","Iteration 6917: train loss = 0.3290 test loss = 0.4255\n","Iteration 6918: train loss = 0.3290 test loss = 0.4255\n","Iteration 6919: train loss = 0.3289 test loss = 0.4255\n","Iteration 6920: train loss = 0.3289 test loss = 0.4254\n","Iteration 6921: train loss = 0.3289 test loss = 0.4254\n","Iteration 6922: train loss = 0.3288 test loss = 0.4254\n","Iteration 6923: train loss = 0.3288 test loss = 0.4254\n","Iteration 6924: train loss = 0.3288 test loss = 0.4254\n","Iteration 6925: train loss = 0.3287 test loss = 0.4253\n","Iteration 6926: train loss = 0.3287 test loss = 0.4253\n","Iteration 6927: train loss = 0.3287 test loss = 0.4253\n","Iteration 6928: train loss = 0.3287 test loss = 0.4253\n","Iteration 6929: train loss = 0.3286 test loss = 0.4253\n","Iteration 6930: train loss = 0.3286 test loss = 0.4252\n","Iteration 6931: train loss = 0.3286 test loss = 0.4252\n","Iteration 6932: train loss = 0.3285 test loss = 0.4252\n","Iteration 6933: train loss = 0.3285 test loss = 0.4252\n","Iteration 6934: train loss = 0.3285 test loss = 0.4252\n","Iteration 6935: train loss = 0.3285 test loss = 0.4252\n","Iteration 6936: train loss = 0.3284 test loss = 0.4251\n","Iteration 6937: train loss = 0.3284 test loss = 0.4251\n","Iteration 6938: train loss = 0.3284 test loss = 0.4251\n","Iteration 6939: train loss = 0.3283 test loss = 0.4251\n","Iteration 6940: train loss = 0.3283 test loss = 0.4251\n","Iteration 6941: train loss = 0.3283 test loss = 0.4250\n","Iteration 6942: train loss = 0.3282 test loss = 0.4250\n","Iteration 6943: train loss = 0.3282 test loss = 0.4250\n","Iteration 6944: train loss = 0.3282 test loss = 0.4250\n","Iteration 6945: train loss = 0.3282 test loss = 0.4250\n","Iteration 6946: train loss = 0.3281 test loss = 0.4249\n","Iteration 6947: train loss = 0.3281 test loss = 0.4249\n","Iteration 6948: train loss = 0.3281 test loss = 0.4249\n","Iteration 6949: train loss = 0.3280 test loss = 0.4249\n","Iteration 6950: train loss = 0.3280 test loss = 0.4249\n","Iteration 6951: train loss = 0.3280 test loss = 0.4248\n","Iteration 6952: train loss = 0.3280 test loss = 0.4248\n","Iteration 6953: train loss = 0.3279 test loss = 0.4248\n","Iteration 6954: train loss = 0.3279 test loss = 0.4248\n","Iteration 6955: train loss = 0.3279 test loss = 0.4248\n","Iteration 6956: train loss = 0.3278 test loss = 0.4247\n","Iteration 6957: train loss = 0.3278 test loss = 0.4247\n","Iteration 6958: train loss = 0.3278 test loss = 0.4247\n","Iteration 6959: train loss = 0.3277 test loss = 0.4247\n","Iteration 6960: train loss = 0.3277 test loss = 0.4247\n","Iteration 6961: train loss = 0.3277 test loss = 0.4246\n","Iteration 6962: train loss = 0.3277 test loss = 0.4246\n","Iteration 6963: train loss = 0.3276 test loss = 0.4246\n","Iteration 6964: train loss = 0.3276 test loss = 0.4246\n","Iteration 6965: train loss = 0.3276 test loss = 0.4246\n","Iteration 6966: train loss = 0.3275 test loss = 0.4245\n","Iteration 6967: train loss = 0.3275 test loss = 0.4245\n","Iteration 6968: train loss = 0.3275 test loss = 0.4245\n","Iteration 6969: train loss = 0.3274 test loss = 0.4245\n","Iteration 6970: train loss = 0.3274 test loss = 0.4245\n","Iteration 6971: train loss = 0.3274 test loss = 0.4244\n","Iteration 6972: train loss = 0.3274 test loss = 0.4244\n","Iteration 6973: train loss = 0.3273 test loss = 0.4244\n","Iteration 6974: train loss = 0.3273 test loss = 0.4244\n","Iteration 6975: train loss = 0.3273 test loss = 0.4244\n","Iteration 6976: train loss = 0.3272 test loss = 0.4243\n","Iteration 6977: train loss = 0.3272 test loss = 0.4243\n","Iteration 6978: train loss = 0.3272 test loss = 0.4243\n","Iteration 6979: train loss = 0.3272 test loss = 0.4243\n","Iteration 6980: train loss = 0.3271 test loss = 0.4243\n","Iteration 6981: train loss = 0.3271 test loss = 0.4242\n","Iteration 6982: train loss = 0.3271 test loss = 0.4242\n","Iteration 6983: train loss = 0.3270 test loss = 0.4242\n","Iteration 6984: train loss = 0.3270 test loss = 0.4242\n","Iteration 6985: train loss = 0.3270 test loss = 0.4242\n","Iteration 6986: train loss = 0.3269 test loss = 0.4241\n","Iteration 6987: train loss = 0.3269 test loss = 0.4241\n","Iteration 6988: train loss = 0.3269 test loss = 0.4241\n","Iteration 6989: train loss = 0.3269 test loss = 0.4241\n","Iteration 6990: train loss = 0.3268 test loss = 0.4241\n","Iteration 6991: train loss = 0.3268 test loss = 0.4240\n","Iteration 6992: train loss = 0.3268 test loss = 0.4240\n","Iteration 6993: train loss = 0.3267 test loss = 0.4240\n","Iteration 6994: train loss = 0.3267 test loss = 0.4240\n","Iteration 6995: train loss = 0.3267 test loss = 0.4240\n","Iteration 6996: train loss = 0.3267 test loss = 0.4239\n","Iteration 6997: train loss = 0.3266 test loss = 0.4239\n","Iteration 6998: train loss = 0.3266 test loss = 0.4239\n","Iteration 6999: train loss = 0.3266 test loss = 0.4239\n","Iteration 7000: train loss = 0.3265 test loss = 0.4239\n","Iteration 7001: train loss = 0.3265 test loss = 0.4238\n","Iteration 7002: train loss = 0.3265 test loss = 0.4238\n","Iteration 7003: train loss = 0.3264 test loss = 0.4238\n","Iteration 7004: train loss = 0.3264 test loss = 0.4238\n","Iteration 7005: train loss = 0.3264 test loss = 0.4238\n","Iteration 7006: train loss = 0.3264 test loss = 0.4237\n","Iteration 7007: train loss = 0.3263 test loss = 0.4237\n","Iteration 7008: train loss = 0.3263 test loss = 0.4237\n","Iteration 7009: train loss = 0.3263 test loss = 0.4237\n","Iteration 7010: train loss = 0.3262 test loss = 0.4237\n","Iteration 7011: train loss = 0.3262 test loss = 0.4237\n","Iteration 7012: train loss = 0.3262 test loss = 0.4236\n","Iteration 7013: train loss = 0.3262 test loss = 0.4236\n","Iteration 7014: train loss = 0.3261 test loss = 0.4236\n","Iteration 7015: train loss = 0.3261 test loss = 0.4236\n","Iteration 7016: train loss = 0.3261 test loss = 0.4236\n","Iteration 7017: train loss = 0.3260 test loss = 0.4235\n","Iteration 7018: train loss = 0.3260 test loss = 0.4235\n","Iteration 7019: train loss = 0.3260 test loss = 0.4235\n","Iteration 7020: train loss = 0.3259 test loss = 0.4235\n","Iteration 7021: train loss = 0.3259 test loss = 0.4235\n","Iteration 7022: train loss = 0.3259 test loss = 0.4234\n","Iteration 7023: train loss = 0.3259 test loss = 0.4234\n","Iteration 7024: train loss = 0.3258 test loss = 0.4234\n","Iteration 7025: train loss = 0.3258 test loss = 0.4234\n","Iteration 7026: train loss = 0.3258 test loss = 0.4234\n","Iteration 7027: train loss = 0.3257 test loss = 0.4233\n","Iteration 7028: train loss = 0.3257 test loss = 0.4233\n","Iteration 7029: train loss = 0.3257 test loss = 0.4233\n","Iteration 7030: train loss = 0.3257 test loss = 0.4233\n","Iteration 7031: train loss = 0.3256 test loss = 0.4233\n","Iteration 7032: train loss = 0.3256 test loss = 0.4232\n","Iteration 7033: train loss = 0.3256 test loss = 0.4232\n","Iteration 7034: train loss = 0.3255 test loss = 0.4232\n","Iteration 7035: train loss = 0.3255 test loss = 0.4232\n","Iteration 7036: train loss = 0.3255 test loss = 0.4232\n","Iteration 7037: train loss = 0.3255 test loss = 0.4231\n","Iteration 7038: train loss = 0.3254 test loss = 0.4231\n","Iteration 7039: train loss = 0.3254 test loss = 0.4231\n","Iteration 7040: train loss = 0.3254 test loss = 0.4231\n","Iteration 7041: train loss = 0.3253 test loss = 0.4231\n","Iteration 7042: train loss = 0.3253 test loss = 0.4230\n","Iteration 7043: train loss = 0.3253 test loss = 0.4230\n","Iteration 7044: train loss = 0.3252 test loss = 0.4230\n","Iteration 7045: train loss = 0.3252 test loss = 0.4230\n","Iteration 7046: train loss = 0.3252 test loss = 0.4230\n","Iteration 7047: train loss = 0.3252 test loss = 0.4229\n","Iteration 7048: train loss = 0.3251 test loss = 0.4229\n","Iteration 7049: train loss = 0.3251 test loss = 0.4229\n","Iteration 7050: train loss = 0.3251 test loss = 0.4229\n","Iteration 7051: train loss = 0.3250 test loss = 0.4229\n","Iteration 7052: train loss = 0.3250 test loss = 0.4228\n","Iteration 7053: train loss = 0.3250 test loss = 0.4228\n","Iteration 7054: train loss = 0.3250 test loss = 0.4228\n","Iteration 7055: train loss = 0.3249 test loss = 0.4228\n","Iteration 7056: train loss = 0.3249 test loss = 0.4228\n","Iteration 7057: train loss = 0.3249 test loss = 0.4228\n","Iteration 7058: train loss = 0.3248 test loss = 0.4227\n","Iteration 7059: train loss = 0.3248 test loss = 0.4227\n","Iteration 7060: train loss = 0.3248 test loss = 0.4227\n","Iteration 7061: train loss = 0.3248 test loss = 0.4227\n","Iteration 7062: train loss = 0.3247 test loss = 0.4227\n","Iteration 7063: train loss = 0.3247 test loss = 0.4226\n","Iteration 7064: train loss = 0.3247 test loss = 0.4226\n","Iteration 7065: train loss = 0.3246 test loss = 0.4226\n","Iteration 7066: train loss = 0.3246 test loss = 0.4226\n","Iteration 7067: train loss = 0.3246 test loss = 0.4226\n","Iteration 7068: train loss = 0.3245 test loss = 0.4225\n","Iteration 7069: train loss = 0.3245 test loss = 0.4225\n","Iteration 7070: train loss = 0.3245 test loss = 0.4225\n","Iteration 7071: train loss = 0.3245 test loss = 0.4225\n","Iteration 7072: train loss = 0.3244 test loss = 0.4225\n","Iteration 7073: train loss = 0.3244 test loss = 0.4224\n","Iteration 7074: train loss = 0.3244 test loss = 0.4224\n","Iteration 7075: train loss = 0.3243 test loss = 0.4224\n","Iteration 7076: train loss = 0.3243 test loss = 0.4224\n","Iteration 7077: train loss = 0.3243 test loss = 0.4224\n","Iteration 7078: train loss = 0.3243 test loss = 0.4223\n","Iteration 7079: train loss = 0.3242 test loss = 0.4223\n","Iteration 7080: train loss = 0.3242 test loss = 0.4223\n","Iteration 7081: train loss = 0.3242 test loss = 0.4223\n","Iteration 7082: train loss = 0.3241 test loss = 0.4223\n","Iteration 7083: train loss = 0.3241 test loss = 0.4222\n","Iteration 7084: train loss = 0.3241 test loss = 0.4222\n","Iteration 7085: train loss = 0.3241 test loss = 0.4222\n","Iteration 7086: train loss = 0.3240 test loss = 0.4222\n","Iteration 7087: train loss = 0.3240 test loss = 0.4222\n","Iteration 7088: train loss = 0.3240 test loss = 0.4221\n","Iteration 7089: train loss = 0.3239 test loss = 0.4221\n","Iteration 7090: train loss = 0.3239 test loss = 0.4221\n","Iteration 7091: train loss = 0.3239 test loss = 0.4221\n","Iteration 7092: train loss = 0.3239 test loss = 0.4221\n","Iteration 7093: train loss = 0.3238 test loss = 0.4221\n","Iteration 7094: train loss = 0.3238 test loss = 0.4220\n","Iteration 7095: train loss = 0.3238 test loss = 0.4220\n","Iteration 7096: train loss = 0.3237 test loss = 0.4220\n","Iteration 7097: train loss = 0.3237 test loss = 0.4220\n","Iteration 7098: train loss = 0.3237 test loss = 0.4220\n","Iteration 7099: train loss = 0.3236 test loss = 0.4219\n","Iteration 7100: train loss = 0.3236 test loss = 0.4219\n","Iteration 7101: train loss = 0.3236 test loss = 0.4219\n","Iteration 7102: train loss = 0.3236 test loss = 0.4219\n","Iteration 7103: train loss = 0.3235 test loss = 0.4219\n","Iteration 7104: train loss = 0.3235 test loss = 0.4218\n","Iteration 7105: train loss = 0.3235 test loss = 0.4218\n","Iteration 7106: train loss = 0.3234 test loss = 0.4218\n","Iteration 7107: train loss = 0.3234 test loss = 0.4218\n","Iteration 7108: train loss = 0.3234 test loss = 0.4218\n","Iteration 7109: train loss = 0.3234 test loss = 0.4217\n","Iteration 7110: train loss = 0.3233 test loss = 0.4217\n","Iteration 7111: train loss = 0.3233 test loss = 0.4217\n","Iteration 7112: train loss = 0.3233 test loss = 0.4217\n","Iteration 7113: train loss = 0.3232 test loss = 0.4217\n","Iteration 7114: train loss = 0.3232 test loss = 0.4216\n","Iteration 7115: train loss = 0.3232 test loss = 0.4216\n","Iteration 7116: train loss = 0.3232 test loss = 0.4216\n","Iteration 7117: train loss = 0.3231 test loss = 0.4216\n","Iteration 7118: train loss = 0.3231 test loss = 0.4216\n","Iteration 7119: train loss = 0.3231 test loss = 0.4216\n","Iteration 7120: train loss = 0.3230 test loss = 0.4215\n","Iteration 7121: train loss = 0.3230 test loss = 0.4215\n","Iteration 7122: train loss = 0.3230 test loss = 0.4215\n","Iteration 7123: train loss = 0.3230 test loss = 0.4215\n","Iteration 7124: train loss = 0.3229 test loss = 0.4215\n","Iteration 7125: train loss = 0.3229 test loss = 0.4214\n","Iteration 7126: train loss = 0.3229 test loss = 0.4214\n","Iteration 7127: train loss = 0.3228 test loss = 0.4214\n","Iteration 7128: train loss = 0.3228 test loss = 0.4214\n","Iteration 7129: train loss = 0.3228 test loss = 0.4214\n","Iteration 7130: train loss = 0.3227 test loss = 0.4213\n","Iteration 7131: train loss = 0.3227 test loss = 0.4213\n","Iteration 7132: train loss = 0.3227 test loss = 0.4213\n","Iteration 7133: train loss = 0.3227 test loss = 0.4213\n","Iteration 7134: train loss = 0.3226 test loss = 0.4213\n","Iteration 7135: train loss = 0.3226 test loss = 0.4212\n","Iteration 7136: train loss = 0.3226 test loss = 0.4212\n","Iteration 7137: train loss = 0.3225 test loss = 0.4212\n","Iteration 7138: train loss = 0.3225 test loss = 0.4212\n","Iteration 7139: train loss = 0.3225 test loss = 0.4212\n","Iteration 7140: train loss = 0.3225 test loss = 0.4211\n","Iteration 7141: train loss = 0.3224 test loss = 0.4211\n","Iteration 7142: train loss = 0.3224 test loss = 0.4211\n","Iteration 7143: train loss = 0.3224 test loss = 0.4211\n","Iteration 7144: train loss = 0.3223 test loss = 0.4211\n","Iteration 7145: train loss = 0.3223 test loss = 0.4211\n","Iteration 7146: train loss = 0.3223 test loss = 0.4210\n","Iteration 7147: train loss = 0.3223 test loss = 0.4210\n","Iteration 7148: train loss = 0.3222 test loss = 0.4210\n","Iteration 7149: train loss = 0.3222 test loss = 0.4210\n","Iteration 7150: train loss = 0.3222 test loss = 0.4210\n","Iteration 7151: train loss = 0.3221 test loss = 0.4209\n","Iteration 7152: train loss = 0.3221 test loss = 0.4209\n","Iteration 7153: train loss = 0.3221 test loss = 0.4209\n","Iteration 7154: train loss = 0.3221 test loss = 0.4209\n","Iteration 7155: train loss = 0.3220 test loss = 0.4209\n","Iteration 7156: train loss = 0.3220 test loss = 0.4208\n","Iteration 7157: train loss = 0.3220 test loss = 0.4208\n","Iteration 7158: train loss = 0.3219 test loss = 0.4208\n","Iteration 7159: train loss = 0.3219 test loss = 0.4208\n","Iteration 7160: train loss = 0.3219 test loss = 0.4208\n","Iteration 7161: train loss = 0.3219 test loss = 0.4207\n","Iteration 7162: train loss = 0.3218 test loss = 0.4207\n","Iteration 7163: train loss = 0.3218 test loss = 0.4207\n","Iteration 7164: train loss = 0.3218 test loss = 0.4207\n","Iteration 7165: train loss = 0.3217 test loss = 0.4207\n","Iteration 7166: train loss = 0.3217 test loss = 0.4206\n","Iteration 7167: train loss = 0.3217 test loss = 0.4206\n","Iteration 7168: train loss = 0.3217 test loss = 0.4206\n","Iteration 7169: train loss = 0.3216 test loss = 0.4206\n","Iteration 7170: train loss = 0.3216 test loss = 0.4206\n","Iteration 7171: train loss = 0.3216 test loss = 0.4206\n","Iteration 7172: train loss = 0.3215 test loss = 0.4205\n","Iteration 7173: train loss = 0.3215 test loss = 0.4205\n","Iteration 7174: train loss = 0.3215 test loss = 0.4205\n","Iteration 7175: train loss = 0.3215 test loss = 0.4205\n","Iteration 7176: train loss = 0.3214 test loss = 0.4205\n","Iteration 7177: train loss = 0.3214 test loss = 0.4204\n","Iteration 7178: train loss = 0.3214 test loss = 0.4204\n","Iteration 7179: train loss = 0.3213 test loss = 0.4204\n","Iteration 7180: train loss = 0.3213 test loss = 0.4204\n","Iteration 7181: train loss = 0.3213 test loss = 0.4204\n","Iteration 7182: train loss = 0.3213 test loss = 0.4203\n","Iteration 7183: train loss = 0.3212 test loss = 0.4203\n","Iteration 7184: train loss = 0.3212 test loss = 0.4203\n","Iteration 7185: train loss = 0.3212 test loss = 0.4203\n","Iteration 7186: train loss = 0.3211 test loss = 0.4203\n","Iteration 7187: train loss = 0.3211 test loss = 0.4202\n","Iteration 7188: train loss = 0.3211 test loss = 0.4202\n","Iteration 7189: train loss = 0.3211 test loss = 0.4202\n","Iteration 7190: train loss = 0.3210 test loss = 0.4202\n","Iteration 7191: train loss = 0.3210 test loss = 0.4202\n","Iteration 7192: train loss = 0.3210 test loss = 0.4202\n","Iteration 7193: train loss = 0.3209 test loss = 0.4201\n","Iteration 7194: train loss = 0.3209 test loss = 0.4201\n","Iteration 7195: train loss = 0.3209 test loss = 0.4201\n","Iteration 7196: train loss = 0.3209 test loss = 0.4201\n","Iteration 7197: train loss = 0.3208 test loss = 0.4201\n","Iteration 7198: train loss = 0.3208 test loss = 0.4200\n","Iteration 7199: train loss = 0.3208 test loss = 0.4200\n","Iteration 7200: train loss = 0.3207 test loss = 0.4200\n","Iteration 7201: train loss = 0.3207 test loss = 0.4200\n","Iteration 7202: train loss = 0.3207 test loss = 0.4200\n","Iteration 7203: train loss = 0.3207 test loss = 0.4199\n","Iteration 7204: train loss = 0.3206 test loss = 0.4199\n","Iteration 7205: train loss = 0.3206 test loss = 0.4199\n","Iteration 7206: train loss = 0.3206 test loss = 0.4199\n","Iteration 7207: train loss = 0.3205 test loss = 0.4199\n","Iteration 7208: train loss = 0.3205 test loss = 0.4198\n","Iteration 7209: train loss = 0.3205 test loss = 0.4198\n","Iteration 7210: train loss = 0.3205 test loss = 0.4198\n","Iteration 7211: train loss = 0.3204 test loss = 0.4198\n","Iteration 7212: train loss = 0.3204 test loss = 0.4198\n","Iteration 7213: train loss = 0.3204 test loss = 0.4198\n","Iteration 7214: train loss = 0.3203 test loss = 0.4197\n","Iteration 7215: train loss = 0.3203 test loss = 0.4197\n","Iteration 7216: train loss = 0.3203 test loss = 0.4197\n","Iteration 7217: train loss = 0.3202 test loss = 0.4197\n","Iteration 7218: train loss = 0.3202 test loss = 0.4197\n","Iteration 7219: train loss = 0.3202 test loss = 0.4196\n","Iteration 7220: train loss = 0.3202 test loss = 0.4196\n","Iteration 7221: train loss = 0.3201 test loss = 0.4196\n","Iteration 7222: train loss = 0.3201 test loss = 0.4196\n","Iteration 7223: train loss = 0.3201 test loss = 0.4196\n","Iteration 7224: train loss = 0.3200 test loss = 0.4195\n","Iteration 7225: train loss = 0.3200 test loss = 0.4195\n","Iteration 7226: train loss = 0.3200 test loss = 0.4195\n","Iteration 7227: train loss = 0.3200 test loss = 0.4195\n","Iteration 7228: train loss = 0.3199 test loss = 0.4195\n","Iteration 7229: train loss = 0.3199 test loss = 0.4194\n","Iteration 7230: train loss = 0.3199 test loss = 0.4194\n","Iteration 7231: train loss = 0.3199 test loss = 0.4194\n","Iteration 7232: train loss = 0.3198 test loss = 0.4194\n","Iteration 7233: train loss = 0.3198 test loss = 0.4194\n","Iteration 7234: train loss = 0.3198 test loss = 0.4194\n","Iteration 7235: train loss = 0.3197 test loss = 0.4193\n","Iteration 7236: train loss = 0.3197 test loss = 0.4193\n","Iteration 7237: train loss = 0.3197 test loss = 0.4193\n","Iteration 7238: train loss = 0.3197 test loss = 0.4193\n","Iteration 7239: train loss = 0.3196 test loss = 0.4193\n","Iteration 7240: train loss = 0.3196 test loss = 0.4192\n","Iteration 7241: train loss = 0.3196 test loss = 0.4192\n","Iteration 7242: train loss = 0.3195 test loss = 0.4192\n","Iteration 7243: train loss = 0.3195 test loss = 0.4192\n","Iteration 7244: train loss = 0.3195 test loss = 0.4192\n","Iteration 7245: train loss = 0.3195 test loss = 0.4191\n","Iteration 7246: train loss = 0.3194 test loss = 0.4191\n","Iteration 7247: train loss = 0.3194 test loss = 0.4191\n","Iteration 7248: train loss = 0.3194 test loss = 0.4191\n","Iteration 7249: train loss = 0.3193 test loss = 0.4191\n","Iteration 7250: train loss = 0.3193 test loss = 0.4191\n","Iteration 7251: train loss = 0.3193 test loss = 0.4190\n","Iteration 7252: train loss = 0.3193 test loss = 0.4190\n","Iteration 7253: train loss = 0.3192 test loss = 0.4190\n","Iteration 7254: train loss = 0.3192 test loss = 0.4190\n","Iteration 7255: train loss = 0.3192 test loss = 0.4190\n","Iteration 7256: train loss = 0.3191 test loss = 0.4189\n","Iteration 7257: train loss = 0.3191 test loss = 0.4189\n","Iteration 7258: train loss = 0.3191 test loss = 0.4189\n","Iteration 7259: train loss = 0.3191 test loss = 0.4189\n","Iteration 7260: train loss = 0.3190 test loss = 0.4189\n","Iteration 7261: train loss = 0.3190 test loss = 0.4188\n","Iteration 7262: train loss = 0.3190 test loss = 0.4188\n","Iteration 7263: train loss = 0.3189 test loss = 0.4188\n","Iteration 7264: train loss = 0.3189 test loss = 0.4188\n","Iteration 7265: train loss = 0.3189 test loss = 0.4188\n","Iteration 7266: train loss = 0.3189 test loss = 0.4187\n","Iteration 7267: train loss = 0.3188 test loss = 0.4187\n","Iteration 7268: train loss = 0.3188 test loss = 0.4187\n","Iteration 7269: train loss = 0.3188 test loss = 0.4187\n","Iteration 7270: train loss = 0.3187 test loss = 0.4187\n","Iteration 7271: train loss = 0.3187 test loss = 0.4187\n","Iteration 7272: train loss = 0.3187 test loss = 0.4186\n","Iteration 7273: train loss = 0.3187 test loss = 0.4186\n","Iteration 7274: train loss = 0.3186 test loss = 0.4186\n","Iteration 7275: train loss = 0.3186 test loss = 0.4186\n","Iteration 7276: train loss = 0.3186 test loss = 0.4186\n","Iteration 7277: train loss = 0.3185 test loss = 0.4185\n","Iteration 7278: train loss = 0.3185 test loss = 0.4185\n","Iteration 7279: train loss = 0.3185 test loss = 0.4185\n","Iteration 7280: train loss = 0.3185 test loss = 0.4185\n","Iteration 7281: train loss = 0.3184 test loss = 0.4185\n","Iteration 7282: train loss = 0.3184 test loss = 0.4184\n","Iteration 7283: train loss = 0.3184 test loss = 0.4184\n","Iteration 7284: train loss = 0.3183 test loss = 0.4184\n","Iteration 7285: train loss = 0.3183 test loss = 0.4184\n","Iteration 7286: train loss = 0.3183 test loss = 0.4184\n","Iteration 7287: train loss = 0.3183 test loss = 0.4184\n","Iteration 7288: train loss = 0.3182 test loss = 0.4183\n","Iteration 7289: train loss = 0.3182 test loss = 0.4183\n","Iteration 7290: train loss = 0.3182 test loss = 0.4183\n","Iteration 7291: train loss = 0.3181 test loss = 0.4183\n","Iteration 7292: train loss = 0.3181 test loss = 0.4183\n","Iteration 7293: train loss = 0.3181 test loss = 0.4182\n","Iteration 7294: train loss = 0.3181 test loss = 0.4182\n","Iteration 7295: train loss = 0.3180 test loss = 0.4182\n","Iteration 7296: train loss = 0.3180 test loss = 0.4182\n","Iteration 7297: train loss = 0.3180 test loss = 0.4182\n","Iteration 7298: train loss = 0.3179 test loss = 0.4181\n","Iteration 7299: train loss = 0.3179 test loss = 0.4181\n","Iteration 7300: train loss = 0.3179 test loss = 0.4181\n","Iteration 7301: train loss = 0.3179 test loss = 0.4181\n","Iteration 7302: train loss = 0.3178 test loss = 0.4181\n","Iteration 7303: train loss = 0.3178 test loss = 0.4181\n","Iteration 7304: train loss = 0.3178 test loss = 0.4180\n","Iteration 7305: train loss = 0.3177 test loss = 0.4180\n","Iteration 7306: train loss = 0.3177 test loss = 0.4180\n","Iteration 7307: train loss = 0.3177 test loss = 0.4180\n","Iteration 7308: train loss = 0.3177 test loss = 0.4180\n","Iteration 7309: train loss = 0.3176 test loss = 0.4179\n","Iteration 7310: train loss = 0.3176 test loss = 0.4179\n","Iteration 7311: train loss = 0.3176 test loss = 0.4179\n","Iteration 7312: train loss = 0.3176 test loss = 0.4179\n","Iteration 7313: train loss = 0.3175 test loss = 0.4179\n","Iteration 7314: train loss = 0.3175 test loss = 0.4178\n","Iteration 7315: train loss = 0.3175 test loss = 0.4178\n","Iteration 7316: train loss = 0.3174 test loss = 0.4178\n","Iteration 7317: train loss = 0.3174 test loss = 0.4178\n","Iteration 7318: train loss = 0.3174 test loss = 0.4178\n","Iteration 7319: train loss = 0.3174 test loss = 0.4178\n","Iteration 7320: train loss = 0.3173 test loss = 0.4177\n","Iteration 7321: train loss = 0.3173 test loss = 0.4177\n","Iteration 7322: train loss = 0.3173 test loss = 0.4177\n","Iteration 7323: train loss = 0.3172 test loss = 0.4177\n","Iteration 7324: train loss = 0.3172 test loss = 0.4177\n","Iteration 7325: train loss = 0.3172 test loss = 0.4176\n","Iteration 7326: train loss = 0.3172 test loss = 0.4176\n","Iteration 7327: train loss = 0.3171 test loss = 0.4176\n","Iteration 7328: train loss = 0.3171 test loss = 0.4176\n","Iteration 7329: train loss = 0.3171 test loss = 0.4176\n","Iteration 7330: train loss = 0.3170 test loss = 0.4175\n","Iteration 7331: train loss = 0.3170 test loss = 0.4175\n","Iteration 7332: train loss = 0.3170 test loss = 0.4175\n","Iteration 7333: train loss = 0.3170 test loss = 0.4175\n","Iteration 7334: train loss = 0.3169 test loss = 0.4175\n","Iteration 7335: train loss = 0.3169 test loss = 0.4175\n","Iteration 7336: train loss = 0.3169 test loss = 0.4174\n","Iteration 7337: train loss = 0.3168 test loss = 0.4174\n","Iteration 7338: train loss = 0.3168 test loss = 0.4174\n","Iteration 7339: train loss = 0.3168 test loss = 0.4174\n","Iteration 7340: train loss = 0.3168 test loss = 0.4174\n","Iteration 7341: train loss = 0.3167 test loss = 0.4173\n","Iteration 7342: train loss = 0.3167 test loss = 0.4173\n","Iteration 7343: train loss = 0.3167 test loss = 0.4173\n","Iteration 7344: train loss = 0.3166 test loss = 0.4173\n","Iteration 7345: train loss = 0.3166 test loss = 0.4173\n","Iteration 7346: train loss = 0.3166 test loss = 0.4173\n","Iteration 7347: train loss = 0.3166 test loss = 0.4172\n","Iteration 7348: train loss = 0.3165 test loss = 0.4172\n","Iteration 7349: train loss = 0.3165 test loss = 0.4172\n","Iteration 7350: train loss = 0.3165 test loss = 0.4172\n","Iteration 7351: train loss = 0.3165 test loss = 0.4172\n","Iteration 7352: train loss = 0.3164 test loss = 0.4171\n","Iteration 7353: train loss = 0.3164 test loss = 0.4171\n","Iteration 7354: train loss = 0.3164 test loss = 0.4171\n","Iteration 7355: train loss = 0.3163 test loss = 0.4171\n","Iteration 7356: train loss = 0.3163 test loss = 0.4171\n","Iteration 7357: train loss = 0.3163 test loss = 0.4170\n","Iteration 7358: train loss = 0.3163 test loss = 0.4170\n","Iteration 7359: train loss = 0.3162 test loss = 0.4170\n","Iteration 7360: train loss = 0.3162 test loss = 0.4170\n","Iteration 7361: train loss = 0.3162 test loss = 0.4170\n","Iteration 7362: train loss = 0.3161 test loss = 0.4170\n","Iteration 7363: train loss = 0.3161 test loss = 0.4169\n","Iteration 7364: train loss = 0.3161 test loss = 0.4169\n","Iteration 7365: train loss = 0.3161 test loss = 0.4169\n","Iteration 7366: train loss = 0.3160 test loss = 0.4169\n","Iteration 7367: train loss = 0.3160 test loss = 0.4169\n","Iteration 7368: train loss = 0.3160 test loss = 0.4168\n","Iteration 7369: train loss = 0.3159 test loss = 0.4168\n","Iteration 7370: train loss = 0.3159 test loss = 0.4168\n","Iteration 7371: train loss = 0.3159 test loss = 0.4168\n","Iteration 7372: train loss = 0.3159 test loss = 0.4168\n","Iteration 7373: train loss = 0.3158 test loss = 0.4167\n","Iteration 7374: train loss = 0.3158 test loss = 0.4167\n","Iteration 7375: train loss = 0.3158 test loss = 0.4167\n","Iteration 7376: train loss = 0.3158 test loss = 0.4167\n","Iteration 7377: train loss = 0.3157 test loss = 0.4167\n","Iteration 7378: train loss = 0.3157 test loss = 0.4167\n","Iteration 7379: train loss = 0.3157 test loss = 0.4166\n","Iteration 7380: train loss = 0.3156 test loss = 0.4166\n","Iteration 7381: train loss = 0.3156 test loss = 0.4166\n","Iteration 7382: train loss = 0.3156 test loss = 0.4166\n","Iteration 7383: train loss = 0.3156 test loss = 0.4166\n","Iteration 7384: train loss = 0.3155 test loss = 0.4165\n","Iteration 7385: train loss = 0.3155 test loss = 0.4165\n","Iteration 7386: train loss = 0.3155 test loss = 0.4165\n","Iteration 7387: train loss = 0.3154 test loss = 0.4165\n","Iteration 7388: train loss = 0.3154 test loss = 0.4165\n","Iteration 7389: train loss = 0.3154 test loss = 0.4165\n","Iteration 7390: train loss = 0.3154 test loss = 0.4164\n","Iteration 7391: train loss = 0.3153 test loss = 0.4164\n","Iteration 7392: train loss = 0.3153 test loss = 0.4164\n","Iteration 7393: train loss = 0.3153 test loss = 0.4164\n","Iteration 7394: train loss = 0.3152 test loss = 0.4164\n","Iteration 7395: train loss = 0.3152 test loss = 0.4163\n","Iteration 7396: train loss = 0.3152 test loss = 0.4163\n","Iteration 7397: train loss = 0.3152 test loss = 0.4163\n","Iteration 7398: train loss = 0.3151 test loss = 0.4163\n","Iteration 7399: train loss = 0.3151 test loss = 0.4163\n","Iteration 7400: train loss = 0.3151 test loss = 0.4162\n","Iteration 7401: train loss = 0.3151 test loss = 0.4162\n","Iteration 7402: train loss = 0.3150 test loss = 0.4162\n","Iteration 7403: train loss = 0.3150 test loss = 0.4162\n","Iteration 7404: train loss = 0.3150 test loss = 0.4162\n","Iteration 7405: train loss = 0.3149 test loss = 0.4162\n","Iteration 7406: train loss = 0.3149 test loss = 0.4161\n","Iteration 7407: train loss = 0.3149 test loss = 0.4161\n","Iteration 7408: train loss = 0.3149 test loss = 0.4161\n","Iteration 7409: train loss = 0.3148 test loss = 0.4161\n","Iteration 7410: train loss = 0.3148 test loss = 0.4161\n","Iteration 7411: train loss = 0.3148 test loss = 0.4160\n","Iteration 7412: train loss = 0.3147 test loss = 0.4160\n","Iteration 7413: train loss = 0.3147 test loss = 0.4160\n","Iteration 7414: train loss = 0.3147 test loss = 0.4160\n","Iteration 7415: train loss = 0.3147 test loss = 0.4160\n","Iteration 7416: train loss = 0.3146 test loss = 0.4160\n","Iteration 7417: train loss = 0.3146 test loss = 0.4159\n","Iteration 7418: train loss = 0.3146 test loss = 0.4159\n","Iteration 7419: train loss = 0.3145 test loss = 0.4159\n","Iteration 7420: train loss = 0.3145 test loss = 0.4159\n","Iteration 7421: train loss = 0.3145 test loss = 0.4159\n","Iteration 7422: train loss = 0.3145 test loss = 0.4158\n","Iteration 7423: train loss = 0.3144 test loss = 0.4158\n","Iteration 7424: train loss = 0.3144 test loss = 0.4158\n","Iteration 7425: train loss = 0.3144 test loss = 0.4158\n","Iteration 7426: train loss = 0.3144 test loss = 0.4158\n","Iteration 7427: train loss = 0.3143 test loss = 0.4158\n","Iteration 7428: train loss = 0.3143 test loss = 0.4157\n","Iteration 7429: train loss = 0.3143 test loss = 0.4157\n","Iteration 7430: train loss = 0.3142 test loss = 0.4157\n","Iteration 7431: train loss = 0.3142 test loss = 0.4157\n","Iteration 7432: train loss = 0.3142 test loss = 0.4157\n","Iteration 7433: train loss = 0.3142 test loss = 0.4156\n","Iteration 7434: train loss = 0.3141 test loss = 0.4156\n","Iteration 7435: train loss = 0.3141 test loss = 0.4156\n","Iteration 7436: train loss = 0.3141 test loss = 0.4156\n","Iteration 7437: train loss = 0.3140 test loss = 0.4156\n","Iteration 7438: train loss = 0.3140 test loss = 0.4156\n","Iteration 7439: train loss = 0.3140 test loss = 0.4155\n","Iteration 7440: train loss = 0.3140 test loss = 0.4155\n","Iteration 7441: train loss = 0.3139 test loss = 0.4155\n","Iteration 7442: train loss = 0.3139 test loss = 0.4155\n","Iteration 7443: train loss = 0.3139 test loss = 0.4155\n","Iteration 7444: train loss = 0.3139 test loss = 0.4154\n","Iteration 7445: train loss = 0.3138 test loss = 0.4154\n","Iteration 7446: train loss = 0.3138 test loss = 0.4154\n","Iteration 7447: train loss = 0.3138 test loss = 0.4154\n","Iteration 7448: train loss = 0.3137 test loss = 0.4154\n","Iteration 7449: train loss = 0.3137 test loss = 0.4153\n","Iteration 7450: train loss = 0.3137 test loss = 0.4153\n","Iteration 7451: train loss = 0.3137 test loss = 0.4153\n","Iteration 7452: train loss = 0.3136 test loss = 0.4153\n","Iteration 7453: train loss = 0.3136 test loss = 0.4153\n","Iteration 7454: train loss = 0.3136 test loss = 0.4153\n","Iteration 7455: train loss = 0.3135 test loss = 0.4152\n","Iteration 7456: train loss = 0.3135 test loss = 0.4152\n","Iteration 7457: train loss = 0.3135 test loss = 0.4152\n","Iteration 7458: train loss = 0.3135 test loss = 0.4152\n","Iteration 7459: train loss = 0.3134 test loss = 0.4152\n","Iteration 7460: train loss = 0.3134 test loss = 0.4151\n","Iteration 7461: train loss = 0.3134 test loss = 0.4151\n","Iteration 7462: train loss = 0.3134 test loss = 0.4151\n","Iteration 7463: train loss = 0.3133 test loss = 0.4151\n","Iteration 7464: train loss = 0.3133 test loss = 0.4151\n","Iteration 7465: train loss = 0.3133 test loss = 0.4151\n","Iteration 7466: train loss = 0.3132 test loss = 0.4150\n","Iteration 7467: train loss = 0.3132 test loss = 0.4150\n","Iteration 7468: train loss = 0.3132 test loss = 0.4150\n","Iteration 7469: train loss = 0.3132 test loss = 0.4150\n","Iteration 7470: train loss = 0.3131 test loss = 0.4150\n","Iteration 7471: train loss = 0.3131 test loss = 0.4149\n","Iteration 7472: train loss = 0.3131 test loss = 0.4149\n","Iteration 7473: train loss = 0.3131 test loss = 0.4149\n","Iteration 7474: train loss = 0.3130 test loss = 0.4149\n","Iteration 7475: train loss = 0.3130 test loss = 0.4149\n","Iteration 7476: train loss = 0.3130 test loss = 0.4149\n","Iteration 7477: train loss = 0.3129 test loss = 0.4148\n","Iteration 7478: train loss = 0.3129 test loss = 0.4148\n","Iteration 7479: train loss = 0.3129 test loss = 0.4148\n","Iteration 7480: train loss = 0.3129 test loss = 0.4148\n","Iteration 7481: train loss = 0.3128 test loss = 0.4148\n","Iteration 7482: train loss = 0.3128 test loss = 0.4147\n","Iteration 7483: train loss = 0.3128 test loss = 0.4147\n","Iteration 7484: train loss = 0.3127 test loss = 0.4147\n","Iteration 7485: train loss = 0.3127 test loss = 0.4147\n","Iteration 7486: train loss = 0.3127 test loss = 0.4147\n","Iteration 7487: train loss = 0.3127 test loss = 0.4147\n","Iteration 7488: train loss = 0.3126 test loss = 0.4146\n","Iteration 7489: train loss = 0.3126 test loss = 0.4146\n","Iteration 7490: train loss = 0.3126 test loss = 0.4146\n","Iteration 7491: train loss = 0.3126 test loss = 0.4146\n","Iteration 7492: train loss = 0.3125 test loss = 0.4146\n","Iteration 7493: train loss = 0.3125 test loss = 0.4145\n","Iteration 7494: train loss = 0.3125 test loss = 0.4145\n","Iteration 7495: train loss = 0.3124 test loss = 0.4145\n","Iteration 7496: train loss = 0.3124 test loss = 0.4145\n","Iteration 7497: train loss = 0.3124 test loss = 0.4145\n","Iteration 7498: train loss = 0.3124 test loss = 0.4145\n","Iteration 7499: train loss = 0.3123 test loss = 0.4144\n","Iteration 7500: train loss = 0.3123 test loss = 0.4144\n","Iteration 7501: train loss = 0.3123 test loss = 0.4144\n","Iteration 7502: train loss = 0.3122 test loss = 0.4144\n","Iteration 7503: train loss = 0.3122 test loss = 0.4144\n","Iteration 7504: train loss = 0.3122 test loss = 0.4143\n","Iteration 7505: train loss = 0.3122 test loss = 0.4143\n","Iteration 7506: train loss = 0.3121 test loss = 0.4143\n","Iteration 7507: train loss = 0.3121 test loss = 0.4143\n","Iteration 7508: train loss = 0.3121 test loss = 0.4143\n","Iteration 7509: train loss = 0.3121 test loss = 0.4143\n","Iteration 7510: train loss = 0.3120 test loss = 0.4142\n","Iteration 7511: train loss = 0.3120 test loss = 0.4142\n","Iteration 7512: train loss = 0.3120 test loss = 0.4142\n","Iteration 7513: train loss = 0.3119 test loss = 0.4142\n","Iteration 7514: train loss = 0.3119 test loss = 0.4142\n","Iteration 7515: train loss = 0.3119 test loss = 0.4141\n","Iteration 7516: train loss = 0.3119 test loss = 0.4141\n","Iteration 7517: train loss = 0.3118 test loss = 0.4141\n","Iteration 7518: train loss = 0.3118 test loss = 0.4141\n","Iteration 7519: train loss = 0.3118 test loss = 0.4141\n","Iteration 7520: train loss = 0.3118 test loss = 0.4141\n","Iteration 7521: train loss = 0.3117 test loss = 0.4140\n","Iteration 7522: train loss = 0.3117 test loss = 0.4140\n","Iteration 7523: train loss = 0.3117 test loss = 0.4140\n","Iteration 7524: train loss = 0.3116 test loss = 0.4140\n","Iteration 7525: train loss = 0.3116 test loss = 0.4140\n","Iteration 7526: train loss = 0.3116 test loss = 0.4139\n","Iteration 7527: train loss = 0.3116 test loss = 0.4139\n","Iteration 7528: train loss = 0.3115 test loss = 0.4139\n","Iteration 7529: train loss = 0.3115 test loss = 0.4139\n","Iteration 7530: train loss = 0.3115 test loss = 0.4139\n","Iteration 7531: train loss = 0.3115 test loss = 0.4139\n","Iteration 7532: train loss = 0.3114 test loss = 0.4138\n","Iteration 7533: train loss = 0.3114 test loss = 0.4138\n","Iteration 7534: train loss = 0.3114 test loss = 0.4138\n","Iteration 7535: train loss = 0.3113 test loss = 0.4138\n","Iteration 7536: train loss = 0.3113 test loss = 0.4138\n","Iteration 7537: train loss = 0.3113 test loss = 0.4137\n","Iteration 7538: train loss = 0.3113 test loss = 0.4137\n","Iteration 7539: train loss = 0.3112 test loss = 0.4137\n","Iteration 7540: train loss = 0.3112 test loss = 0.4137\n","Iteration 7541: train loss = 0.3112 test loss = 0.4137\n","Iteration 7542: train loss = 0.3111 test loss = 0.4137\n","Iteration 7543: train loss = 0.3111 test loss = 0.4136\n","Iteration 7544: train loss = 0.3111 test loss = 0.4136\n","Iteration 7545: train loss = 0.3111 test loss = 0.4136\n","Iteration 7546: train loss = 0.3110 test loss = 0.4136\n","Iteration 7547: train loss = 0.3110 test loss = 0.4136\n","Iteration 7548: train loss = 0.3110 test loss = 0.4136\n","Iteration 7549: train loss = 0.3110 test loss = 0.4135\n","Iteration 7550: train loss = 0.3109 test loss = 0.4135\n","Iteration 7551: train loss = 0.3109 test loss = 0.4135\n","Iteration 7552: train loss = 0.3109 test loss = 0.4135\n","Iteration 7553: train loss = 0.3108 test loss = 0.4135\n","Iteration 7554: train loss = 0.3108 test loss = 0.4134\n","Iteration 7555: train loss = 0.3108 test loss = 0.4134\n","Iteration 7556: train loss = 0.3108 test loss = 0.4134\n","Iteration 7557: train loss = 0.3107 test loss = 0.4134\n","Iteration 7558: train loss = 0.3107 test loss = 0.4134\n","Iteration 7559: train loss = 0.3107 test loss = 0.4134\n","Iteration 7560: train loss = 0.3107 test loss = 0.4133\n","Iteration 7561: train loss = 0.3106 test loss = 0.4133\n","Iteration 7562: train loss = 0.3106 test loss = 0.4133\n","Iteration 7563: train loss = 0.3106 test loss = 0.4133\n","Iteration 7564: train loss = 0.3105 test loss = 0.4133\n","Iteration 7565: train loss = 0.3105 test loss = 0.4132\n","Iteration 7566: train loss = 0.3105 test loss = 0.4132\n","Iteration 7567: train loss = 0.3105 test loss = 0.4132\n","Iteration 7568: train loss = 0.3104 test loss = 0.4132\n","Iteration 7569: train loss = 0.3104 test loss = 0.4132\n","Iteration 7570: train loss = 0.3104 test loss = 0.4132\n","Iteration 7571: train loss = 0.3104 test loss = 0.4131\n","Iteration 7572: train loss = 0.3103 test loss = 0.4131\n","Iteration 7573: train loss = 0.3103 test loss = 0.4131\n","Iteration 7574: train loss = 0.3103 test loss = 0.4131\n","Iteration 7575: train loss = 0.3102 test loss = 0.4131\n","Iteration 7576: train loss = 0.3102 test loss = 0.4130\n","Iteration 7577: train loss = 0.3102 test loss = 0.4130\n","Iteration 7578: train loss = 0.3102 test loss = 0.4130\n","Iteration 7579: train loss = 0.3101 test loss = 0.4130\n","Iteration 7580: train loss = 0.3101 test loss = 0.4130\n","Iteration 7581: train loss = 0.3101 test loss = 0.4130\n","Iteration 7582: train loss = 0.3101 test loss = 0.4129\n","Iteration 7583: train loss = 0.3100 test loss = 0.4129\n","Iteration 7584: train loss = 0.3100 test loss = 0.4129\n","Iteration 7585: train loss = 0.3100 test loss = 0.4129\n","Iteration 7586: train loss = 0.3099 test loss = 0.4129\n","Iteration 7587: train loss = 0.3099 test loss = 0.4128\n","Iteration 7588: train loss = 0.3099 test loss = 0.4128\n","Iteration 7589: train loss = 0.3099 test loss = 0.4128\n","Iteration 7590: train loss = 0.3098 test loss = 0.4128\n","Iteration 7591: train loss = 0.3098 test loss = 0.4128\n","Iteration 7592: train loss = 0.3098 test loss = 0.4128\n","Iteration 7593: train loss = 0.3098 test loss = 0.4127\n","Iteration 7594: train loss = 0.3097 test loss = 0.4127\n","Iteration 7595: train loss = 0.3097 test loss = 0.4127\n","Iteration 7596: train loss = 0.3097 test loss = 0.4127\n","Iteration 7597: train loss = 0.3096 test loss = 0.4127\n","Iteration 7598: train loss = 0.3096 test loss = 0.4127\n","Iteration 7599: train loss = 0.3096 test loss = 0.4126\n","Iteration 7600: train loss = 0.3096 test loss = 0.4126\n","Iteration 7601: train loss = 0.3095 test loss = 0.4126\n","Iteration 7602: train loss = 0.3095 test loss = 0.4126\n","Iteration 7603: train loss = 0.3095 test loss = 0.4126\n","Iteration 7604: train loss = 0.3095 test loss = 0.4125\n","Iteration 7605: train loss = 0.3094 test loss = 0.4125\n","Iteration 7606: train loss = 0.3094 test loss = 0.4125\n","Iteration 7607: train loss = 0.3094 test loss = 0.4125\n","Iteration 7608: train loss = 0.3093 test loss = 0.4125\n","Iteration 7609: train loss = 0.3093 test loss = 0.4125\n","Iteration 7610: train loss = 0.3093 test loss = 0.4124\n","Iteration 7611: train loss = 0.3093 test loss = 0.4124\n","Iteration 7612: train loss = 0.3092 test loss = 0.4124\n","Iteration 7613: train loss = 0.3092 test loss = 0.4124\n","Iteration 7614: train loss = 0.3092 test loss = 0.4124\n","Iteration 7615: train loss = 0.3092 test loss = 0.4123\n","Iteration 7616: train loss = 0.3091 test loss = 0.4123\n","Iteration 7617: train loss = 0.3091 test loss = 0.4123\n","Iteration 7618: train loss = 0.3091 test loss = 0.4123\n","Iteration 7619: train loss = 0.3090 test loss = 0.4123\n","Iteration 7620: train loss = 0.3090 test loss = 0.4123\n","Iteration 7621: train loss = 0.3090 test loss = 0.4122\n","Iteration 7622: train loss = 0.3090 test loss = 0.4122\n","Iteration 7623: train loss = 0.3089 test loss = 0.4122\n","Iteration 7624: train loss = 0.3089 test loss = 0.4122\n","Iteration 7625: train loss = 0.3089 test loss = 0.4122\n","Iteration 7626: train loss = 0.3089 test loss = 0.4122\n","Iteration 7627: train loss = 0.3088 test loss = 0.4121\n","Iteration 7628: train loss = 0.3088 test loss = 0.4121\n","Iteration 7629: train loss = 0.3088 test loss = 0.4121\n","Iteration 7630: train loss = 0.3087 test loss = 0.4121\n","Iteration 7631: train loss = 0.3087 test loss = 0.4121\n","Iteration 7632: train loss = 0.3087 test loss = 0.4120\n","Iteration 7633: train loss = 0.3087 test loss = 0.4120\n","Iteration 7634: train loss = 0.3086 test loss = 0.4120\n","Iteration 7635: train loss = 0.3086 test loss = 0.4120\n","Iteration 7636: train loss = 0.3086 test loss = 0.4120\n","Iteration 7637: train loss = 0.3086 test loss = 0.4120\n","Iteration 7638: train loss = 0.3085 test loss = 0.4119\n","Iteration 7639: train loss = 0.3085 test loss = 0.4119\n","Iteration 7640: train loss = 0.3085 test loss = 0.4119\n","Iteration 7641: train loss = 0.3084 test loss = 0.4119\n","Iteration 7642: train loss = 0.3084 test loss = 0.4119\n","Iteration 7643: train loss = 0.3084 test loss = 0.4119\n","Iteration 7644: train loss = 0.3084 test loss = 0.4118\n","Iteration 7645: train loss = 0.3083 test loss = 0.4118\n","Iteration 7646: train loss = 0.3083 test loss = 0.4118\n","Iteration 7647: train loss = 0.3083 test loss = 0.4118\n","Iteration 7648: train loss = 0.3083 test loss = 0.4118\n","Iteration 7649: train loss = 0.3082 test loss = 0.4117\n","Iteration 7650: train loss = 0.3082 test loss = 0.4117\n","Iteration 7651: train loss = 0.3082 test loss = 0.4117\n","Iteration 7652: train loss = 0.3082 test loss = 0.4117\n","Iteration 7653: train loss = 0.3081 test loss = 0.4117\n","Iteration 7654: train loss = 0.3081 test loss = 0.4117\n","Iteration 7655: train loss = 0.3081 test loss = 0.4116\n","Iteration 7656: train loss = 0.3080 test loss = 0.4116\n","Iteration 7657: train loss = 0.3080 test loss = 0.4116\n","Iteration 7658: train loss = 0.3080 test loss = 0.4116\n","Iteration 7659: train loss = 0.3080 test loss = 0.4116\n","Iteration 7660: train loss = 0.3079 test loss = 0.4115\n","Iteration 7661: train loss = 0.3079 test loss = 0.4115\n","Iteration 7662: train loss = 0.3079 test loss = 0.4115\n","Iteration 7663: train loss = 0.3079 test loss = 0.4115\n","Iteration 7664: train loss = 0.3078 test loss = 0.4115\n","Iteration 7665: train loss = 0.3078 test loss = 0.4115\n","Iteration 7666: train loss = 0.3078 test loss = 0.4114\n","Iteration 7667: train loss = 0.3077 test loss = 0.4114\n","Iteration 7668: train loss = 0.3077 test loss = 0.4114\n","Iteration 7669: train loss = 0.3077 test loss = 0.4114\n","Iteration 7670: train loss = 0.3077 test loss = 0.4114\n","Iteration 7671: train loss = 0.3076 test loss = 0.4114\n","Iteration 7672: train loss = 0.3076 test loss = 0.4113\n","Iteration 7673: train loss = 0.3076 test loss = 0.4113\n","Iteration 7674: train loss = 0.3076 test loss = 0.4113\n","Iteration 7675: train loss = 0.3075 test loss = 0.4113\n","Iteration 7676: train loss = 0.3075 test loss = 0.4113\n","Iteration 7677: train loss = 0.3075 test loss = 0.4112\n","Iteration 7678: train loss = 0.3074 test loss = 0.4112\n","Iteration 7679: train loss = 0.3074 test loss = 0.4112\n","Iteration 7680: train loss = 0.3074 test loss = 0.4112\n","Iteration 7681: train loss = 0.3074 test loss = 0.4112\n","Iteration 7682: train loss = 0.3073 test loss = 0.4112\n","Iteration 7683: train loss = 0.3073 test loss = 0.4111\n","Iteration 7684: train loss = 0.3073 test loss = 0.4111\n","Iteration 7685: train loss = 0.3073 test loss = 0.4111\n","Iteration 7686: train loss = 0.3072 test loss = 0.4111\n","Iteration 7687: train loss = 0.3072 test loss = 0.4111\n","Iteration 7688: train loss = 0.3072 test loss = 0.4111\n","Iteration 7689: train loss = 0.3072 test loss = 0.4110\n","Iteration 7690: train loss = 0.3071 test loss = 0.4110\n","Iteration 7691: train loss = 0.3071 test loss = 0.4110\n","Iteration 7692: train loss = 0.3071 test loss = 0.4110\n","Iteration 7693: train loss = 0.3070 test loss = 0.4110\n","Iteration 7694: train loss = 0.3070 test loss = 0.4109\n","Iteration 7695: train loss = 0.3070 test loss = 0.4109\n","Iteration 7696: train loss = 0.3070 test loss = 0.4109\n","Iteration 7697: train loss = 0.3069 test loss = 0.4109\n","Iteration 7698: train loss = 0.3069 test loss = 0.4109\n","Iteration 7699: train loss = 0.3069 test loss = 0.4109\n","Iteration 7700: train loss = 0.3069 test loss = 0.4108\n","Iteration 7701: train loss = 0.3068 test loss = 0.4108\n","Iteration 7702: train loss = 0.3068 test loss = 0.4108\n","Iteration 7703: train loss = 0.3068 test loss = 0.4108\n","Iteration 7704: train loss = 0.3067 test loss = 0.4108\n","Iteration 7705: train loss = 0.3067 test loss = 0.4108\n","Iteration 7706: train loss = 0.3067 test loss = 0.4107\n","Iteration 7707: train loss = 0.3067 test loss = 0.4107\n","Iteration 7708: train loss = 0.3066 test loss = 0.4107\n","Iteration 7709: train loss = 0.3066 test loss = 0.4107\n","Iteration 7710: train loss = 0.3066 test loss = 0.4107\n","Iteration 7711: train loss = 0.3066 test loss = 0.4106\n","Iteration 7712: train loss = 0.3065 test loss = 0.4106\n","Iteration 7713: train loss = 0.3065 test loss = 0.4106\n","Iteration 7714: train loss = 0.3065 test loss = 0.4106\n","Iteration 7715: train loss = 0.3065 test loss = 0.4106\n","Iteration 7716: train loss = 0.3064 test loss = 0.4106\n","Iteration 7717: train loss = 0.3064 test loss = 0.4105\n","Iteration 7718: train loss = 0.3064 test loss = 0.4105\n","Iteration 7719: train loss = 0.3063 test loss = 0.4105\n","Iteration 7720: train loss = 0.3063 test loss = 0.4105\n","Iteration 7721: train loss = 0.3063 test loss = 0.4105\n","Iteration 7722: train loss = 0.3063 test loss = 0.4105\n","Iteration 7723: train loss = 0.3062 test loss = 0.4104\n","Iteration 7724: train loss = 0.3062 test loss = 0.4104\n","Iteration 7725: train loss = 0.3062 test loss = 0.4104\n","Iteration 7726: train loss = 0.3062 test loss = 0.4104\n","Iteration 7727: train loss = 0.3061 test loss = 0.4104\n","Iteration 7728: train loss = 0.3061 test loss = 0.4104\n","Iteration 7729: train loss = 0.3061 test loss = 0.4103\n","Iteration 7730: train loss = 0.3060 test loss = 0.4103\n","Iteration 7731: train loss = 0.3060 test loss = 0.4103\n","Iteration 7732: train loss = 0.3060 test loss = 0.4103\n","Iteration 7733: train loss = 0.3060 test loss = 0.4103\n","Iteration 7734: train loss = 0.3059 test loss = 0.4102\n","Iteration 7735: train loss = 0.3059 test loss = 0.4102\n","Iteration 7736: train loss = 0.3059 test loss = 0.4102\n","Iteration 7737: train loss = 0.3059 test loss = 0.4102\n","Iteration 7738: train loss = 0.3058 test loss = 0.4102\n","Iteration 7739: train loss = 0.3058 test loss = 0.4102\n","Iteration 7740: train loss = 0.3058 test loss = 0.4101\n","Iteration 7741: train loss = 0.3058 test loss = 0.4101\n","Iteration 7742: train loss = 0.3057 test loss = 0.4101\n","Iteration 7743: train loss = 0.3057 test loss = 0.4101\n","Iteration 7744: train loss = 0.3057 test loss = 0.4101\n","Iteration 7745: train loss = 0.3056 test loss = 0.4101\n","Iteration 7746: train loss = 0.3056 test loss = 0.4100\n","Iteration 7747: train loss = 0.3056 test loss = 0.4100\n","Iteration 7748: train loss = 0.3056 test loss = 0.4100\n","Iteration 7749: train loss = 0.3055 test loss = 0.4100\n","Iteration 7750: train loss = 0.3055 test loss = 0.4100\n","Iteration 7751: train loss = 0.3055 test loss = 0.4099\n","Iteration 7752: train loss = 0.3055 test loss = 0.4099\n","Iteration 7753: train loss = 0.3054 test loss = 0.4099\n","Iteration 7754: train loss = 0.3054 test loss = 0.4099\n","Iteration 7755: train loss = 0.3054 test loss = 0.4099\n","Iteration 7756: train loss = 0.3054 test loss = 0.4099\n","Iteration 7757: train loss = 0.3053 test loss = 0.4098\n","Iteration 7758: train loss = 0.3053 test loss = 0.4098\n","Iteration 7759: train loss = 0.3053 test loss = 0.4098\n","Iteration 7760: train loss = 0.3052 test loss = 0.4098\n","Iteration 7761: train loss = 0.3052 test loss = 0.4098\n","Iteration 7762: train loss = 0.3052 test loss = 0.4098\n","Iteration 7763: train loss = 0.3052 test loss = 0.4097\n","Iteration 7764: train loss = 0.3051 test loss = 0.4097\n","Iteration 7765: train loss = 0.3051 test loss = 0.4097\n","Iteration 7766: train loss = 0.3051 test loss = 0.4097\n","Iteration 7767: train loss = 0.3051 test loss = 0.4097\n","Iteration 7768: train loss = 0.3050 test loss = 0.4097\n","Iteration 7769: train loss = 0.3050 test loss = 0.4096\n","Iteration 7770: train loss = 0.3050 test loss = 0.4096\n","Iteration 7771: train loss = 0.3050 test loss = 0.4096\n","Iteration 7772: train loss = 0.3049 test loss = 0.4096\n","Iteration 7773: train loss = 0.3049 test loss = 0.4096\n","Iteration 7774: train loss = 0.3049 test loss = 0.4095\n","Iteration 7775: train loss = 0.3048 test loss = 0.4095\n","Iteration 7776: train loss = 0.3048 test loss = 0.4095\n","Iteration 7777: train loss = 0.3048 test loss = 0.4095\n","Iteration 7778: train loss = 0.3048 test loss = 0.4095\n","Iteration 7779: train loss = 0.3047 test loss = 0.4095\n","Iteration 7780: train loss = 0.3047 test loss = 0.4094\n","Iteration 7781: train loss = 0.3047 test loss = 0.4094\n","Iteration 7782: train loss = 0.3047 test loss = 0.4094\n","Iteration 7783: train loss = 0.3046 test loss = 0.4094\n","Iteration 7784: train loss = 0.3046 test loss = 0.4094\n","Iteration 7785: train loss = 0.3046 test loss = 0.4094\n","Iteration 7786: train loss = 0.3046 test loss = 0.4093\n","Iteration 7787: train loss = 0.3045 test loss = 0.4093\n","Iteration 7788: train loss = 0.3045 test loss = 0.4093\n","Iteration 7789: train loss = 0.3045 test loss = 0.4093\n","Iteration 7790: train loss = 0.3044 test loss = 0.4093\n","Iteration 7791: train loss = 0.3044 test loss = 0.4093\n","Iteration 7792: train loss = 0.3044 test loss = 0.4092\n","Iteration 7793: train loss = 0.3044 test loss = 0.4092\n","Iteration 7794: train loss = 0.3043 test loss = 0.4092\n","Iteration 7795: train loss = 0.3043 test loss = 0.4092\n","Iteration 7796: train loss = 0.3043 test loss = 0.4092\n","Iteration 7797: train loss = 0.3043 test loss = 0.4091\n","Iteration 7798: train loss = 0.3042 test loss = 0.4091\n","Iteration 7799: train loss = 0.3042 test loss = 0.4091\n","Iteration 7800: train loss = 0.3042 test loss = 0.4091\n","Iteration 7801: train loss = 0.3042 test loss = 0.4091\n","Iteration 7802: train loss = 0.3041 test loss = 0.4091\n","Iteration 7803: train loss = 0.3041 test loss = 0.4090\n","Iteration 7804: train loss = 0.3041 test loss = 0.4090\n","Iteration 7805: train loss = 0.3040 test loss = 0.4090\n","Iteration 7806: train loss = 0.3040 test loss = 0.4090\n","Iteration 7807: train loss = 0.3040 test loss = 0.4090\n","Iteration 7808: train loss = 0.3040 test loss = 0.4090\n","Iteration 7809: train loss = 0.3039 test loss = 0.4089\n","Iteration 7810: train loss = 0.3039 test loss = 0.4089\n","Iteration 7811: train loss = 0.3039 test loss = 0.4089\n","Iteration 7812: train loss = 0.3039 test loss = 0.4089\n","Iteration 7813: train loss = 0.3038 test loss = 0.4089\n","Iteration 7814: train loss = 0.3038 test loss = 0.4089\n","Iteration 7815: train loss = 0.3038 test loss = 0.4088\n","Iteration 7816: train loss = 0.3038 test loss = 0.4088\n","Iteration 7817: train loss = 0.3037 test loss = 0.4088\n","Iteration 7818: train loss = 0.3037 test loss = 0.4088\n","Iteration 7819: train loss = 0.3037 test loss = 0.4088\n","Iteration 7820: train loss = 0.3036 test loss = 0.4088\n","Iteration 7821: train loss = 0.3036 test loss = 0.4087\n","Iteration 7822: train loss = 0.3036 test loss = 0.4087\n","Iteration 7823: train loss = 0.3036 test loss = 0.4087\n","Iteration 7824: train loss = 0.3035 test loss = 0.4087\n","Iteration 7825: train loss = 0.3035 test loss = 0.4087\n","Iteration 7826: train loss = 0.3035 test loss = 0.4086\n","Iteration 7827: train loss = 0.3035 test loss = 0.4086\n","Iteration 7828: train loss = 0.3034 test loss = 0.4086\n","Iteration 7829: train loss = 0.3034 test loss = 0.4086\n","Iteration 7830: train loss = 0.3034 test loss = 0.4086\n","Iteration 7831: train loss = 0.3034 test loss = 0.4086\n","Iteration 7832: train loss = 0.3033 test loss = 0.4085\n","Iteration 7833: train loss = 0.3033 test loss = 0.4085\n","Iteration 7834: train loss = 0.3033 test loss = 0.4085\n","Iteration 7835: train loss = 0.3033 test loss = 0.4085\n","Iteration 7836: train loss = 0.3032 test loss = 0.4085\n","Iteration 7837: train loss = 0.3032 test loss = 0.4085\n","Iteration 7838: train loss = 0.3032 test loss = 0.4084\n","Iteration 7839: train loss = 0.3031 test loss = 0.4084\n","Iteration 7840: train loss = 0.3031 test loss = 0.4084\n","Iteration 7841: train loss = 0.3031 test loss = 0.4084\n","Iteration 7842: train loss = 0.3031 test loss = 0.4084\n","Iteration 7843: train loss = 0.3030 test loss = 0.4084\n","Iteration 7844: train loss = 0.3030 test loss = 0.4083\n","Iteration 7845: train loss = 0.3030 test loss = 0.4083\n","Iteration 7846: train loss = 0.3030 test loss = 0.4083\n","Iteration 7847: train loss = 0.3029 test loss = 0.4083\n","Iteration 7848: train loss = 0.3029 test loss = 0.4083\n","Iteration 7849: train loss = 0.3029 test loss = 0.4083\n","Iteration 7850: train loss = 0.3029 test loss = 0.4082\n","Iteration 7851: train loss = 0.3028 test loss = 0.4082\n","Iteration 7852: train loss = 0.3028 test loss = 0.4082\n","Iteration 7853: train loss = 0.3028 test loss = 0.4082\n","Iteration 7854: train loss = 0.3027 test loss = 0.4082\n","Iteration 7855: train loss = 0.3027 test loss = 0.4081\n","Iteration 7856: train loss = 0.3027 test loss = 0.4081\n","Iteration 7857: train loss = 0.3027 test loss = 0.4081\n","Iteration 7858: train loss = 0.3026 test loss = 0.4081\n","Iteration 7859: train loss = 0.3026 test loss = 0.4081\n","Iteration 7860: train loss = 0.3026 test loss = 0.4081\n","Iteration 7861: train loss = 0.3026 test loss = 0.4080\n","Iteration 7862: train loss = 0.3025 test loss = 0.4080\n","Iteration 7863: train loss = 0.3025 test loss = 0.4080\n","Iteration 7864: train loss = 0.3025 test loss = 0.4080\n","Iteration 7865: train loss = 0.3025 test loss = 0.4080\n","Iteration 7866: train loss = 0.3024 test loss = 0.4080\n","Iteration 7867: train loss = 0.3024 test loss = 0.4079\n","Iteration 7868: train loss = 0.3024 test loss = 0.4079\n","Iteration 7869: train loss = 0.3024 test loss = 0.4079\n","Iteration 7870: train loss = 0.3023 test loss = 0.4079\n","Iteration 7871: train loss = 0.3023 test loss = 0.4079\n","Iteration 7872: train loss = 0.3023 test loss = 0.4079\n","Iteration 7873: train loss = 0.3022 test loss = 0.4078\n","Iteration 7874: train loss = 0.3022 test loss = 0.4078\n","Iteration 7875: train loss = 0.3022 test loss = 0.4078\n","Iteration 7876: train loss = 0.3022 test loss = 0.4078\n","Iteration 7877: train loss = 0.3021 test loss = 0.4078\n","Iteration 7878: train loss = 0.3021 test loss = 0.4078\n","Iteration 7879: train loss = 0.3021 test loss = 0.4077\n","Iteration 7880: train loss = 0.3021 test loss = 0.4077\n","Iteration 7881: train loss = 0.3020 test loss = 0.4077\n","Iteration 7882: train loss = 0.3020 test loss = 0.4077\n","Iteration 7883: train loss = 0.3020 test loss = 0.4077\n","Iteration 7884: train loss = 0.3020 test loss = 0.4077\n","Iteration 7885: train loss = 0.3019 test loss = 0.4076\n","Iteration 7886: train loss = 0.3019 test loss = 0.4076\n","Iteration 7887: train loss = 0.3019 test loss = 0.4076\n","Iteration 7888: train loss = 0.3019 test loss = 0.4076\n","Iteration 7889: train loss = 0.3018 test loss = 0.4076\n","Iteration 7890: train loss = 0.3018 test loss = 0.4075\n","Iteration 7891: train loss = 0.3018 test loss = 0.4075\n","Iteration 7892: train loss = 0.3017 test loss = 0.4075\n","Iteration 7893: train loss = 0.3017 test loss = 0.4075\n","Iteration 7894: train loss = 0.3017 test loss = 0.4075\n","Iteration 7895: train loss = 0.3017 test loss = 0.4075\n","Iteration 7896: train loss = 0.3016 test loss = 0.4074\n","Iteration 7897: train loss = 0.3016 test loss = 0.4074\n","Iteration 7898: train loss = 0.3016 test loss = 0.4074\n","Iteration 7899: train loss = 0.3016 test loss = 0.4074\n","Iteration 7900: train loss = 0.3015 test loss = 0.4074\n","Iteration 7901: train loss = 0.3015 test loss = 0.4074\n","Iteration 7902: train loss = 0.3015 test loss = 0.4073\n","Iteration 7903: train loss = 0.3015 test loss = 0.4073\n","Iteration 7904: train loss = 0.3014 test loss = 0.4073\n","Iteration 7905: train loss = 0.3014 test loss = 0.4073\n","Iteration 7906: train loss = 0.3014 test loss = 0.4073\n","Iteration 7907: train loss = 0.3014 test loss = 0.4073\n","Iteration 7908: train loss = 0.3013 test loss = 0.4072\n","Iteration 7909: train loss = 0.3013 test loss = 0.4072\n","Iteration 7910: train loss = 0.3013 test loss = 0.4072\n","Iteration 7911: train loss = 0.3012 test loss = 0.4072\n","Iteration 7912: train loss = 0.3012 test loss = 0.4072\n","Iteration 7913: train loss = 0.3012 test loss = 0.4072\n","Iteration 7914: train loss = 0.3012 test loss = 0.4071\n","Iteration 7915: train loss = 0.3011 test loss = 0.4071\n","Iteration 7916: train loss = 0.3011 test loss = 0.4071\n","Iteration 7917: train loss = 0.3011 test loss = 0.4071\n","Iteration 7918: train loss = 0.3011 test loss = 0.4071\n","Iteration 7919: train loss = 0.3010 test loss = 0.4071\n","Iteration 7920: train loss = 0.3010 test loss = 0.4070\n","Iteration 7921: train loss = 0.3010 test loss = 0.4070\n","Iteration 7922: train loss = 0.3010 test loss = 0.4070\n","Iteration 7923: train loss = 0.3009 test loss = 0.4070\n","Iteration 7924: train loss = 0.3009 test loss = 0.4070\n","Iteration 7925: train loss = 0.3009 test loss = 0.4070\n","Iteration 7926: train loss = 0.3009 test loss = 0.4069\n","Iteration 7927: train loss = 0.3008 test loss = 0.4069\n","Iteration 7928: train loss = 0.3008 test loss = 0.4069\n","Iteration 7929: train loss = 0.3008 test loss = 0.4069\n","Iteration 7930: train loss = 0.3008 test loss = 0.4069\n","Iteration 7931: train loss = 0.3007 test loss = 0.4069\n","Iteration 7932: train loss = 0.3007 test loss = 0.4068\n","Iteration 7933: train loss = 0.3007 test loss = 0.4068\n","Iteration 7934: train loss = 0.3006 test loss = 0.4068\n","Iteration 7935: train loss = 0.3006 test loss = 0.4068\n","Iteration 7936: train loss = 0.3006 test loss = 0.4068\n","Iteration 7937: train loss = 0.3006 test loss = 0.4067\n","Iteration 7938: train loss = 0.3005 test loss = 0.4067\n","Iteration 7939: train loss = 0.3005 test loss = 0.4067\n","Iteration 7940: train loss = 0.3005 test loss = 0.4067\n","Iteration 7941: train loss = 0.3005 test loss = 0.4067\n","Iteration 7942: train loss = 0.3004 test loss = 0.4067\n","Iteration 7943: train loss = 0.3004 test loss = 0.4066\n","Iteration 7944: train loss = 0.3004 test loss = 0.4066\n","Iteration 7945: train loss = 0.3004 test loss = 0.4066\n","Iteration 7946: train loss = 0.3003 test loss = 0.4066\n","Iteration 7947: train loss = 0.3003 test loss = 0.4066\n","Iteration 7948: train loss = 0.3003 test loss = 0.4066\n","Iteration 7949: train loss = 0.3003 test loss = 0.4065\n","Iteration 7950: train loss = 0.3002 test loss = 0.4065\n","Iteration 7951: train loss = 0.3002 test loss = 0.4065\n","Iteration 7952: train loss = 0.3002 test loss = 0.4065\n","Iteration 7953: train loss = 0.3001 test loss = 0.4065\n","Iteration 7954: train loss = 0.3001 test loss = 0.4065\n","Iteration 7955: train loss = 0.3001 test loss = 0.4064\n","Iteration 7956: train loss = 0.3001 test loss = 0.4064\n","Iteration 7957: train loss = 0.3000 test loss = 0.4064\n","Iteration 7958: train loss = 0.3000 test loss = 0.4064\n","Iteration 7959: train loss = 0.3000 test loss = 0.4064\n","Iteration 7960: train loss = 0.3000 test loss = 0.4064\n","Iteration 7961: train loss = 0.2999 test loss = 0.4063\n","Iteration 7962: train loss = 0.2999 test loss = 0.4063\n","Iteration 7963: train loss = 0.2999 test loss = 0.4063\n","Iteration 7964: train loss = 0.2999 test loss = 0.4063\n","Iteration 7965: train loss = 0.2998 test loss = 0.4063\n","Iteration 7966: train loss = 0.2998 test loss = 0.4063\n","Iteration 7967: train loss = 0.2998 test loss = 0.4062\n","Iteration 7968: train loss = 0.2998 test loss = 0.4062\n","Iteration 7969: train loss = 0.2997 test loss = 0.4062\n","Iteration 7970: train loss = 0.2997 test loss = 0.4062\n","Iteration 7971: train loss = 0.2997 test loss = 0.4062\n","Iteration 7972: train loss = 0.2997 test loss = 0.4062\n","Iteration 7973: train loss = 0.2996 test loss = 0.4061\n","Iteration 7974: train loss = 0.2996 test loss = 0.4061\n","Iteration 7975: train loss = 0.2996 test loss = 0.4061\n","Iteration 7976: train loss = 0.2996 test loss = 0.4061\n","Iteration 7977: train loss = 0.2995 test loss = 0.4061\n","Iteration 7978: train loss = 0.2995 test loss = 0.4061\n","Iteration 7979: train loss = 0.2995 test loss = 0.4060\n","Iteration 7980: train loss = 0.2994 test loss = 0.4060\n","Iteration 7981: train loss = 0.2994 test loss = 0.4060\n","Iteration 7982: train loss = 0.2994 test loss = 0.4060\n","Iteration 7983: train loss = 0.2994 test loss = 0.4060\n","Iteration 7984: train loss = 0.2993 test loss = 0.4060\n","Iteration 7985: train loss = 0.2993 test loss = 0.4059\n","Iteration 7986: train loss = 0.2993 test loss = 0.4059\n","Iteration 7987: train loss = 0.2993 test loss = 0.4059\n","Iteration 7988: train loss = 0.2992 test loss = 0.4059\n","Iteration 7989: train loss = 0.2992 test loss = 0.4059\n","Iteration 7990: train loss = 0.2992 test loss = 0.4059\n","Iteration 7991: train loss = 0.2992 test loss = 0.4058\n","Iteration 7992: train loss = 0.2991 test loss = 0.4058\n","Iteration 7993: train loss = 0.2991 test loss = 0.4058\n","Iteration 7994: train loss = 0.2991 test loss = 0.4058\n","Iteration 7995: train loss = 0.2991 test loss = 0.4058\n","Iteration 7996: train loss = 0.2990 test loss = 0.4058\n","Iteration 7997: train loss = 0.2990 test loss = 0.4057\n","Iteration 7998: train loss = 0.2990 test loss = 0.4057\n","Iteration 7999: train loss = 0.2990 test loss = 0.4057\n","Iteration 8000: train loss = 0.2989 test loss = 0.4057\n","Iteration 8001: train loss = 0.2989 test loss = 0.4057\n","Iteration 8002: train loss = 0.2989 test loss = 0.4057\n","Iteration 8003: train loss = 0.2988 test loss = 0.4056\n","Iteration 8004: train loss = 0.2988 test loss = 0.4056\n","Iteration 8005: train loss = 0.2988 test loss = 0.4056\n","Iteration 8006: train loss = 0.2988 test loss = 0.4056\n","Iteration 8007: train loss = 0.2987 test loss = 0.4056\n","Iteration 8008: train loss = 0.2987 test loss = 0.4056\n","Iteration 8009: train loss = 0.2987 test loss = 0.4055\n","Iteration 8010: train loss = 0.2987 test loss = 0.4055\n","Iteration 8011: train loss = 0.2986 test loss = 0.4055\n","Iteration 8012: train loss = 0.2986 test loss = 0.4055\n","Iteration 8013: train loss = 0.2986 test loss = 0.4055\n","Iteration 8014: train loss = 0.2986 test loss = 0.4055\n","Iteration 8015: train loss = 0.2985 test loss = 0.4054\n","Iteration 8016: train loss = 0.2985 test loss = 0.4054\n","Iteration 8017: train loss = 0.2985 test loss = 0.4054\n","Iteration 8018: train loss = 0.2985 test loss = 0.4054\n","Iteration 8019: train loss = 0.2984 test loss = 0.4054\n","Iteration 8020: train loss = 0.2984 test loss = 0.4054\n","Iteration 8021: train loss = 0.2984 test loss = 0.4053\n","Iteration 8022: train loss = 0.2984 test loss = 0.4053\n","Iteration 8023: train loss = 0.2983 test loss = 0.4053\n","Iteration 8024: train loss = 0.2983 test loss = 0.4053\n","Iteration 8025: train loss = 0.2983 test loss = 0.4053\n","Iteration 8026: train loss = 0.2983 test loss = 0.4052\n","Iteration 8027: train loss = 0.2982 test loss = 0.4052\n","Iteration 8028: train loss = 0.2982 test loss = 0.4052\n","Iteration 8029: train loss = 0.2982 test loss = 0.4052\n","Iteration 8030: train loss = 0.2981 test loss = 0.4052\n","Iteration 8031: train loss = 0.2981 test loss = 0.4052\n","Iteration 8032: train loss = 0.2981 test loss = 0.4051\n","Iteration 8033: train loss = 0.2981 test loss = 0.4051\n","Iteration 8034: train loss = 0.2980 test loss = 0.4051\n","Iteration 8035: train loss = 0.2980 test loss = 0.4051\n","Iteration 8036: train loss = 0.2980 test loss = 0.4051\n","Iteration 8037: train loss = 0.2980 test loss = 0.4051\n","Iteration 8038: train loss = 0.2979 test loss = 0.4050\n","Iteration 8039: train loss = 0.2979 test loss = 0.4050\n","Iteration 8040: train loss = 0.2979 test loss = 0.4050\n","Iteration 8041: train loss = 0.2979 test loss = 0.4050\n","Iteration 8042: train loss = 0.2978 test loss = 0.4050\n","Iteration 8043: train loss = 0.2978 test loss = 0.4050\n","Iteration 8044: train loss = 0.2978 test loss = 0.4049\n","Iteration 8045: train loss = 0.2978 test loss = 0.4049\n","Iteration 8046: train loss = 0.2977 test loss = 0.4049\n","Iteration 8047: train loss = 0.2977 test loss = 0.4049\n","Iteration 8048: train loss = 0.2977 test loss = 0.4049\n","Iteration 8049: train loss = 0.2977 test loss = 0.4049\n","Iteration 8050: train loss = 0.2976 test loss = 0.4048\n","Iteration 8051: train loss = 0.2976 test loss = 0.4048\n","Iteration 8052: train loss = 0.2976 test loss = 0.4048\n","Iteration 8053: train loss = 0.2976 test loss = 0.4048\n","Iteration 8054: train loss = 0.2975 test loss = 0.4048\n","Iteration 8055: train loss = 0.2975 test loss = 0.4048\n","Iteration 8056: train loss = 0.2975 test loss = 0.4047\n","Iteration 8057: train loss = 0.2975 test loss = 0.4047\n","Iteration 8058: train loss = 0.2974 test loss = 0.4047\n","Iteration 8059: train loss = 0.2974 test loss = 0.4047\n","Iteration 8060: train loss = 0.2974 test loss = 0.4047\n","Iteration 8061: train loss = 0.2973 test loss = 0.4047\n","Iteration 8062: train loss = 0.2973 test loss = 0.4046\n","Iteration 8063: train loss = 0.2973 test loss = 0.4046\n","Iteration 8064: train loss = 0.2973 test loss = 0.4046\n","Iteration 8065: train loss = 0.2972 test loss = 0.4046\n","Iteration 8066: train loss = 0.2972 test loss = 0.4046\n","Iteration 8067: train loss = 0.2972 test loss = 0.4046\n","Iteration 8068: train loss = 0.2972 test loss = 0.4045\n","Iteration 8069: train loss = 0.2971 test loss = 0.4045\n","Iteration 8070: train loss = 0.2971 test loss = 0.4045\n","Iteration 8071: train loss = 0.2971 test loss = 0.4045\n","Iteration 8072: train loss = 0.2971 test loss = 0.4045\n","Iteration 8073: train loss = 0.2970 test loss = 0.4045\n","Iteration 8074: train loss = 0.2970 test loss = 0.4045\n","Iteration 8075: train loss = 0.2970 test loss = 0.4044\n","Iteration 8076: train loss = 0.2970 test loss = 0.4044\n","Iteration 8077: train loss = 0.2969 test loss = 0.4044\n","Iteration 8078: train loss = 0.2969 test loss = 0.4044\n","Iteration 8079: train loss = 0.2969 test loss = 0.4044\n","Iteration 8080: train loss = 0.2969 test loss = 0.4044\n","Iteration 8081: train loss = 0.2968 test loss = 0.4043\n","Iteration 8082: train loss = 0.2968 test loss = 0.4043\n","Iteration 8083: train loss = 0.2968 test loss = 0.4043\n","Iteration 8084: train loss = 0.2968 test loss = 0.4043\n","Iteration 8085: train loss = 0.2967 test loss = 0.4043\n","Iteration 8086: train loss = 0.2967 test loss = 0.4043\n","Iteration 8087: train loss = 0.2967 test loss = 0.4042\n","Iteration 8088: train loss = 0.2967 test loss = 0.4042\n","Iteration 8089: train loss = 0.2966 test loss = 0.4042\n","Iteration 8090: train loss = 0.2966 test loss = 0.4042\n","Iteration 8091: train loss = 0.2966 test loss = 0.4042\n","Iteration 8092: train loss = 0.2966 test loss = 0.4042\n","Iteration 8093: train loss = 0.2965 test loss = 0.4041\n","Iteration 8094: train loss = 0.2965 test loss = 0.4041\n","Iteration 8095: train loss = 0.2965 test loss = 0.4041\n","Iteration 8096: train loss = 0.2965 test loss = 0.4041\n","Iteration 8097: train loss = 0.2964 test loss = 0.4041\n","Iteration 8098: train loss = 0.2964 test loss = 0.4041\n","Iteration 8099: train loss = 0.2964 test loss = 0.4040\n","Iteration 8100: train loss = 0.2963 test loss = 0.4040\n","Iteration 8101: train loss = 0.2963 test loss = 0.4040\n","Iteration 8102: train loss = 0.2963 test loss = 0.4040\n","Iteration 8103: train loss = 0.2963 test loss = 0.4040\n","Iteration 8104: train loss = 0.2962 test loss = 0.4040\n","Iteration 8105: train loss = 0.2962 test loss = 0.4039\n","Iteration 8106: train loss = 0.2962 test loss = 0.4039\n","Iteration 8107: train loss = 0.2962 test loss = 0.4039\n","Iteration 8108: train loss = 0.2961 test loss = 0.4039\n","Iteration 8109: train loss = 0.2961 test loss = 0.4039\n","Iteration 8110: train loss = 0.2961 test loss = 0.4039\n","Iteration 8111: train loss = 0.2961 test loss = 0.4038\n","Iteration 8112: train loss = 0.2960 test loss = 0.4038\n","Iteration 8113: train loss = 0.2960 test loss = 0.4038\n","Iteration 8114: train loss = 0.2960 test loss = 0.4038\n","Iteration 8115: train loss = 0.2960 test loss = 0.4038\n","Iteration 8116: train loss = 0.2959 test loss = 0.4038\n","Iteration 8117: train loss = 0.2959 test loss = 0.4037\n","Iteration 8118: train loss = 0.2959 test loss = 0.4037\n","Iteration 8119: train loss = 0.2959 test loss = 0.4037\n","Iteration 8120: train loss = 0.2958 test loss = 0.4037\n","Iteration 8121: train loss = 0.2958 test loss = 0.4037\n","Iteration 8122: train loss = 0.2958 test loss = 0.4037\n","Iteration 8123: train loss = 0.2958 test loss = 0.4036\n","Iteration 8124: train loss = 0.2957 test loss = 0.4036\n","Iteration 8125: train loss = 0.2957 test loss = 0.4036\n","Iteration 8126: train loss = 0.2957 test loss = 0.4036\n","Iteration 8127: train loss = 0.2957 test loss = 0.4036\n","Iteration 8128: train loss = 0.2956 test loss = 0.4036\n","Iteration 8129: train loss = 0.2956 test loss = 0.4035\n","Iteration 8130: train loss = 0.2956 test loss = 0.4035\n","Iteration 8131: train loss = 0.2956 test loss = 0.4035\n","Iteration 8132: train loss = 0.2955 test loss = 0.4035\n","Iteration 8133: train loss = 0.2955 test loss = 0.4035\n","Iteration 8134: train loss = 0.2955 test loss = 0.4035\n","Iteration 8135: train loss = 0.2955 test loss = 0.4034\n","Iteration 8136: train loss = 0.2954 test loss = 0.4034\n","Iteration 8137: train loss = 0.2954 test loss = 0.4034\n","Iteration 8138: train loss = 0.2954 test loss = 0.4034\n","Iteration 8139: train loss = 0.2954 test loss = 0.4034\n","Iteration 8140: train loss = 0.2953 test loss = 0.4034\n","Iteration 8141: train loss = 0.2953 test loss = 0.4033\n","Iteration 8142: train loss = 0.2953 test loss = 0.4033\n","Iteration 8143: train loss = 0.2952 test loss = 0.4033\n","Iteration 8144: train loss = 0.2952 test loss = 0.4033\n","Iteration 8145: train loss = 0.2952 test loss = 0.4033\n","Iteration 8146: train loss = 0.2952 test loss = 0.4033\n","Iteration 8147: train loss = 0.2951 test loss = 0.4032\n","Iteration 8148: train loss = 0.2951 test loss = 0.4032\n","Iteration 8149: train loss = 0.2951 test loss = 0.4032\n","Iteration 8150: train loss = 0.2951 test loss = 0.4032\n","Iteration 8151: train loss = 0.2950 test loss = 0.4032\n","Iteration 8152: train loss = 0.2950 test loss = 0.4032\n","Iteration 8153: train loss = 0.2950 test loss = 0.4031\n","Iteration 8154: train loss = 0.2950 test loss = 0.4031\n","Iteration 8155: train loss = 0.2949 test loss = 0.4031\n","Iteration 8156: train loss = 0.2949 test loss = 0.4031\n","Iteration 8157: train loss = 0.2949 test loss = 0.4031\n","Iteration 8158: train loss = 0.2949 test loss = 0.4031\n","Iteration 8159: train loss = 0.2948 test loss = 0.4030\n","Iteration 8160: train loss = 0.2948 test loss = 0.4030\n","Iteration 8161: train loss = 0.2948 test loss = 0.4030\n","Iteration 8162: train loss = 0.2948 test loss = 0.4030\n","Iteration 8163: train loss = 0.2947 test loss = 0.4030\n","Iteration 8164: train loss = 0.2947 test loss = 0.4030\n","Iteration 8165: train loss = 0.2947 test loss = 0.4030\n","Iteration 8166: train loss = 0.2947 test loss = 0.4029\n","Iteration 8167: train loss = 0.2946 test loss = 0.4029\n","Iteration 8168: train loss = 0.2946 test loss = 0.4029\n","Iteration 8169: train loss = 0.2946 test loss = 0.4029\n","Iteration 8170: train loss = 0.2946 test loss = 0.4029\n","Iteration 8171: train loss = 0.2945 test loss = 0.4029\n","Iteration 8172: train loss = 0.2945 test loss = 0.4028\n","Iteration 8173: train loss = 0.2945 test loss = 0.4028\n","Iteration 8174: train loss = 0.2945 test loss = 0.4028\n","Iteration 8175: train loss = 0.2944 test loss = 0.4028\n","Iteration 8176: train loss = 0.2944 test loss = 0.4028\n","Iteration 8177: train loss = 0.2944 test loss = 0.4028\n","Iteration 8178: train loss = 0.2944 test loss = 0.4027\n","Iteration 8179: train loss = 0.2943 test loss = 0.4027\n","Iteration 8180: train loss = 0.2943 test loss = 0.4027\n","Iteration 8181: train loss = 0.2943 test loss = 0.4027\n","Iteration 8182: train loss = 0.2943 test loss = 0.4027\n","Iteration 8183: train loss = 0.2942 test loss = 0.4027\n","Iteration 8184: train loss = 0.2942 test loss = 0.4026\n","Iteration 8185: train loss = 0.2942 test loss = 0.4026\n","Iteration 8186: train loss = 0.2942 test loss = 0.4026\n","Iteration 8187: train loss = 0.2941 test loss = 0.4026\n","Iteration 8188: train loss = 0.2941 test loss = 0.4026\n","Iteration 8189: train loss = 0.2941 test loss = 0.4026\n","Iteration 8190: train loss = 0.2941 test loss = 0.4025\n","Iteration 8191: train loss = 0.2940 test loss = 0.4025\n","Iteration 8192: train loss = 0.2940 test loss = 0.4025\n","Iteration 8193: train loss = 0.2940 test loss = 0.4025\n","Iteration 8194: train loss = 0.2940 test loss = 0.4025\n","Iteration 8195: train loss = 0.2939 test loss = 0.4025\n","Iteration 8196: train loss = 0.2939 test loss = 0.4024\n","Iteration 8197: train loss = 0.2939 test loss = 0.4024\n","Iteration 8198: train loss = 0.2939 test loss = 0.4024\n","Iteration 8199: train loss = 0.2938 test loss = 0.4024\n","Iteration 8200: train loss = 0.2938 test loss = 0.4024\n","Iteration 8201: train loss = 0.2938 test loss = 0.4024\n","Iteration 8202: train loss = 0.2937 test loss = 0.4023\n","Iteration 8203: train loss = 0.2937 test loss = 0.4023\n","Iteration 8204: train loss = 0.2937 test loss = 0.4023\n","Iteration 8205: train loss = 0.2937 test loss = 0.4023\n","Iteration 8206: train loss = 0.2936 test loss = 0.4023\n","Iteration 8207: train loss = 0.2936 test loss = 0.4023\n","Iteration 8208: train loss = 0.2936 test loss = 0.4022\n","Iteration 8209: train loss = 0.2936 test loss = 0.4022\n","Iteration 8210: train loss = 0.2935 test loss = 0.4022\n","Iteration 8211: train loss = 0.2935 test loss = 0.4022\n","Iteration 8212: train loss = 0.2935 test loss = 0.4022\n","Iteration 8213: train loss = 0.2935 test loss = 0.4022\n","Iteration 8214: train loss = 0.2934 test loss = 0.4022\n","Iteration 8215: train loss = 0.2934 test loss = 0.4021\n","Iteration 8216: train loss = 0.2934 test loss = 0.4021\n","Iteration 8217: train loss = 0.2934 test loss = 0.4021\n","Iteration 8218: train loss = 0.2933 test loss = 0.4021\n","Iteration 8219: train loss = 0.2933 test loss = 0.4021\n","Iteration 8220: train loss = 0.2933 test loss = 0.4021\n","Iteration 8221: train loss = 0.2933 test loss = 0.4020\n","Iteration 8222: train loss = 0.2932 test loss = 0.4020\n","Iteration 8223: train loss = 0.2932 test loss = 0.4020\n","Iteration 8224: train loss = 0.2932 test loss = 0.4020\n","Iteration 8225: train loss = 0.2932 test loss = 0.4020\n","Iteration 8226: train loss = 0.2931 test loss = 0.4020\n","Iteration 8227: train loss = 0.2931 test loss = 0.4019\n","Iteration 8228: train loss = 0.2931 test loss = 0.4019\n","Iteration 8229: train loss = 0.2931 test loss = 0.4019\n","Iteration 8230: train loss = 0.2930 test loss = 0.4019\n","Iteration 8231: train loss = 0.2930 test loss = 0.4019\n","Iteration 8232: train loss = 0.2930 test loss = 0.4019\n","Iteration 8233: train loss = 0.2930 test loss = 0.4018\n","Iteration 8234: train loss = 0.2929 test loss = 0.4018\n","Iteration 8235: train loss = 0.2929 test loss = 0.4018\n","Iteration 8236: train loss = 0.2929 test loss = 0.4018\n","Iteration 8237: train loss = 0.2929 test loss = 0.4018\n","Iteration 8238: train loss = 0.2928 test loss = 0.4018\n","Iteration 8239: train loss = 0.2928 test loss = 0.4017\n","Iteration 8240: train loss = 0.2928 test loss = 0.4017\n","Iteration 8241: train loss = 0.2928 test loss = 0.4017\n","Iteration 8242: train loss = 0.2927 test loss = 0.4017\n","Iteration 8243: train loss = 0.2927 test loss = 0.4017\n","Iteration 8244: train loss = 0.2927 test loss = 0.4017\n","Iteration 8245: train loss = 0.2927 test loss = 0.4017\n","Iteration 8246: train loss = 0.2926 test loss = 0.4016\n","Iteration 8247: train loss = 0.2926 test loss = 0.4016\n","Iteration 8248: train loss = 0.2926 test loss = 0.4016\n","Iteration 8249: train loss = 0.2926 test loss = 0.4016\n","Iteration 8250: train loss = 0.2925 test loss = 0.4016\n","Iteration 8251: train loss = 0.2925 test loss = 0.4016\n","Iteration 8252: train loss = 0.2925 test loss = 0.4015\n","Iteration 8253: train loss = 0.2925 test loss = 0.4015\n","Iteration 8254: train loss = 0.2924 test loss = 0.4015\n","Iteration 8255: train loss = 0.2924 test loss = 0.4015\n","Iteration 8256: train loss = 0.2924 test loss = 0.4015\n","Iteration 8257: train loss = 0.2924 test loss = 0.4015\n","Iteration 8258: train loss = 0.2923 test loss = 0.4014\n","Iteration 8259: train loss = 0.2923 test loss = 0.4014\n","Iteration 8260: train loss = 0.2923 test loss = 0.4014\n","Iteration 8261: train loss = 0.2923 test loss = 0.4014\n","Iteration 8262: train loss = 0.2922 test loss = 0.4014\n","Iteration 8263: train loss = 0.2922 test loss = 0.4014\n","Iteration 8264: train loss = 0.2922 test loss = 0.4013\n","Iteration 8265: train loss = 0.2922 test loss = 0.4013\n","Iteration 8266: train loss = 0.2921 test loss = 0.4013\n","Iteration 8267: train loss = 0.2921 test loss = 0.4013\n","Iteration 8268: train loss = 0.2921 test loss = 0.4013\n","Iteration 8269: train loss = 0.2921 test loss = 0.4013\n","Iteration 8270: train loss = 0.2920 test loss = 0.4012\n","Iteration 8271: train loss = 0.2920 test loss = 0.4012\n","Iteration 8272: train loss = 0.2920 test loss = 0.4012\n","Iteration 8273: train loss = 0.2920 test loss = 0.4012\n","Iteration 8274: train loss = 0.2919 test loss = 0.4012\n","Iteration 8275: train loss = 0.2919 test loss = 0.4012\n","Iteration 8276: train loss = 0.2919 test loss = 0.4012\n","Iteration 8277: train loss = 0.2919 test loss = 0.4011\n","Iteration 8278: train loss = 0.2918 test loss = 0.4011\n","Iteration 8279: train loss = 0.2918 test loss = 0.4011\n","Iteration 8280: train loss = 0.2918 test loss = 0.4011\n","Iteration 8281: train loss = 0.2918 test loss = 0.4011\n","Iteration 8282: train loss = 0.2917 test loss = 0.4011\n","Iteration 8283: train loss = 0.2917 test loss = 0.4010\n","Iteration 8284: train loss = 0.2917 test loss = 0.4010\n","Iteration 8285: train loss = 0.2917 test loss = 0.4010\n","Iteration 8286: train loss = 0.2916 test loss = 0.4010\n","Iteration 8287: train loss = 0.2916 test loss = 0.4010\n","Iteration 8288: train loss = 0.2916 test loss = 0.4010\n","Iteration 8289: train loss = 0.2916 test loss = 0.4009\n","Iteration 8290: train loss = 0.2915 test loss = 0.4009\n","Iteration 8291: train loss = 0.2915 test loss = 0.4009\n","Iteration 8292: train loss = 0.2915 test loss = 0.4009\n","Iteration 8293: train loss = 0.2915 test loss = 0.4009\n","Iteration 8294: train loss = 0.2914 test loss = 0.4009\n","Iteration 8295: train loss = 0.2914 test loss = 0.4008\n","Iteration 8296: train loss = 0.2914 test loss = 0.4008\n","Iteration 8297: train loss = 0.2914 test loss = 0.4008\n","Iteration 8298: train loss = 0.2913 test loss = 0.4008\n","Iteration 8299: train loss = 0.2913 test loss = 0.4008\n","Iteration 8300: train loss = 0.2913 test loss = 0.4008\n","Iteration 8301: train loss = 0.2913 test loss = 0.4007\n","Iteration 8302: train loss = 0.2912 test loss = 0.4007\n","Iteration 8303: train loss = 0.2912 test loss = 0.4007\n","Iteration 8304: train loss = 0.2912 test loss = 0.4007\n","Iteration 8305: train loss = 0.2912 test loss = 0.4007\n","Iteration 8306: train loss = 0.2911 test loss = 0.4007\n","Iteration 8307: train loss = 0.2911 test loss = 0.4007\n","Iteration 8308: train loss = 0.2911 test loss = 0.4006\n","Iteration 8309: train loss = 0.2911 test loss = 0.4006\n","Iteration 8310: train loss = 0.2910 test loss = 0.4006\n","Iteration 8311: train loss = 0.2910 test loss = 0.4006\n","Iteration 8312: train loss = 0.2910 test loss = 0.4006\n","Iteration 8313: train loss = 0.2910 test loss = 0.4006\n","Iteration 8314: train loss = 0.2909 test loss = 0.4005\n","Iteration 8315: train loss = 0.2909 test loss = 0.4005\n","Iteration 8316: train loss = 0.2909 test loss = 0.4005\n","Iteration 8317: train loss = 0.2909 test loss = 0.4005\n","Iteration 8318: train loss = 0.2908 test loss = 0.4005\n","Iteration 8319: train loss = 0.2908 test loss = 0.4005\n","Iteration 8320: train loss = 0.2908 test loss = 0.4004\n","Iteration 8321: train loss = 0.2908 test loss = 0.4004\n","Iteration 8322: train loss = 0.2907 test loss = 0.4004\n","Iteration 8323: train loss = 0.2907 test loss = 0.4004\n","Iteration 8324: train loss = 0.2907 test loss = 0.4004\n","Iteration 8325: train loss = 0.2907 test loss = 0.4004\n","Iteration 8326: train loss = 0.2906 test loss = 0.4004\n","Iteration 8327: train loss = 0.2906 test loss = 0.4003\n","Iteration 8328: train loss = 0.2906 test loss = 0.4003\n","Iteration 8329: train loss = 0.2906 test loss = 0.4003\n","Iteration 8330: train loss = 0.2905 test loss = 0.4003\n","Iteration 8331: train loss = 0.2905 test loss = 0.4003\n","Iteration 8332: train loss = 0.2905 test loss = 0.4003\n","Iteration 8333: train loss = 0.2905 test loss = 0.4002\n","Iteration 8334: train loss = 0.2904 test loss = 0.4002\n","Iteration 8335: train loss = 0.2904 test loss = 0.4002\n","Iteration 8336: train loss = 0.2904 test loss = 0.4002\n","Iteration 8337: train loss = 0.2904 test loss = 0.4002\n","Iteration 8338: train loss = 0.2903 test loss = 0.4002\n","Iteration 8339: train loss = 0.2903 test loss = 0.4001\n","Iteration 8340: train loss = 0.2903 test loss = 0.4001\n","Iteration 8341: train loss = 0.2903 test loss = 0.4001\n","Iteration 8342: train loss = 0.2902 test loss = 0.4001\n","Iteration 8343: train loss = 0.2902 test loss = 0.4001\n","Iteration 8344: train loss = 0.2902 test loss = 0.4001\n","Iteration 8345: train loss = 0.2902 test loss = 0.4000\n","Iteration 8346: train loss = 0.2901 test loss = 0.4000\n","Iteration 8347: train loss = 0.2901 test loss = 0.4000\n","Iteration 8348: train loss = 0.2901 test loss = 0.4000\n","Iteration 8349: train loss = 0.2901 test loss = 0.4000\n","Iteration 8350: train loss = 0.2900 test loss = 0.4000\n","Iteration 8351: train loss = 0.2900 test loss = 0.4000\n","Iteration 8352: train loss = 0.2900 test loss = 0.3999\n","Iteration 8353: train loss = 0.2900 test loss = 0.3999\n","Iteration 8354: train loss = 0.2899 test loss = 0.3999\n","Iteration 8355: train loss = 0.2899 test loss = 0.3999\n","Iteration 8356: train loss = 0.2899 test loss = 0.3999\n","Iteration 8357: train loss = 0.2899 test loss = 0.3999\n","Iteration 8358: train loss = 0.2898 test loss = 0.3998\n","Iteration 8359: train loss = 0.2898 test loss = 0.3998\n","Iteration 8360: train loss = 0.2898 test loss = 0.3998\n","Iteration 8361: train loss = 0.2898 test loss = 0.3998\n","Iteration 8362: train loss = 0.2897 test loss = 0.3998\n","Iteration 8363: train loss = 0.2897 test loss = 0.3998\n","Iteration 8364: train loss = 0.2897 test loss = 0.3997\n","Iteration 8365: train loss = 0.2897 test loss = 0.3997\n","Iteration 8366: train loss = 0.2896 test loss = 0.3997\n","Iteration 8367: train loss = 0.2896 test loss = 0.3997\n","Iteration 8368: train loss = 0.2896 test loss = 0.3997\n","Iteration 8369: train loss = 0.2896 test loss = 0.3997\n","Iteration 8370: train loss = 0.2895 test loss = 0.3997\n","Iteration 8371: train loss = 0.2895 test loss = 0.3996\n","Iteration 8372: train loss = 0.2895 test loss = 0.3996\n","Iteration 8373: train loss = 0.2895 test loss = 0.3996\n","Iteration 8374: train loss = 0.2894 test loss = 0.3996\n","Iteration 8375: train loss = 0.2894 test loss = 0.3996\n","Iteration 8376: train loss = 0.2894 test loss = 0.3996\n","Iteration 8377: train loss = 0.2894 test loss = 0.3995\n","Iteration 8378: train loss = 0.2893 test loss = 0.3995\n","Iteration 8379: train loss = 0.2893 test loss = 0.3995\n","Iteration 8380: train loss = 0.2893 test loss = 0.3995\n","Iteration 8381: train loss = 0.2893 test loss = 0.3995\n","Iteration 8382: train loss = 0.2892 test loss = 0.3995\n","Iteration 8383: train loss = 0.2892 test loss = 0.3994\n","Iteration 8384: train loss = 0.2892 test loss = 0.3994\n","Iteration 8385: train loss = 0.2892 test loss = 0.3994\n","Iteration 8386: train loss = 0.2891 test loss = 0.3994\n","Iteration 8387: train loss = 0.2891 test loss = 0.3994\n","Iteration 8388: train loss = 0.2891 test loss = 0.3994\n","Iteration 8389: train loss = 0.2891 test loss = 0.3994\n","Iteration 8390: train loss = 0.2890 test loss = 0.3993\n","Iteration 8391: train loss = 0.2890 test loss = 0.3993\n","Iteration 8392: train loss = 0.2890 test loss = 0.3993\n","Iteration 8393: train loss = 0.2890 test loss = 0.3993\n","Iteration 8394: train loss = 0.2889 test loss = 0.3993\n","Iteration 8395: train loss = 0.2889 test loss = 0.3993\n","Iteration 8396: train loss = 0.2889 test loss = 0.3992\n","Iteration 8397: train loss = 0.2889 test loss = 0.3992\n","Iteration 8398: train loss = 0.2888 test loss = 0.3992\n","Iteration 8399: train loss = 0.2888 test loss = 0.3992\n","Iteration 8400: train loss = 0.2888 test loss = 0.3992\n","Iteration 8401: train loss = 0.2888 test loss = 0.3992\n","Iteration 8402: train loss = 0.2887 test loss = 0.3991\n","Iteration 8403: train loss = 0.2887 test loss = 0.3991\n","Iteration 8404: train loss = 0.2887 test loss = 0.3991\n","Iteration 8405: train loss = 0.2887 test loss = 0.3991\n","Iteration 8406: train loss = 0.2886 test loss = 0.3991\n","Iteration 8407: train loss = 0.2886 test loss = 0.3991\n","Iteration 8408: train loss = 0.2886 test loss = 0.3991\n","Iteration 8409: train loss = 0.2886 test loss = 0.3990\n","Iteration 8410: train loss = 0.2885 test loss = 0.3990\n","Iteration 8411: train loss = 0.2885 test loss = 0.3990\n","Iteration 8412: train loss = 0.2885 test loss = 0.3990\n","Iteration 8413: train loss = 0.2885 test loss = 0.3990\n","Iteration 8414: train loss = 0.2884 test loss = 0.3990\n","Iteration 8415: train loss = 0.2884 test loss = 0.3989\n","Iteration 8416: train loss = 0.2884 test loss = 0.3989\n","Iteration 8417: train loss = 0.2884 test loss = 0.3989\n","Iteration 8418: train loss = 0.2884 test loss = 0.3989\n","Iteration 8419: train loss = 0.2883 test loss = 0.3989\n","Iteration 8420: train loss = 0.2883 test loss = 0.3989\n","Iteration 8421: train loss = 0.2883 test loss = 0.3988\n","Iteration 8422: train loss = 0.2883 test loss = 0.3988\n","Iteration 8423: train loss = 0.2882 test loss = 0.3988\n","Iteration 8424: train loss = 0.2882 test loss = 0.3988\n","Iteration 8425: train loss = 0.2882 test loss = 0.3988\n","Iteration 8426: train loss = 0.2882 test loss = 0.3988\n","Iteration 8427: train loss = 0.2881 test loss = 0.3988\n","Iteration 8428: train loss = 0.2881 test loss = 0.3987\n","Iteration 8429: train loss = 0.2881 test loss = 0.3987\n","Iteration 8430: train loss = 0.2881 test loss = 0.3987\n","Iteration 8431: train loss = 0.2880 test loss = 0.3987\n","Iteration 8432: train loss = 0.2880 test loss = 0.3987\n","Iteration 8433: train loss = 0.2880 test loss = 0.3987\n","Iteration 8434: train loss = 0.2880 test loss = 0.3986\n","Iteration 8435: train loss = 0.2879 test loss = 0.3986\n","Iteration 8436: train loss = 0.2879 test loss = 0.3986\n","Iteration 8437: train loss = 0.2879 test loss = 0.3986\n","Iteration 8438: train loss = 0.2879 test loss = 0.3986\n","Iteration 8439: train loss = 0.2878 test loss = 0.3986\n","Iteration 8440: train loss = 0.2878 test loss = 0.3985\n","Iteration 8441: train loss = 0.2878 test loss = 0.3985\n","Iteration 8442: train loss = 0.2878 test loss = 0.3985\n","Iteration 8443: train loss = 0.2877 test loss = 0.3985\n","Iteration 8444: train loss = 0.2877 test loss = 0.3985\n","Iteration 8445: train loss = 0.2877 test loss = 0.3985\n","Iteration 8446: train loss = 0.2877 test loss = 0.3985\n","Iteration 8447: train loss = 0.2876 test loss = 0.3984\n","Iteration 8448: train loss = 0.2876 test loss = 0.3984\n","Iteration 8449: train loss = 0.2876 test loss = 0.3984\n","Iteration 8450: train loss = 0.2876 test loss = 0.3984\n","Iteration 8451: train loss = 0.2875 test loss = 0.3984\n","Iteration 8452: train loss = 0.2875 test loss = 0.3984\n","Iteration 8453: train loss = 0.2875 test loss = 0.3983\n","Iteration 8454: train loss = 0.2875 test loss = 0.3983\n","Iteration 8455: train loss = 0.2874 test loss = 0.3983\n","Iteration 8456: train loss = 0.2874 test loss = 0.3983\n","Iteration 8457: train loss = 0.2874 test loss = 0.3983\n","Iteration 8458: train loss = 0.2874 test loss = 0.3983\n","Iteration 8459: train loss = 0.2873 test loss = 0.3983\n","Iteration 8460: train loss = 0.2873 test loss = 0.3982\n","Iteration 8461: train loss = 0.2873 test loss = 0.3982\n","Iteration 8462: train loss = 0.2873 test loss = 0.3982\n","Iteration 8463: train loss = 0.2872 test loss = 0.3982\n","Iteration 8464: train loss = 0.2872 test loss = 0.3982\n","Iteration 8465: train loss = 0.2872 test loss = 0.3982\n","Iteration 8466: train loss = 0.2872 test loss = 0.3981\n","Iteration 8467: train loss = 0.2871 test loss = 0.3981\n","Iteration 8468: train loss = 0.2871 test loss = 0.3981\n","Iteration 8469: train loss = 0.2871 test loss = 0.3981\n","Iteration 8470: train loss = 0.2871 test loss = 0.3981\n","Iteration 8471: train loss = 0.2870 test loss = 0.3981\n","Iteration 8472: train loss = 0.2870 test loss = 0.3980\n","Iteration 8473: train loss = 0.2870 test loss = 0.3980\n","Iteration 8474: train loss = 0.2870 test loss = 0.3980\n","Iteration 8475: train loss = 0.2869 test loss = 0.3980\n","Iteration 8476: train loss = 0.2869 test loss = 0.3980\n","Iteration 8477: train loss = 0.2869 test loss = 0.3980\n","Iteration 8478: train loss = 0.2869 test loss = 0.3980\n","Iteration 8479: train loss = 0.2869 test loss = 0.3979\n","Iteration 8480: train loss = 0.2868 test loss = 0.3979\n","Iteration 8481: train loss = 0.2868 test loss = 0.3979\n","Iteration 8482: train loss = 0.2868 test loss = 0.3979\n","Iteration 8483: train loss = 0.2868 test loss = 0.3979\n","Iteration 8484: train loss = 0.2867 test loss = 0.3979\n","Iteration 8485: train loss = 0.2867 test loss = 0.3978\n","Iteration 8486: train loss = 0.2867 test loss = 0.3978\n","Iteration 8487: train loss = 0.2867 test loss = 0.3978\n","Iteration 8488: train loss = 0.2866 test loss = 0.3978\n","Iteration 8489: train loss = 0.2866 test loss = 0.3978\n","Iteration 8490: train loss = 0.2866 test loss = 0.3978\n","Iteration 8491: train loss = 0.2866 test loss = 0.3978\n","Iteration 8492: train loss = 0.2865 test loss = 0.3977\n","Iteration 8493: train loss = 0.2865 test loss = 0.3977\n","Iteration 8494: train loss = 0.2865 test loss = 0.3977\n","Iteration 8495: train loss = 0.2865 test loss = 0.3977\n","Iteration 8496: train loss = 0.2864 test loss = 0.3977\n","Iteration 8497: train loss = 0.2864 test loss = 0.3977\n","Iteration 8498: train loss = 0.2864 test loss = 0.3976\n","Iteration 8499: train loss = 0.2864 test loss = 0.3976\n","Iteration 8500: train loss = 0.2863 test loss = 0.3976\n","Iteration 8501: train loss = 0.2863 test loss = 0.3976\n","Iteration 8502: train loss = 0.2863 test loss = 0.3976\n","Iteration 8503: train loss = 0.2863 test loss = 0.3976\n","Iteration 8504: train loss = 0.2862 test loss = 0.3976\n","Iteration 8505: train loss = 0.2862 test loss = 0.3975\n","Iteration 8506: train loss = 0.2862 test loss = 0.3975\n","Iteration 8507: train loss = 0.2862 test loss = 0.3975\n","Iteration 8508: train loss = 0.2861 test loss = 0.3975\n","Iteration 8509: train loss = 0.2861 test loss = 0.3975\n","Iteration 8510: train loss = 0.2861 test loss = 0.3975\n","Iteration 8511: train loss = 0.2861 test loss = 0.3974\n","Iteration 8512: train loss = 0.2860 test loss = 0.3974\n","Iteration 8513: train loss = 0.2860 test loss = 0.3974\n","Iteration 8514: train loss = 0.2860 test loss = 0.3974\n","Iteration 8515: train loss = 0.2860 test loss = 0.3974\n","Iteration 8516: train loss = 0.2859 test loss = 0.3974\n","Iteration 8517: train loss = 0.2859 test loss = 0.3974\n","Iteration 8518: train loss = 0.2859 test loss = 0.3973\n","Iteration 8519: train loss = 0.2859 test loss = 0.3973\n","Iteration 8520: train loss = 0.2858 test loss = 0.3973\n","Iteration 8521: train loss = 0.2858 test loss = 0.3973\n","Iteration 8522: train loss = 0.2858 test loss = 0.3973\n","Iteration 8523: train loss = 0.2858 test loss = 0.3973\n","Iteration 8524: train loss = 0.2858 test loss = 0.3972\n","Iteration 8525: train loss = 0.2857 test loss = 0.3972\n","Iteration 8526: train loss = 0.2857 test loss = 0.3972\n","Iteration 8527: train loss = 0.2857 test loss = 0.3972\n","Iteration 8528: train loss = 0.2857 test loss = 0.3972\n","Iteration 8529: train loss = 0.2856 test loss = 0.3972\n","Iteration 8530: train loss = 0.2856 test loss = 0.3971\n","Iteration 8531: train loss = 0.2856 test loss = 0.3971\n","Iteration 8532: train loss = 0.2856 test loss = 0.3971\n","Iteration 8533: train loss = 0.2855 test loss = 0.3971\n","Iteration 8534: train loss = 0.2855 test loss = 0.3971\n","Iteration 8535: train loss = 0.2855 test loss = 0.3971\n","Iteration 8536: train loss = 0.2855 test loss = 0.3971\n","Iteration 8537: train loss = 0.2854 test loss = 0.3970\n","Iteration 8538: train loss = 0.2854 test loss = 0.3970\n","Iteration 8539: train loss = 0.2854 test loss = 0.3970\n","Iteration 8540: train loss = 0.2854 test loss = 0.3970\n","Iteration 8541: train loss = 0.2853 test loss = 0.3970\n","Iteration 8542: train loss = 0.2853 test loss = 0.3970\n","Iteration 8543: train loss = 0.2853 test loss = 0.3969\n","Iteration 8544: train loss = 0.2853 test loss = 0.3969\n","Iteration 8545: train loss = 0.2852 test loss = 0.3969\n","Iteration 8546: train loss = 0.2852 test loss = 0.3969\n","Iteration 8547: train loss = 0.2852 test loss = 0.3969\n","Iteration 8548: train loss = 0.2852 test loss = 0.3969\n","Iteration 8549: train loss = 0.2851 test loss = 0.3969\n","Iteration 8550: train loss = 0.2851 test loss = 0.3968\n","Iteration 8551: train loss = 0.2851 test loss = 0.3968\n","Iteration 8552: train loss = 0.2851 test loss = 0.3968\n","Iteration 8553: train loss = 0.2850 test loss = 0.3968\n","Iteration 8554: train loss = 0.2850 test loss = 0.3968\n","Iteration 8555: train loss = 0.2850 test loss = 0.3968\n","Iteration 8556: train loss = 0.2850 test loss = 0.3967\n","Iteration 8557: train loss = 0.2849 test loss = 0.3967\n","Iteration 8558: train loss = 0.2849 test loss = 0.3967\n","Iteration 8559: train loss = 0.2849 test loss = 0.3967\n","Iteration 8560: train loss = 0.2849 test loss = 0.3967\n","Iteration 8561: train loss = 0.2849 test loss = 0.3967\n","Iteration 8562: train loss = 0.2848 test loss = 0.3967\n","Iteration 8563: train loss = 0.2848 test loss = 0.3966\n","Iteration 8564: train loss = 0.2848 test loss = 0.3966\n","Iteration 8565: train loss = 0.2848 test loss = 0.3966\n","Iteration 8566: train loss = 0.2847 test loss = 0.3966\n","Iteration 8567: train loss = 0.2847 test loss = 0.3966\n","Iteration 8568: train loss = 0.2847 test loss = 0.3966\n","Iteration 8569: train loss = 0.2847 test loss = 0.3965\n","Iteration 8570: train loss = 0.2846 test loss = 0.3965\n","Iteration 8571: train loss = 0.2846 test loss = 0.3965\n","Iteration 8572: train loss = 0.2846 test loss = 0.3965\n","Iteration 8573: train loss = 0.2846 test loss = 0.3965\n","Iteration 8574: train loss = 0.2845 test loss = 0.3965\n","Iteration 8575: train loss = 0.2845 test loss = 0.3965\n","Iteration 8576: train loss = 0.2845 test loss = 0.3964\n","Iteration 8577: train loss = 0.2845 test loss = 0.3964\n","Iteration 8578: train loss = 0.2844 test loss = 0.3964\n","Iteration 8579: train loss = 0.2844 test loss = 0.3964\n","Iteration 8580: train loss = 0.2844 test loss = 0.3964\n","Iteration 8581: train loss = 0.2844 test loss = 0.3964\n","Iteration 8582: train loss = 0.2843 test loss = 0.3963\n","Iteration 8583: train loss = 0.2843 test loss = 0.3963\n","Iteration 8584: train loss = 0.2843 test loss = 0.3963\n","Iteration 8585: train loss = 0.2843 test loss = 0.3963\n","Iteration 8586: train loss = 0.2842 test loss = 0.3963\n","Iteration 8587: train loss = 0.2842 test loss = 0.3963\n","Iteration 8588: train loss = 0.2842 test loss = 0.3963\n","Iteration 8589: train loss = 0.2842 test loss = 0.3962\n","Iteration 8590: train loss = 0.2841 test loss = 0.3962\n","Iteration 8591: train loss = 0.2841 test loss = 0.3962\n","Iteration 8592: train loss = 0.2841 test loss = 0.3962\n","Iteration 8593: train loss = 0.2841 test loss = 0.3962\n","Iteration 8594: train loss = 0.2841 test loss = 0.3962\n","Iteration 8595: train loss = 0.2840 test loss = 0.3962\n","Iteration 8596: train loss = 0.2840 test loss = 0.3961\n","Iteration 8597: train loss = 0.2840 test loss = 0.3961\n","Iteration 8598: train loss = 0.2840 test loss = 0.3961\n","Iteration 8599: train loss = 0.2839 test loss = 0.3961\n","Iteration 8600: train loss = 0.2839 test loss = 0.3961\n","Iteration 8601: train loss = 0.2839 test loss = 0.3961\n","Iteration 8602: train loss = 0.2839 test loss = 0.3960\n","Iteration 8603: train loss = 0.2838 test loss = 0.3960\n","Iteration 8604: train loss = 0.2838 test loss = 0.3960\n","Iteration 8605: train loss = 0.2838 test loss = 0.3960\n","Iteration 8606: train loss = 0.2838 test loss = 0.3960\n","Iteration 8607: train loss = 0.2837 test loss = 0.3960\n","Iteration 8608: train loss = 0.2837 test loss = 0.3960\n","Iteration 8609: train loss = 0.2837 test loss = 0.3959\n","Iteration 8610: train loss = 0.2837 test loss = 0.3959\n","Iteration 8611: train loss = 0.2836 test loss = 0.3959\n","Iteration 8612: train loss = 0.2836 test loss = 0.3959\n","Iteration 8613: train loss = 0.2836 test loss = 0.3959\n","Iteration 8614: train loss = 0.2836 test loss = 0.3959\n","Iteration 8615: train loss = 0.2835 test loss = 0.3958\n","Iteration 8616: train loss = 0.2835 test loss = 0.3958\n","Iteration 8617: train loss = 0.2835 test loss = 0.3958\n","Iteration 8618: train loss = 0.2835 test loss = 0.3958\n","Iteration 8619: train loss = 0.2834 test loss = 0.3958\n","Iteration 8620: train loss = 0.2834 test loss = 0.3958\n","Iteration 8621: train loss = 0.2834 test loss = 0.3958\n","Iteration 8622: train loss = 0.2834 test loss = 0.3957\n","Iteration 8623: train loss = 0.2834 test loss = 0.3957\n","Iteration 8624: train loss = 0.2833 test loss = 0.3957\n","Iteration 8625: train loss = 0.2833 test loss = 0.3957\n","Iteration 8626: train loss = 0.2833 test loss = 0.3957\n","Iteration 8627: train loss = 0.2833 test loss = 0.3957\n","Iteration 8628: train loss = 0.2832 test loss = 0.3956\n","Iteration 8629: train loss = 0.2832 test loss = 0.3956\n","Iteration 8630: train loss = 0.2832 test loss = 0.3956\n","Iteration 8631: train loss = 0.2832 test loss = 0.3956\n","Iteration 8632: train loss = 0.2831 test loss = 0.3956\n","Iteration 8633: train loss = 0.2831 test loss = 0.3956\n","Iteration 8634: train loss = 0.2831 test loss = 0.3956\n","Iteration 8635: train loss = 0.2831 test loss = 0.3955\n","Iteration 8636: train loss = 0.2830 test loss = 0.3955\n","Iteration 8637: train loss = 0.2830 test loss = 0.3955\n","Iteration 8638: train loss = 0.2830 test loss = 0.3955\n","Iteration 8639: train loss = 0.2830 test loss = 0.3955\n","Iteration 8640: train loss = 0.2829 test loss = 0.3955\n","Iteration 8641: train loss = 0.2829 test loss = 0.3955\n","Iteration 8642: train loss = 0.2829 test loss = 0.3954\n","Iteration 8643: train loss = 0.2829 test loss = 0.3954\n","Iteration 8644: train loss = 0.2828 test loss = 0.3954\n","Iteration 8645: train loss = 0.2828 test loss = 0.3954\n","Iteration 8646: train loss = 0.2828 test loss = 0.3954\n","Iteration 8647: train loss = 0.2828 test loss = 0.3954\n","Iteration 8648: train loss = 0.2828 test loss = 0.3953\n","Iteration 8649: train loss = 0.2827 test loss = 0.3953\n","Iteration 8650: train loss = 0.2827 test loss = 0.3953\n","Iteration 8651: train loss = 0.2827 test loss = 0.3953\n","Iteration 8652: train loss = 0.2827 test loss = 0.3953\n","Iteration 8653: train loss = 0.2826 test loss = 0.3953\n","Iteration 8654: train loss = 0.2826 test loss = 0.3953\n","Iteration 8655: train loss = 0.2826 test loss = 0.3952\n","Iteration 8656: train loss = 0.2826 test loss = 0.3952\n","Iteration 8657: train loss = 0.2825 test loss = 0.3952\n","Iteration 8658: train loss = 0.2825 test loss = 0.3952\n","Iteration 8659: train loss = 0.2825 test loss = 0.3952\n","Iteration 8660: train loss = 0.2825 test loss = 0.3952\n","Iteration 8661: train loss = 0.2824 test loss = 0.3951\n","Iteration 8662: train loss = 0.2824 test loss = 0.3951\n","Iteration 8663: train loss = 0.2824 test loss = 0.3951\n","Iteration 8664: train loss = 0.2824 test loss = 0.3951\n","Iteration 8665: train loss = 0.2823 test loss = 0.3951\n","Iteration 8666: train loss = 0.2823 test loss = 0.3951\n","Iteration 8667: train loss = 0.2823 test loss = 0.3951\n","Iteration 8668: train loss = 0.2823 test loss = 0.3950\n","Iteration 8669: train loss = 0.2822 test loss = 0.3950\n","Iteration 8670: train loss = 0.2822 test loss = 0.3950\n","Iteration 8671: train loss = 0.2822 test loss = 0.3950\n","Iteration 8672: train loss = 0.2822 test loss = 0.3950\n","Iteration 8673: train loss = 0.2822 test loss = 0.3950\n","Iteration 8674: train loss = 0.2821 test loss = 0.3950\n","Iteration 8675: train loss = 0.2821 test loss = 0.3949\n","Iteration 8676: train loss = 0.2821 test loss = 0.3949\n","Iteration 8677: train loss = 0.2821 test loss = 0.3949\n","Iteration 8678: train loss = 0.2820 test loss = 0.3949\n","Iteration 8679: train loss = 0.2820 test loss = 0.3949\n","Iteration 8680: train loss = 0.2820 test loss = 0.3949\n","Iteration 8681: train loss = 0.2820 test loss = 0.3948\n","Iteration 8682: train loss = 0.2819 test loss = 0.3948\n","Iteration 8683: train loss = 0.2819 test loss = 0.3948\n","Iteration 8684: train loss = 0.2819 test loss = 0.3948\n","Iteration 8685: train loss = 0.2819 test loss = 0.3948\n","Iteration 8686: train loss = 0.2818 test loss = 0.3948\n","Iteration 8687: train loss = 0.2818 test loss = 0.3948\n","Iteration 8688: train loss = 0.2818 test loss = 0.3947\n","Iteration 8689: train loss = 0.2818 test loss = 0.3947\n","Iteration 8690: train loss = 0.2817 test loss = 0.3947\n","Iteration 8691: train loss = 0.2817 test loss = 0.3947\n","Iteration 8692: train loss = 0.2817 test loss = 0.3947\n","Iteration 8693: train loss = 0.2817 test loss = 0.3947\n","Iteration 8694: train loss = 0.2817 test loss = 0.3946\n","Iteration 8695: train loss = 0.2816 test loss = 0.3946\n","Iteration 8696: train loss = 0.2816 test loss = 0.3946\n","Iteration 8697: train loss = 0.2816 test loss = 0.3946\n","Iteration 8698: train loss = 0.2816 test loss = 0.3946\n","Iteration 8699: train loss = 0.2815 test loss = 0.3946\n","Iteration 8700: train loss = 0.2815 test loss = 0.3946\n","Iteration 8701: train loss = 0.2815 test loss = 0.3945\n","Iteration 8702: train loss = 0.2815 test loss = 0.3945\n","Iteration 8703: train loss = 0.2814 test loss = 0.3945\n","Iteration 8704: train loss = 0.2814 test loss = 0.3945\n","Iteration 8705: train loss = 0.2814 test loss = 0.3945\n","Iteration 8706: train loss = 0.2814 test loss = 0.3945\n","Iteration 8707: train loss = 0.2813 test loss = 0.3945\n","Iteration 8708: train loss = 0.2813 test loss = 0.3944\n","Iteration 8709: train loss = 0.2813 test loss = 0.3944\n","Iteration 8710: train loss = 0.2813 test loss = 0.3944\n","Iteration 8711: train loss = 0.2812 test loss = 0.3944\n","Iteration 8712: train loss = 0.2812 test loss = 0.3944\n","Iteration 8713: train loss = 0.2812 test loss = 0.3944\n","Iteration 8714: train loss = 0.2812 test loss = 0.3943\n","Iteration 8715: train loss = 0.2811 test loss = 0.3943\n","Iteration 8716: train loss = 0.2811 test loss = 0.3943\n","Iteration 8717: train loss = 0.2811 test loss = 0.3943\n","Iteration 8718: train loss = 0.2811 test loss = 0.3943\n","Iteration 8719: train loss = 0.2811 test loss = 0.3943\n","Iteration 8720: train loss = 0.2810 test loss = 0.3943\n","Iteration 8721: train loss = 0.2810 test loss = 0.3942\n","Iteration 8722: train loss = 0.2810 test loss = 0.3942\n","Iteration 8723: train loss = 0.2810 test loss = 0.3942\n","Iteration 8724: train loss = 0.2809 test loss = 0.3942\n","Iteration 8725: train loss = 0.2809 test loss = 0.3942\n","Iteration 8726: train loss = 0.2809 test loss = 0.3942\n","Iteration 8727: train loss = 0.2809 test loss = 0.3942\n","Iteration 8728: train loss = 0.2808 test loss = 0.3941\n","Iteration 8729: train loss = 0.2808 test loss = 0.3941\n","Iteration 8730: train loss = 0.2808 test loss = 0.3941\n","Iteration 8731: train loss = 0.2808 test loss = 0.3941\n","Iteration 8732: train loss = 0.2807 test loss = 0.3941\n","Iteration 8733: train loss = 0.2807 test loss = 0.3941\n","Iteration 8734: train loss = 0.2807 test loss = 0.3941\n","Iteration 8735: train loss = 0.2807 test loss = 0.3940\n","Iteration 8736: train loss = 0.2806 test loss = 0.3940\n","Iteration 8737: train loss = 0.2806 test loss = 0.3940\n","Iteration 8738: train loss = 0.2806 test loss = 0.3940\n","Iteration 8739: train loss = 0.2806 test loss = 0.3940\n","Iteration 8740: train loss = 0.2806 test loss = 0.3940\n","Iteration 8741: train loss = 0.2805 test loss = 0.3939\n","Iteration 8742: train loss = 0.2805 test loss = 0.3939\n","Iteration 8743: train loss = 0.2805 test loss = 0.3939\n","Iteration 8744: train loss = 0.2805 test loss = 0.3939\n","Iteration 8745: train loss = 0.2804 test loss = 0.3939\n","Iteration 8746: train loss = 0.2804 test loss = 0.3939\n","Iteration 8747: train loss = 0.2804 test loss = 0.3939\n","Iteration 8748: train loss = 0.2804 test loss = 0.3938\n","Iteration 8749: train loss = 0.2803 test loss = 0.3938\n","Iteration 8750: train loss = 0.2803 test loss = 0.3938\n","Iteration 8751: train loss = 0.2803 test loss = 0.3938\n","Iteration 8752: train loss = 0.2803 test loss = 0.3938\n","Iteration 8753: train loss = 0.2802 test loss = 0.3938\n","Iteration 8754: train loss = 0.2802 test loss = 0.3938\n","Iteration 8755: train loss = 0.2802 test loss = 0.3937\n","Iteration 8756: train loss = 0.2802 test loss = 0.3937\n","Iteration 8757: train loss = 0.2802 test loss = 0.3937\n","Iteration 8758: train loss = 0.2801 test loss = 0.3937\n","Iteration 8759: train loss = 0.2801 test loss = 0.3937\n","Iteration 8760: train loss = 0.2801 test loss = 0.3937\n","Iteration 8761: train loss = 0.2801 test loss = 0.3936\n","Iteration 8762: train loss = 0.2800 test loss = 0.3936\n","Iteration 8763: train loss = 0.2800 test loss = 0.3936\n","Iteration 8764: train loss = 0.2800 test loss = 0.3936\n","Iteration 8765: train loss = 0.2800 test loss = 0.3936\n","Iteration 8766: train loss = 0.2799 test loss = 0.3936\n","Iteration 8767: train loss = 0.2799 test loss = 0.3936\n","Iteration 8768: train loss = 0.2799 test loss = 0.3935\n","Iteration 8769: train loss = 0.2799 test loss = 0.3935\n","Iteration 8770: train loss = 0.2798 test loss = 0.3935\n","Iteration 8771: train loss = 0.2798 test loss = 0.3935\n","Iteration 8772: train loss = 0.2798 test loss = 0.3935\n","Iteration 8773: train loss = 0.2798 test loss = 0.3935\n","Iteration 8774: train loss = 0.2797 test loss = 0.3935\n","Iteration 8775: train loss = 0.2797 test loss = 0.3934\n","Iteration 8776: train loss = 0.2797 test loss = 0.3934\n","Iteration 8777: train loss = 0.2797 test loss = 0.3934\n","Iteration 8778: train loss = 0.2797 test loss = 0.3934\n","Iteration 8779: train loss = 0.2796 test loss = 0.3934\n","Iteration 8780: train loss = 0.2796 test loss = 0.3934\n","Iteration 8781: train loss = 0.2796 test loss = 0.3934\n","Iteration 8782: train loss = 0.2796 test loss = 0.3933\n","Iteration 8783: train loss = 0.2795 test loss = 0.3933\n","Iteration 8784: train loss = 0.2795 test loss = 0.3933\n","Iteration 8785: train loss = 0.2795 test loss = 0.3933\n","Iteration 8786: train loss = 0.2795 test loss = 0.3933\n","Iteration 8787: train loss = 0.2794 test loss = 0.3933\n","Iteration 8788: train loss = 0.2794 test loss = 0.3932\n","Iteration 8789: train loss = 0.2794 test loss = 0.3932\n","Iteration 8790: train loss = 0.2794 test loss = 0.3932\n","Iteration 8791: train loss = 0.2793 test loss = 0.3932\n","Iteration 8792: train loss = 0.2793 test loss = 0.3932\n","Iteration 8793: train loss = 0.2793 test loss = 0.3932\n","Iteration 8794: train loss = 0.2793 test loss = 0.3932\n","Iteration 8795: train loss = 0.2793 test loss = 0.3931\n","Iteration 8796: train loss = 0.2792 test loss = 0.3931\n","Iteration 8797: train loss = 0.2792 test loss = 0.3931\n","Iteration 8798: train loss = 0.2792 test loss = 0.3931\n","Iteration 8799: train loss = 0.2792 test loss = 0.3931\n","Iteration 8800: train loss = 0.2791 test loss = 0.3931\n","Iteration 8801: train loss = 0.2791 test loss = 0.3931\n","Iteration 8802: train loss = 0.2791 test loss = 0.3930\n","Iteration 8803: train loss = 0.2791 test loss = 0.3930\n","Iteration 8804: train loss = 0.2790 test loss = 0.3930\n","Iteration 8805: train loss = 0.2790 test loss = 0.3930\n","Iteration 8806: train loss = 0.2790 test loss = 0.3930\n","Iteration 8807: train loss = 0.2790 test loss = 0.3930\n","Iteration 8808: train loss = 0.2789 test loss = 0.3930\n","Iteration 8809: train loss = 0.2789 test loss = 0.3929\n","Iteration 8810: train loss = 0.2789 test loss = 0.3929\n","Iteration 8811: train loss = 0.2789 test loss = 0.3929\n","Iteration 8812: train loss = 0.2789 test loss = 0.3929\n","Iteration 8813: train loss = 0.2788 test loss = 0.3929\n","Iteration 8814: train loss = 0.2788 test loss = 0.3929\n","Iteration 8815: train loss = 0.2788 test loss = 0.3928\n","Iteration 8816: train loss = 0.2788 test loss = 0.3928\n","Iteration 8817: train loss = 0.2787 test loss = 0.3928\n","Iteration 8818: train loss = 0.2787 test loss = 0.3928\n","Iteration 8819: train loss = 0.2787 test loss = 0.3928\n","Iteration 8820: train loss = 0.2787 test loss = 0.3928\n","Iteration 8821: train loss = 0.2786 test loss = 0.3928\n","Iteration 8822: train loss = 0.2786 test loss = 0.3927\n","Iteration 8823: train loss = 0.2786 test loss = 0.3927\n","Iteration 8824: train loss = 0.2786 test loss = 0.3927\n","Iteration 8825: train loss = 0.2785 test loss = 0.3927\n","Iteration 8826: train loss = 0.2785 test loss = 0.3927\n","Iteration 8827: train loss = 0.2785 test loss = 0.3927\n","Iteration 8828: train loss = 0.2785 test loss = 0.3927\n","Iteration 8829: train loss = 0.2785 test loss = 0.3926\n","Iteration 8830: train loss = 0.2784 test loss = 0.3926\n","Iteration 8831: train loss = 0.2784 test loss = 0.3926\n","Iteration 8832: train loss = 0.2784 test loss = 0.3926\n","Iteration 8833: train loss = 0.2784 test loss = 0.3926\n","Iteration 8834: train loss = 0.2783 test loss = 0.3926\n","Iteration 8835: train loss = 0.2783 test loss = 0.3926\n","Iteration 8836: train loss = 0.2783 test loss = 0.3925\n","Iteration 8837: train loss = 0.2783 test loss = 0.3925\n","Iteration 8838: train loss = 0.2782 test loss = 0.3925\n","Iteration 8839: train loss = 0.2782 test loss = 0.3925\n","Iteration 8840: train loss = 0.2782 test loss = 0.3925\n","Iteration 8841: train loss = 0.2782 test loss = 0.3925\n","Iteration 8842: train loss = 0.2781 test loss = 0.3924\n","Iteration 8843: train loss = 0.2781 test loss = 0.3924\n","Iteration 8844: train loss = 0.2781 test loss = 0.3924\n","Iteration 8845: train loss = 0.2781 test loss = 0.3924\n","Iteration 8846: train loss = 0.2781 test loss = 0.3924\n","Iteration 8847: train loss = 0.2780 test loss = 0.3924\n","Iteration 8848: train loss = 0.2780 test loss = 0.3924\n","Iteration 8849: train loss = 0.2780 test loss = 0.3923\n","Iteration 8850: train loss = 0.2780 test loss = 0.3923\n","Iteration 8851: train loss = 0.2779 test loss = 0.3923\n","Iteration 8852: train loss = 0.2779 test loss = 0.3923\n","Iteration 8853: train loss = 0.2779 test loss = 0.3923\n","Iteration 8854: train loss = 0.2779 test loss = 0.3923\n","Iteration 8855: train loss = 0.2778 test loss = 0.3923\n","Iteration 8856: train loss = 0.2778 test loss = 0.3922\n","Iteration 8857: train loss = 0.2778 test loss = 0.3922\n","Iteration 8858: train loss = 0.2778 test loss = 0.3922\n","Iteration 8859: train loss = 0.2777 test loss = 0.3922\n","Iteration 8860: train loss = 0.2777 test loss = 0.3922\n","Iteration 8861: train loss = 0.2777 test loss = 0.3922\n","Iteration 8862: train loss = 0.2777 test loss = 0.3922\n","Iteration 8863: train loss = 0.2777 test loss = 0.3921\n","Iteration 8864: train loss = 0.2776 test loss = 0.3921\n","Iteration 8865: train loss = 0.2776 test loss = 0.3921\n","Iteration 8866: train loss = 0.2776 test loss = 0.3921\n","Iteration 8867: train loss = 0.2776 test loss = 0.3921\n","Iteration 8868: train loss = 0.2775 test loss = 0.3921\n","Iteration 8869: train loss = 0.2775 test loss = 0.3921\n","Iteration 8870: train loss = 0.2775 test loss = 0.3920\n","Iteration 8871: train loss = 0.2775 test loss = 0.3920\n","Iteration 8872: train loss = 0.2774 test loss = 0.3920\n","Iteration 8873: train loss = 0.2774 test loss = 0.3920\n","Iteration 8874: train loss = 0.2774 test loss = 0.3920\n","Iteration 8875: train loss = 0.2774 test loss = 0.3920\n","Iteration 8876: train loss = 0.2773 test loss = 0.3920\n","Iteration 8877: train loss = 0.2773 test loss = 0.3919\n","Iteration 8878: train loss = 0.2773 test loss = 0.3919\n","Iteration 8879: train loss = 0.2773 test loss = 0.3919\n","Iteration 8880: train loss = 0.2773 test loss = 0.3919\n","Iteration 8881: train loss = 0.2772 test loss = 0.3919\n","Iteration 8882: train loss = 0.2772 test loss = 0.3919\n","Iteration 8883: train loss = 0.2772 test loss = 0.3918\n","Iteration 8884: train loss = 0.2772 test loss = 0.3918\n","Iteration 8885: train loss = 0.2771 test loss = 0.3918\n","Iteration 8886: train loss = 0.2771 test loss = 0.3918\n","Iteration 8887: train loss = 0.2771 test loss = 0.3918\n","Iteration 8888: train loss = 0.2771 test loss = 0.3918\n","Iteration 8889: train loss = 0.2770 test loss = 0.3918\n","Iteration 8890: train loss = 0.2770 test loss = 0.3917\n","Iteration 8891: train loss = 0.2770 test loss = 0.3917\n","Iteration 8892: train loss = 0.2770 test loss = 0.3917\n","Iteration 8893: train loss = 0.2770 test loss = 0.3917\n","Iteration 8894: train loss = 0.2769 test loss = 0.3917\n","Iteration 8895: train loss = 0.2769 test loss = 0.3917\n","Iteration 8896: train loss = 0.2769 test loss = 0.3917\n","Iteration 8897: train loss = 0.2769 test loss = 0.3916\n","Iteration 8898: train loss = 0.2768 test loss = 0.3916\n","Iteration 8899: train loss = 0.2768 test loss = 0.3916\n","Iteration 8900: train loss = 0.2768 test loss = 0.3916\n","Iteration 8901: train loss = 0.2768 test loss = 0.3916\n","Iteration 8902: train loss = 0.2767 test loss = 0.3916\n","Iteration 8903: train loss = 0.2767 test loss = 0.3916\n","Iteration 8904: train loss = 0.2767 test loss = 0.3915\n","Iteration 8905: train loss = 0.2767 test loss = 0.3915\n","Iteration 8906: train loss = 0.2766 test loss = 0.3915\n","Iteration 8907: train loss = 0.2766 test loss = 0.3915\n","Iteration 8908: train loss = 0.2766 test loss = 0.3915\n","Iteration 8909: train loss = 0.2766 test loss = 0.3915\n","Iteration 8910: train loss = 0.2766 test loss = 0.3915\n","Iteration 8911: train loss = 0.2765 test loss = 0.3914\n","Iteration 8912: train loss = 0.2765 test loss = 0.3914\n","Iteration 8913: train loss = 0.2765 test loss = 0.3914\n","Iteration 8914: train loss = 0.2765 test loss = 0.3914\n","Iteration 8915: train loss = 0.2764 test loss = 0.3914\n","Iteration 8916: train loss = 0.2764 test loss = 0.3914\n","Iteration 8917: train loss = 0.2764 test loss = 0.3914\n","Iteration 8918: train loss = 0.2764 test loss = 0.3913\n","Iteration 8919: train loss = 0.2763 test loss = 0.3913\n","Iteration 8920: train loss = 0.2763 test loss = 0.3913\n","Iteration 8921: train loss = 0.2763 test loss = 0.3913\n","Iteration 8922: train loss = 0.2763 test loss = 0.3913\n","Iteration 8923: train loss = 0.2763 test loss = 0.3913\n","Iteration 8924: train loss = 0.2762 test loss = 0.3913\n","Iteration 8925: train loss = 0.2762 test loss = 0.3912\n","Iteration 8926: train loss = 0.2762 test loss = 0.3912\n","Iteration 8927: train loss = 0.2762 test loss = 0.3912\n","Iteration 8928: train loss = 0.2761 test loss = 0.3912\n","Iteration 8929: train loss = 0.2761 test loss = 0.3912\n","Iteration 8930: train loss = 0.2761 test loss = 0.3912\n","Iteration 8931: train loss = 0.2761 test loss = 0.3912\n","Iteration 8932: train loss = 0.2760 test loss = 0.3911\n","Iteration 8933: train loss = 0.2760 test loss = 0.3911\n","Iteration 8934: train loss = 0.2760 test loss = 0.3911\n","Iteration 8935: train loss = 0.2760 test loss = 0.3911\n","Iteration 8936: train loss = 0.2760 test loss = 0.3911\n","Iteration 8937: train loss = 0.2759 test loss = 0.3911\n","Iteration 8938: train loss = 0.2759 test loss = 0.3910\n","Iteration 8939: train loss = 0.2759 test loss = 0.3910\n","Iteration 8940: train loss = 0.2759 test loss = 0.3910\n","Iteration 8941: train loss = 0.2758 test loss = 0.3910\n","Iteration 8942: train loss = 0.2758 test loss = 0.3910\n","Iteration 8943: train loss = 0.2758 test loss = 0.3910\n","Iteration 8944: train loss = 0.2758 test loss = 0.3910\n","Iteration 8945: train loss = 0.2757 test loss = 0.3909\n","Iteration 8946: train loss = 0.2757 test loss = 0.3909\n","Iteration 8947: train loss = 0.2757 test loss = 0.3909\n","Iteration 8948: train loss = 0.2757 test loss = 0.3909\n","Iteration 8949: train loss = 0.2757 test loss = 0.3909\n","Iteration 8950: train loss = 0.2756 test loss = 0.3909\n","Iteration 8951: train loss = 0.2756 test loss = 0.3909\n","Iteration 8952: train loss = 0.2756 test loss = 0.3908\n","Iteration 8953: train loss = 0.2756 test loss = 0.3908\n","Iteration 8954: train loss = 0.2755 test loss = 0.3908\n","Iteration 8955: train loss = 0.2755 test loss = 0.3908\n","Iteration 8956: train loss = 0.2755 test loss = 0.3908\n","Iteration 8957: train loss = 0.2755 test loss = 0.3908\n","Iteration 8958: train loss = 0.2754 test loss = 0.3908\n","Iteration 8959: train loss = 0.2754 test loss = 0.3907\n","Iteration 8960: train loss = 0.2754 test loss = 0.3907\n","Iteration 8961: train loss = 0.2754 test loss = 0.3907\n","Iteration 8962: train loss = 0.2753 test loss = 0.3907\n","Iteration 8963: train loss = 0.2753 test loss = 0.3907\n","Iteration 8964: train loss = 0.2753 test loss = 0.3907\n","Iteration 8965: train loss = 0.2753 test loss = 0.3907\n","Iteration 8966: train loss = 0.2753 test loss = 0.3906\n","Iteration 8967: train loss = 0.2752 test loss = 0.3906\n","Iteration 8968: train loss = 0.2752 test loss = 0.3906\n","Iteration 8969: train loss = 0.2752 test loss = 0.3906\n","Iteration 8970: train loss = 0.2752 test loss = 0.3906\n","Iteration 8971: train loss = 0.2751 test loss = 0.3906\n","Iteration 8972: train loss = 0.2751 test loss = 0.3906\n","Iteration 8973: train loss = 0.2751 test loss = 0.3905\n","Iteration 8974: train loss = 0.2751 test loss = 0.3905\n","Iteration 8975: train loss = 0.2750 test loss = 0.3905\n","Iteration 8976: train loss = 0.2750 test loss = 0.3905\n","Iteration 8977: train loss = 0.2750 test loss = 0.3905\n","Iteration 8978: train loss = 0.2750 test loss = 0.3905\n","Iteration 8979: train loss = 0.2750 test loss = 0.3905\n","Iteration 8980: train loss = 0.2749 test loss = 0.3904\n","Iteration 8981: train loss = 0.2749 test loss = 0.3904\n","Iteration 8982: train loss = 0.2749 test loss = 0.3904\n","Iteration 8983: train loss = 0.2749 test loss = 0.3904\n","Iteration 8984: train loss = 0.2748 test loss = 0.3904\n","Iteration 8985: train loss = 0.2748 test loss = 0.3904\n","Iteration 8986: train loss = 0.2748 test loss = 0.3904\n","Iteration 8987: train loss = 0.2748 test loss = 0.3903\n","Iteration 8988: train loss = 0.2747 test loss = 0.3903\n","Iteration 8989: train loss = 0.2747 test loss = 0.3903\n","Iteration 8990: train loss = 0.2747 test loss = 0.3903\n","Iteration 8991: train loss = 0.2747 test loss = 0.3903\n","Iteration 8992: train loss = 0.2747 test loss = 0.3903\n","Iteration 8993: train loss = 0.2746 test loss = 0.3903\n","Iteration 8994: train loss = 0.2746 test loss = 0.3902\n","Iteration 8995: train loss = 0.2746 test loss = 0.3902\n","Iteration 8996: train loss = 0.2746 test loss = 0.3902\n","Iteration 8997: train loss = 0.2745 test loss = 0.3902\n","Iteration 8998: train loss = 0.2745 test loss = 0.3902\n","Iteration 8999: train loss = 0.2745 test loss = 0.3902\n","Iteration 9000: train loss = 0.2745 test loss = 0.3902\n","Iteration 9001: train loss = 0.2744 test loss = 0.3901\n","Iteration 9002: train loss = 0.2744 test loss = 0.3901\n","Iteration 9003: train loss = 0.2744 test loss = 0.3901\n","Iteration 9004: train loss = 0.2744 test loss = 0.3901\n","Iteration 9005: train loss = 0.2744 test loss = 0.3901\n","Iteration 9006: train loss = 0.2743 test loss = 0.3901\n","Iteration 9007: train loss = 0.2743 test loss = 0.3901\n","Iteration 9008: train loss = 0.2743 test loss = 0.3900\n","Iteration 9009: train loss = 0.2743 test loss = 0.3900\n","Iteration 9010: train loss = 0.2742 test loss = 0.3900\n","Iteration 9011: train loss = 0.2742 test loss = 0.3900\n","Iteration 9012: train loss = 0.2742 test loss = 0.3900\n","Iteration 9013: train loss = 0.2742 test loss = 0.3900\n","Iteration 9014: train loss = 0.2741 test loss = 0.3900\n","Iteration 9015: train loss = 0.2741 test loss = 0.3899\n","Iteration 9016: train loss = 0.2741 test loss = 0.3899\n","Iteration 9017: train loss = 0.2741 test loss = 0.3899\n","Iteration 9018: train loss = 0.2741 test loss = 0.3899\n","Iteration 9019: train loss = 0.2740 test loss = 0.3899\n","Iteration 9020: train loss = 0.2740 test loss = 0.3899\n","Iteration 9021: train loss = 0.2740 test loss = 0.3899\n","Iteration 9022: train loss = 0.2740 test loss = 0.3898\n","Iteration 9023: train loss = 0.2739 test loss = 0.3898\n","Iteration 9024: train loss = 0.2739 test loss = 0.3898\n","Iteration 9025: train loss = 0.2739 test loss = 0.3898\n","Iteration 9026: train loss = 0.2739 test loss = 0.3898\n","Iteration 9027: train loss = 0.2739 test loss = 0.3898\n","Iteration 9028: train loss = 0.2738 test loss = 0.3898\n","Iteration 9029: train loss = 0.2738 test loss = 0.3897\n","Iteration 9030: train loss = 0.2738 test loss = 0.3897\n","Iteration 9031: train loss = 0.2738 test loss = 0.3897\n","Iteration 9032: train loss = 0.2737 test loss = 0.3897\n","Iteration 9033: train loss = 0.2737 test loss = 0.3897\n","Iteration 9034: train loss = 0.2737 test loss = 0.3897\n","Iteration 9035: train loss = 0.2737 test loss = 0.3897\n","Iteration 9036: train loss = 0.2736 test loss = 0.3896\n","Iteration 9037: train loss = 0.2736 test loss = 0.3896\n","Iteration 9038: train loss = 0.2736 test loss = 0.3896\n","Iteration 9039: train loss = 0.2736 test loss = 0.3896\n","Iteration 9040: train loss = 0.2736 test loss = 0.3896\n","Iteration 9041: train loss = 0.2735 test loss = 0.3896\n","Iteration 9042: train loss = 0.2735 test loss = 0.3896\n","Iteration 9043: train loss = 0.2735 test loss = 0.3895\n","Iteration 9044: train loss = 0.2735 test loss = 0.3895\n","Iteration 9045: train loss = 0.2734 test loss = 0.3895\n","Iteration 9046: train loss = 0.2734 test loss = 0.3895\n","Iteration 9047: train loss = 0.2734 test loss = 0.3895\n","Iteration 9048: train loss = 0.2734 test loss = 0.3895\n","Iteration 9049: train loss = 0.2733 test loss = 0.3895\n","Iteration 9050: train loss = 0.2733 test loss = 0.3894\n","Iteration 9051: train loss = 0.2733 test loss = 0.3894\n","Iteration 9052: train loss = 0.2733 test loss = 0.3894\n","Iteration 9053: train loss = 0.2733 test loss = 0.3894\n","Iteration 9054: train loss = 0.2732 test loss = 0.3894\n","Iteration 9055: train loss = 0.2732 test loss = 0.3894\n","Iteration 9056: train loss = 0.2732 test loss = 0.3894\n","Iteration 9057: train loss = 0.2732 test loss = 0.3893\n","Iteration 9058: train loss = 0.2731 test loss = 0.3893\n","Iteration 9059: train loss = 0.2731 test loss = 0.3893\n","Iteration 9060: train loss = 0.2731 test loss = 0.3893\n","Iteration 9061: train loss = 0.2731 test loss = 0.3893\n","Iteration 9062: train loss = 0.2730 test loss = 0.3893\n","Iteration 9063: train loss = 0.2730 test loss = 0.3893\n","Iteration 9064: train loss = 0.2730 test loss = 0.3892\n","Iteration 9065: train loss = 0.2730 test loss = 0.3892\n","Iteration 9066: train loss = 0.2730 test loss = 0.3892\n","Iteration 9067: train loss = 0.2729 test loss = 0.3892\n","Iteration 9068: train loss = 0.2729 test loss = 0.3892\n","Iteration 9069: train loss = 0.2729 test loss = 0.3892\n","Iteration 9070: train loss = 0.2729 test loss = 0.3892\n","Iteration 9071: train loss = 0.2728 test loss = 0.3891\n","Iteration 9072: train loss = 0.2728 test loss = 0.3891\n","Iteration 9073: train loss = 0.2728 test loss = 0.3891\n","Iteration 9074: train loss = 0.2728 test loss = 0.3891\n","Iteration 9075: train loss = 0.2728 test loss = 0.3891\n","Iteration 9076: train loss = 0.2727 test loss = 0.3891\n","Iteration 9077: train loss = 0.2727 test loss = 0.3891\n","Iteration 9078: train loss = 0.2727 test loss = 0.3890\n","Iteration 9079: train loss = 0.2727 test loss = 0.3890\n","Iteration 9080: train loss = 0.2726 test loss = 0.3890\n","Iteration 9081: train loss = 0.2726 test loss = 0.3890\n","Iteration 9082: train loss = 0.2726 test loss = 0.3890\n","Iteration 9083: train loss = 0.2726 test loss = 0.3890\n","Iteration 9084: train loss = 0.2725 test loss = 0.3890\n","Iteration 9085: train loss = 0.2725 test loss = 0.3889\n","Iteration 9086: train loss = 0.2725 test loss = 0.3889\n","Iteration 9087: train loss = 0.2725 test loss = 0.3889\n","Iteration 9088: train loss = 0.2725 test loss = 0.3889\n","Iteration 9089: train loss = 0.2724 test loss = 0.3889\n","Iteration 9090: train loss = 0.2724 test loss = 0.3889\n","Iteration 9091: train loss = 0.2724 test loss = 0.3889\n","Iteration 9092: train loss = 0.2724 test loss = 0.3888\n","Iteration 9093: train loss = 0.2723 test loss = 0.3888\n","Iteration 9094: train loss = 0.2723 test loss = 0.3888\n","Iteration 9095: train loss = 0.2723 test loss = 0.3888\n","Iteration 9096: train loss = 0.2723 test loss = 0.3888\n","Iteration 9097: train loss = 0.2722 test loss = 0.3888\n","Iteration 9098: train loss = 0.2722 test loss = 0.3888\n","Iteration 9099: train loss = 0.2722 test loss = 0.3887\n","Iteration 9100: train loss = 0.2722 test loss = 0.3887\n","Iteration 9101: train loss = 0.2722 test loss = 0.3887\n","Iteration 9102: train loss = 0.2721 test loss = 0.3887\n","Iteration 9103: train loss = 0.2721 test loss = 0.3887\n","Iteration 9104: train loss = 0.2721 test loss = 0.3887\n","Iteration 9105: train loss = 0.2721 test loss = 0.3887\n","Iteration 9106: train loss = 0.2720 test loss = 0.3887\n","Iteration 9107: train loss = 0.2720 test loss = 0.3886\n","Iteration 9108: train loss = 0.2720 test loss = 0.3886\n","Iteration 9109: train loss = 0.2720 test loss = 0.3886\n","Iteration 9110: train loss = 0.2720 test loss = 0.3886\n","Iteration 9111: train loss = 0.2719 test loss = 0.3886\n","Iteration 9112: train loss = 0.2719 test loss = 0.3886\n","Iteration 9113: train loss = 0.2719 test loss = 0.3886\n","Iteration 9114: train loss = 0.2719 test loss = 0.3885\n","Iteration 9115: train loss = 0.2718 test loss = 0.3885\n","Iteration 9116: train loss = 0.2718 test loss = 0.3885\n","Iteration 9117: train loss = 0.2718 test loss = 0.3885\n","Iteration 9118: train loss = 0.2718 test loss = 0.3885\n","Iteration 9119: train loss = 0.2717 test loss = 0.3885\n","Iteration 9120: train loss = 0.2717 test loss = 0.3885\n","Iteration 9121: train loss = 0.2717 test loss = 0.3884\n","Iteration 9122: train loss = 0.2717 test loss = 0.3884\n","Iteration 9123: train loss = 0.2717 test loss = 0.3884\n","Iteration 9124: train loss = 0.2716 test loss = 0.3884\n","Iteration 9125: train loss = 0.2716 test loss = 0.3884\n","Iteration 9126: train loss = 0.2716 test loss = 0.3884\n","Iteration 9127: train loss = 0.2716 test loss = 0.3884\n","Iteration 9128: train loss = 0.2715 test loss = 0.3883\n","Iteration 9129: train loss = 0.2715 test loss = 0.3883\n","Iteration 9130: train loss = 0.2715 test loss = 0.3883\n","Iteration 9131: train loss = 0.2715 test loss = 0.3883\n","Iteration 9132: train loss = 0.2715 test loss = 0.3883\n","Iteration 9133: train loss = 0.2714 test loss = 0.3883\n","Iteration 9134: train loss = 0.2714 test loss = 0.3883\n","Iteration 9135: train loss = 0.2714 test loss = 0.3882\n","Iteration 9136: train loss = 0.2714 test loss = 0.3882\n","Iteration 9137: train loss = 0.2713 test loss = 0.3882\n","Iteration 9138: train loss = 0.2713 test loss = 0.3882\n","Iteration 9139: train loss = 0.2713 test loss = 0.3882\n","Iteration 9140: train loss = 0.2713 test loss = 0.3882\n","Iteration 9141: train loss = 0.2712 test loss = 0.3882\n","Iteration 9142: train loss = 0.2712 test loss = 0.3881\n","Iteration 9143: train loss = 0.2712 test loss = 0.3881\n","Iteration 9144: train loss = 0.2712 test loss = 0.3881\n","Iteration 9145: train loss = 0.2712 test loss = 0.3881\n","Iteration 9146: train loss = 0.2711 test loss = 0.3881\n","Iteration 9147: train loss = 0.2711 test loss = 0.3881\n","Iteration 9148: train loss = 0.2711 test loss = 0.3881\n","Iteration 9149: train loss = 0.2711 test loss = 0.3880\n","Iteration 9150: train loss = 0.2710 test loss = 0.3880\n","Iteration 9151: train loss = 0.2710 test loss = 0.3880\n","Iteration 9152: train loss = 0.2710 test loss = 0.3880\n","Iteration 9153: train loss = 0.2710 test loss = 0.3880\n","Iteration 9154: train loss = 0.2710 test loss = 0.3880\n","Iteration 9155: train loss = 0.2709 test loss = 0.3880\n","Iteration 9156: train loss = 0.2709 test loss = 0.3879\n","Iteration 9157: train loss = 0.2709 test loss = 0.3879\n","Iteration 9158: train loss = 0.2709 test loss = 0.3879\n","Iteration 9159: train loss = 0.2708 test loss = 0.3879\n","Iteration 9160: train loss = 0.2708 test loss = 0.3879\n","Iteration 9161: train loss = 0.2708 test loss = 0.3879\n","Iteration 9162: train loss = 0.2708 test loss = 0.3879\n","Iteration 9163: train loss = 0.2708 test loss = 0.3879\n","Iteration 9164: train loss = 0.2707 test loss = 0.3878\n","Iteration 9165: train loss = 0.2707 test loss = 0.3878\n","Iteration 9166: train loss = 0.2707 test loss = 0.3878\n","Iteration 9167: train loss = 0.2707 test loss = 0.3878\n","Iteration 9168: train loss = 0.2706 test loss = 0.3878\n","Iteration 9169: train loss = 0.2706 test loss = 0.3878\n","Iteration 9170: train loss = 0.2706 test loss = 0.3878\n","Iteration 9171: train loss = 0.2706 test loss = 0.3877\n","Iteration 9172: train loss = 0.2705 test loss = 0.3877\n","Iteration 9173: train loss = 0.2705 test loss = 0.3877\n","Iteration 9174: train loss = 0.2705 test loss = 0.3877\n","Iteration 9175: train loss = 0.2705 test loss = 0.3877\n","Iteration 9176: train loss = 0.2705 test loss = 0.3877\n","Iteration 9177: train loss = 0.2704 test loss = 0.3877\n","Iteration 9178: train loss = 0.2704 test loss = 0.3876\n","Iteration 9179: train loss = 0.2704 test loss = 0.3876\n","Iteration 9180: train loss = 0.2704 test loss = 0.3876\n","Iteration 9181: train loss = 0.2703 test loss = 0.3876\n","Iteration 9182: train loss = 0.2703 test loss = 0.3876\n","Iteration 9183: train loss = 0.2703 test loss = 0.3876\n","Iteration 9184: train loss = 0.2703 test loss = 0.3876\n","Iteration 9185: train loss = 0.2703 test loss = 0.3875\n","Iteration 9186: train loss = 0.2702 test loss = 0.3875\n","Iteration 9187: train loss = 0.2702 test loss = 0.3875\n","Iteration 9188: train loss = 0.2702 test loss = 0.3875\n","Iteration 9189: train loss = 0.2702 test loss = 0.3875\n","Iteration 9190: train loss = 0.2701 test loss = 0.3875\n","Iteration 9191: train loss = 0.2701 test loss = 0.3875\n","Iteration 9192: train loss = 0.2701 test loss = 0.3874\n","Iteration 9193: train loss = 0.2701 test loss = 0.3874\n","Iteration 9194: train loss = 0.2701 test loss = 0.3874\n","Iteration 9195: train loss = 0.2700 test loss = 0.3874\n","Iteration 9196: train loss = 0.2700 test loss = 0.3874\n","Iteration 9197: train loss = 0.2700 test loss = 0.3874\n","Iteration 9198: train loss = 0.2700 test loss = 0.3874\n","Iteration 9199: train loss = 0.2699 test loss = 0.3873\n","Iteration 9200: train loss = 0.2699 test loss = 0.3873\n","Iteration 9201: train loss = 0.2699 test loss = 0.3873\n","Iteration 9202: train loss = 0.2699 test loss = 0.3873\n","Iteration 9203: train loss = 0.2698 test loss = 0.3873\n","Iteration 9204: train loss = 0.2698 test loss = 0.3873\n","Iteration 9205: train loss = 0.2698 test loss = 0.3873\n","Iteration 9206: train loss = 0.2698 test loss = 0.3873\n","Iteration 9207: train loss = 0.2698 test loss = 0.3872\n","Iteration 9208: train loss = 0.2697 test loss = 0.3872\n","Iteration 9209: train loss = 0.2697 test loss = 0.3872\n","Iteration 9210: train loss = 0.2697 test loss = 0.3872\n","Iteration 9211: train loss = 0.2697 test loss = 0.3872\n","Iteration 9212: train loss = 0.2696 test loss = 0.3872\n","Iteration 9213: train loss = 0.2696 test loss = 0.3872\n","Iteration 9214: train loss = 0.2696 test loss = 0.3871\n","Iteration 9215: train loss = 0.2696 test loss = 0.3871\n","Iteration 9216: train loss = 0.2696 test loss = 0.3871\n","Iteration 9217: train loss = 0.2695 test loss = 0.3871\n","Iteration 9218: train loss = 0.2695 test loss = 0.3871\n","Iteration 9219: train loss = 0.2695 test loss = 0.3871\n","Iteration 9220: train loss = 0.2695 test loss = 0.3871\n","Iteration 9221: train loss = 0.2694 test loss = 0.3870\n","Iteration 9222: train loss = 0.2694 test loss = 0.3870\n","Iteration 9223: train loss = 0.2694 test loss = 0.3870\n","Iteration 9224: train loss = 0.2694 test loss = 0.3870\n","Iteration 9225: train loss = 0.2694 test loss = 0.3870\n","Iteration 9226: train loss = 0.2693 test loss = 0.3870\n","Iteration 9227: train loss = 0.2693 test loss = 0.3870\n","Iteration 9228: train loss = 0.2693 test loss = 0.3869\n","Iteration 9229: train loss = 0.2693 test loss = 0.3869\n","Iteration 9230: train loss = 0.2692 test loss = 0.3869\n","Iteration 9231: train loss = 0.2692 test loss = 0.3869\n","Iteration 9232: train loss = 0.2692 test loss = 0.3869\n","Iteration 9233: train loss = 0.2692 test loss = 0.3869\n","Iteration 9234: train loss = 0.2692 test loss = 0.3869\n","Iteration 9235: train loss = 0.2691 test loss = 0.3869\n","Iteration 9236: train loss = 0.2691 test loss = 0.3868\n","Iteration 9237: train loss = 0.2691 test loss = 0.3868\n","Iteration 9238: train loss = 0.2691 test loss = 0.3868\n","Iteration 9239: train loss = 0.2690 test loss = 0.3868\n","Iteration 9240: train loss = 0.2690 test loss = 0.3868\n","Iteration 9241: train loss = 0.2690 test loss = 0.3868\n","Iteration 9242: train loss = 0.2690 test loss = 0.3868\n","Iteration 9243: train loss = 0.2690 test loss = 0.3867\n","Iteration 9244: train loss = 0.2689 test loss = 0.3867\n","Iteration 9245: train loss = 0.2689 test loss = 0.3867\n","Iteration 9246: train loss = 0.2689 test loss = 0.3867\n","Iteration 9247: train loss = 0.2689 test loss = 0.3867\n","Iteration 9248: train loss = 0.2688 test loss = 0.3867\n","Iteration 9249: train loss = 0.2688 test loss = 0.3867\n","Iteration 9250: train loss = 0.2688 test loss = 0.3866\n","Iteration 9251: train loss = 0.2688 test loss = 0.3866\n","Iteration 9252: train loss = 0.2687 test loss = 0.3866\n","Iteration 9253: train loss = 0.2687 test loss = 0.3866\n","Iteration 9254: train loss = 0.2687 test loss = 0.3866\n","Iteration 9255: train loss = 0.2687 test loss = 0.3866\n","Iteration 9256: train loss = 0.2687 test loss = 0.3866\n","Iteration 9257: train loss = 0.2686 test loss = 0.3865\n","Iteration 9258: train loss = 0.2686 test loss = 0.3865\n","Iteration 9259: train loss = 0.2686 test loss = 0.3865\n","Iteration 9260: train loss = 0.2686 test loss = 0.3865\n","Iteration 9261: train loss = 0.2685 test loss = 0.3865\n","Iteration 9262: train loss = 0.2685 test loss = 0.3865\n","Iteration 9263: train loss = 0.2685 test loss = 0.3865\n","Iteration 9264: train loss = 0.2685 test loss = 0.3865\n","Iteration 9265: train loss = 0.2685 test loss = 0.3864\n","Iteration 9266: train loss = 0.2684 test loss = 0.3864\n","Iteration 9267: train loss = 0.2684 test loss = 0.3864\n","Iteration 9268: train loss = 0.2684 test loss = 0.3864\n","Iteration 9269: train loss = 0.2684 test loss = 0.3864\n","Iteration 9270: train loss = 0.2683 test loss = 0.3864\n","Iteration 9271: train loss = 0.2683 test loss = 0.3864\n","Iteration 9272: train loss = 0.2683 test loss = 0.3863\n","Iteration 9273: train loss = 0.2683 test loss = 0.3863\n","Iteration 9274: train loss = 0.2683 test loss = 0.3863\n","Iteration 9275: train loss = 0.2682 test loss = 0.3863\n","Iteration 9276: train loss = 0.2682 test loss = 0.3863\n","Iteration 9277: train loss = 0.2682 test loss = 0.3863\n","Iteration 9278: train loss = 0.2682 test loss = 0.3863\n","Iteration 9279: train loss = 0.2681 test loss = 0.3862\n","Iteration 9280: train loss = 0.2681 test loss = 0.3862\n","Iteration 9281: train loss = 0.2681 test loss = 0.3862\n","Iteration 9282: train loss = 0.2681 test loss = 0.3862\n","Iteration 9283: train loss = 0.2681 test loss = 0.3862\n","Iteration 9284: train loss = 0.2680 test loss = 0.3862\n","Iteration 9285: train loss = 0.2680 test loss = 0.3862\n","Iteration 9286: train loss = 0.2680 test loss = 0.3861\n","Iteration 9287: train loss = 0.2680 test loss = 0.3861\n","Iteration 9288: train loss = 0.2679 test loss = 0.3861\n","Iteration 9289: train loss = 0.2679 test loss = 0.3861\n","Iteration 9290: train loss = 0.2679 test loss = 0.3861\n","Iteration 9291: train loss = 0.2679 test loss = 0.3861\n","Iteration 9292: train loss = 0.2679 test loss = 0.3861\n","Iteration 9293: train loss = 0.2678 test loss = 0.3861\n","Iteration 9294: train loss = 0.2678 test loss = 0.3860\n","Iteration 9295: train loss = 0.2678 test loss = 0.3860\n","Iteration 9296: train loss = 0.2678 test loss = 0.3860\n","Iteration 9297: train loss = 0.2677 test loss = 0.3860\n","Iteration 9298: train loss = 0.2677 test loss = 0.3860\n","Iteration 9299: train loss = 0.2677 test loss = 0.3860\n","Iteration 9300: train loss = 0.2677 test loss = 0.3860\n","Iteration 9301: train loss = 0.2677 test loss = 0.3859\n","Iteration 9302: train loss = 0.2676 test loss = 0.3859\n","Iteration 9303: train loss = 0.2676 test loss = 0.3859\n","Iteration 9304: train loss = 0.2676 test loss = 0.3859\n","Iteration 9305: train loss = 0.2676 test loss = 0.3859\n","Iteration 9306: train loss = 0.2675 test loss = 0.3859\n","Iteration 9307: train loss = 0.2675 test loss = 0.3859\n","Iteration 9308: train loss = 0.2675 test loss = 0.3858\n","Iteration 9309: train loss = 0.2675 test loss = 0.3858\n","Iteration 9310: train loss = 0.2675 test loss = 0.3858\n","Iteration 9311: train loss = 0.2674 test loss = 0.3858\n","Iteration 9312: train loss = 0.2674 test loss = 0.3858\n","Iteration 9313: train loss = 0.2674 test loss = 0.3858\n","Iteration 9314: train loss = 0.2674 test loss = 0.3858\n","Iteration 9315: train loss = 0.2673 test loss = 0.3858\n","Iteration 9316: train loss = 0.2673 test loss = 0.3857\n","Iteration 9317: train loss = 0.2673 test loss = 0.3857\n","Iteration 9318: train loss = 0.2673 test loss = 0.3857\n","Iteration 9319: train loss = 0.2673 test loss = 0.3857\n","Iteration 9320: train loss = 0.2672 test loss = 0.3857\n","Iteration 9321: train loss = 0.2672 test loss = 0.3857\n","Iteration 9322: train loss = 0.2672 test loss = 0.3857\n","Iteration 9323: train loss = 0.2672 test loss = 0.3856\n","Iteration 9324: train loss = 0.2671 test loss = 0.3856\n","Iteration 9325: train loss = 0.2671 test loss = 0.3856\n","Iteration 9326: train loss = 0.2671 test loss = 0.3856\n","Iteration 9327: train loss = 0.2671 test loss = 0.3856\n","Iteration 9328: train loss = 0.2671 test loss = 0.3856\n","Iteration 9329: train loss = 0.2670 test loss = 0.3856\n","Iteration 9330: train loss = 0.2670 test loss = 0.3855\n","Iteration 9331: train loss = 0.2670 test loss = 0.3855\n","Iteration 9332: train loss = 0.2670 test loss = 0.3855\n","Iteration 9333: train loss = 0.2669 test loss = 0.3855\n","Iteration 9334: train loss = 0.2669 test loss = 0.3855\n","Iteration 9335: train loss = 0.2669 test loss = 0.3855\n","Iteration 9336: train loss = 0.2669 test loss = 0.3855\n","Iteration 9337: train loss = 0.2669 test loss = 0.3855\n","Iteration 9338: train loss = 0.2668 test loss = 0.3854\n","Iteration 9339: train loss = 0.2668 test loss = 0.3854\n","Iteration 9340: train loss = 0.2668 test loss = 0.3854\n","Iteration 9341: train loss = 0.2668 test loss = 0.3854\n","Iteration 9342: train loss = 0.2667 test loss = 0.3854\n","Iteration 9343: train loss = 0.2667 test loss = 0.3854\n","Iteration 9344: train loss = 0.2667 test loss = 0.3854\n","Iteration 9345: train loss = 0.2667 test loss = 0.3853\n","Iteration 9346: train loss = 0.2667 test loss = 0.3853\n","Iteration 9347: train loss = 0.2666 test loss = 0.3853\n","Iteration 9348: train loss = 0.2666 test loss = 0.3853\n","Iteration 9349: train loss = 0.2666 test loss = 0.3853\n","Iteration 9350: train loss = 0.2666 test loss = 0.3853\n","Iteration 9351: train loss = 0.2665 test loss = 0.3853\n","Iteration 9352: train loss = 0.2665 test loss = 0.3853\n","Iteration 9353: train loss = 0.2665 test loss = 0.3852\n","Iteration 9354: train loss = 0.2665 test loss = 0.3852\n","Iteration 9355: train loss = 0.2665 test loss = 0.3852\n","Iteration 9356: train loss = 0.2664 test loss = 0.3852\n","Iteration 9357: train loss = 0.2664 test loss = 0.3852\n","Iteration 9358: train loss = 0.2664 test loss = 0.3852\n","Iteration 9359: train loss = 0.2664 test loss = 0.3852\n","Iteration 9360: train loss = 0.2663 test loss = 0.3851\n","Iteration 9361: train loss = 0.2663 test loss = 0.3851\n","Iteration 9362: train loss = 0.2663 test loss = 0.3851\n","Iteration 9363: train loss = 0.2663 test loss = 0.3851\n","Iteration 9364: train loss = 0.2663 test loss = 0.3851\n","Iteration 9365: train loss = 0.2662 test loss = 0.3851\n","Iteration 9366: train loss = 0.2662 test loss = 0.3851\n","Iteration 9367: train loss = 0.2662 test loss = 0.3850\n","Iteration 9368: train loss = 0.2662 test loss = 0.3850\n","Iteration 9369: train loss = 0.2661 test loss = 0.3850\n","Iteration 9370: train loss = 0.2661 test loss = 0.3850\n","Iteration 9371: train loss = 0.2661 test loss = 0.3850\n","Iteration 9372: train loss = 0.2661 test loss = 0.3850\n","Iteration 9373: train loss = 0.2661 test loss = 0.3850\n","Iteration 9374: train loss = 0.2660 test loss = 0.3850\n","Iteration 9375: train loss = 0.2660 test loss = 0.3849\n","Iteration 9376: train loss = 0.2660 test loss = 0.3849\n","Iteration 9377: train loss = 0.2660 test loss = 0.3849\n","Iteration 9378: train loss = 0.2659 test loss = 0.3849\n","Iteration 9379: train loss = 0.2659 test loss = 0.3849\n","Iteration 9380: train loss = 0.2659 test loss = 0.3849\n","Iteration 9381: train loss = 0.2659 test loss = 0.3849\n","Iteration 9382: train loss = 0.2659 test loss = 0.3848\n","Iteration 9383: train loss = 0.2658 test loss = 0.3848\n","Iteration 9384: train loss = 0.2658 test loss = 0.3848\n","Iteration 9385: train loss = 0.2658 test loss = 0.3848\n","Iteration 9386: train loss = 0.2658 test loss = 0.3848\n","Iteration 9387: train loss = 0.2658 test loss = 0.3848\n","Iteration 9388: train loss = 0.2657 test loss = 0.3848\n","Iteration 9389: train loss = 0.2657 test loss = 0.3848\n","Iteration 9390: train loss = 0.2657 test loss = 0.3847\n","Iteration 9391: train loss = 0.2657 test loss = 0.3847\n","Iteration 9392: train loss = 0.2656 test loss = 0.3847\n","Iteration 9393: train loss = 0.2656 test loss = 0.3847\n","Iteration 9394: train loss = 0.2656 test loss = 0.3847\n","Iteration 9395: train loss = 0.2656 test loss = 0.3847\n","Iteration 9396: train loss = 0.2656 test loss = 0.3847\n","Iteration 9397: train loss = 0.2655 test loss = 0.3846\n","Iteration 9398: train loss = 0.2655 test loss = 0.3846\n","Iteration 9399: train loss = 0.2655 test loss = 0.3846\n","Iteration 9400: train loss = 0.2655 test loss = 0.3846\n","Iteration 9401: train loss = 0.2654 test loss = 0.3846\n","Iteration 9402: train loss = 0.2654 test loss = 0.3846\n","Iteration 9403: train loss = 0.2654 test loss = 0.3846\n","Iteration 9404: train loss = 0.2654 test loss = 0.3845\n","Iteration 9405: train loss = 0.2654 test loss = 0.3845\n","Iteration 9406: train loss = 0.2653 test loss = 0.3845\n","Iteration 9407: train loss = 0.2653 test loss = 0.3845\n","Iteration 9408: train loss = 0.2653 test loss = 0.3845\n","Iteration 9409: train loss = 0.2653 test loss = 0.3845\n","Iteration 9410: train loss = 0.2652 test loss = 0.3845\n","Iteration 9411: train loss = 0.2652 test loss = 0.3845\n","Iteration 9412: train loss = 0.2652 test loss = 0.3844\n","Iteration 9413: train loss = 0.2652 test loss = 0.3844\n","Iteration 9414: train loss = 0.2652 test loss = 0.3844\n","Iteration 9415: train loss = 0.2651 test loss = 0.3844\n","Iteration 9416: train loss = 0.2651 test loss = 0.3844\n","Iteration 9417: train loss = 0.2651 test loss = 0.3844\n","Iteration 9418: train loss = 0.2651 test loss = 0.3844\n","Iteration 9419: train loss = 0.2650 test loss = 0.3843\n","Iteration 9420: train loss = 0.2650 test loss = 0.3843\n","Iteration 9421: train loss = 0.2650 test loss = 0.3843\n","Iteration 9422: train loss = 0.2650 test loss = 0.3843\n","Iteration 9423: train loss = 0.2650 test loss = 0.3843\n","Iteration 9424: train loss = 0.2649 test loss = 0.3843\n","Iteration 9425: train loss = 0.2649 test loss = 0.3843\n","Iteration 9426: train loss = 0.2649 test loss = 0.3843\n","Iteration 9427: train loss = 0.2649 test loss = 0.3842\n","Iteration 9428: train loss = 0.2648 test loss = 0.3842\n","Iteration 9429: train loss = 0.2648 test loss = 0.3842\n","Iteration 9430: train loss = 0.2648 test loss = 0.3842\n","Iteration 9431: train loss = 0.2648 test loss = 0.3842\n","Iteration 9432: train loss = 0.2648 test loss = 0.3842\n","Iteration 9433: train loss = 0.2647 test loss = 0.3842\n","Iteration 9434: train loss = 0.2647 test loss = 0.3841\n","Iteration 9435: train loss = 0.2647 test loss = 0.3841\n","Iteration 9436: train loss = 0.2647 test loss = 0.3841\n","Iteration 9437: train loss = 0.2647 test loss = 0.3841\n","Iteration 9438: train loss = 0.2646 test loss = 0.3841\n","Iteration 9439: train loss = 0.2646 test loss = 0.3841\n","Iteration 9440: train loss = 0.2646 test loss = 0.3841\n","Iteration 9441: train loss = 0.2646 test loss = 0.3841\n","Iteration 9442: train loss = 0.2645 test loss = 0.3840\n","Iteration 9443: train loss = 0.2645 test loss = 0.3840\n","Iteration 9444: train loss = 0.2645 test loss = 0.3840\n","Iteration 9445: train loss = 0.2645 test loss = 0.3840\n","Iteration 9446: train loss = 0.2645 test loss = 0.3840\n","Iteration 9447: train loss = 0.2644 test loss = 0.3840\n","Iteration 9448: train loss = 0.2644 test loss = 0.3840\n","Iteration 9449: train loss = 0.2644 test loss = 0.3839\n","Iteration 9450: train loss = 0.2644 test loss = 0.3839\n","Iteration 9451: train loss = 0.2643 test loss = 0.3839\n","Iteration 9452: train loss = 0.2643 test loss = 0.3839\n","Iteration 9453: train loss = 0.2643 test loss = 0.3839\n","Iteration 9454: train loss = 0.2643 test loss = 0.3839\n","Iteration 9455: train loss = 0.2643 test loss = 0.3839\n","Iteration 9456: train loss = 0.2642 test loss = 0.3839\n","Iteration 9457: train loss = 0.2642 test loss = 0.3838\n","Iteration 9458: train loss = 0.2642 test loss = 0.3838\n","Iteration 9459: train loss = 0.2642 test loss = 0.3838\n","Iteration 9460: train loss = 0.2641 test loss = 0.3838\n","Iteration 9461: train loss = 0.2641 test loss = 0.3838\n","Iteration 9462: train loss = 0.2641 test loss = 0.3838\n","Iteration 9463: train loss = 0.2641 test loss = 0.3838\n","Iteration 9464: train loss = 0.2641 test loss = 0.3837\n","Iteration 9465: train loss = 0.2640 test loss = 0.3837\n","Iteration 9466: train loss = 0.2640 test loss = 0.3837\n","Iteration 9467: train loss = 0.2640 test loss = 0.3837\n","Iteration 9468: train loss = 0.2640 test loss = 0.3837\n","Iteration 9469: train loss = 0.2640 test loss = 0.3837\n","Iteration 9470: train loss = 0.2639 test loss = 0.3837\n","Iteration 9471: train loss = 0.2639 test loss = 0.3837\n","Iteration 9472: train loss = 0.2639 test loss = 0.3836\n","Iteration 9473: train loss = 0.2639 test loss = 0.3836\n","Iteration 9474: train loss = 0.2638 test loss = 0.3836\n","Iteration 9475: train loss = 0.2638 test loss = 0.3836\n","Iteration 9476: train loss = 0.2638 test loss = 0.3836\n","Iteration 9477: train loss = 0.2638 test loss = 0.3836\n","Iteration 9478: train loss = 0.2638 test loss = 0.3836\n","Iteration 9479: train loss = 0.2637 test loss = 0.3835\n","Iteration 9480: train loss = 0.2637 test loss = 0.3835\n","Iteration 9481: train loss = 0.2637 test loss = 0.3835\n","Iteration 9482: train loss = 0.2637 test loss = 0.3835\n","Iteration 9483: train loss = 0.2636 test loss = 0.3835\n","Iteration 9484: train loss = 0.2636 test loss = 0.3835\n","Iteration 9485: train loss = 0.2636 test loss = 0.3835\n","Iteration 9486: train loss = 0.2636 test loss = 0.3835\n","Iteration 9487: train loss = 0.2636 test loss = 0.3834\n","Iteration 9488: train loss = 0.2635 test loss = 0.3834\n","Iteration 9489: train loss = 0.2635 test loss = 0.3834\n","Iteration 9490: train loss = 0.2635 test loss = 0.3834\n","Iteration 9491: train loss = 0.2635 test loss = 0.3834\n","Iteration 9492: train loss = 0.2635 test loss = 0.3834\n","Iteration 9493: train loss = 0.2634 test loss = 0.3834\n","Iteration 9494: train loss = 0.2634 test loss = 0.3833\n","Iteration 9495: train loss = 0.2634 test loss = 0.3833\n","Iteration 9496: train loss = 0.2634 test loss = 0.3833\n","Iteration 9497: train loss = 0.2633 test loss = 0.3833\n","Iteration 9498: train loss = 0.2633 test loss = 0.3833\n","Iteration 9499: train loss = 0.2633 test loss = 0.3833\n","Iteration 9500: train loss = 0.2633 test loss = 0.3833\n","Iteration 9501: train loss = 0.2633 test loss = 0.3833\n","Iteration 9502: train loss = 0.2632 test loss = 0.3832\n","Iteration 9503: train loss = 0.2632 test loss = 0.3832\n","Iteration 9504: train loss = 0.2632 test loss = 0.3832\n","Iteration 9505: train loss = 0.2632 test loss = 0.3832\n","Iteration 9506: train loss = 0.2631 test loss = 0.3832\n","Iteration 9507: train loss = 0.2631 test loss = 0.3832\n","Iteration 9508: train loss = 0.2631 test loss = 0.3832\n","Iteration 9509: train loss = 0.2631 test loss = 0.3831\n","Iteration 9510: train loss = 0.2631 test loss = 0.3831\n","Iteration 9511: train loss = 0.2630 test loss = 0.3831\n","Iteration 9512: train loss = 0.2630 test loss = 0.3831\n","Iteration 9513: train loss = 0.2630 test loss = 0.3831\n","Iteration 9514: train loss = 0.2630 test loss = 0.3831\n","Iteration 9515: train loss = 0.2630 test loss = 0.3831\n","Iteration 9516: train loss = 0.2629 test loss = 0.3831\n","Iteration 9517: train loss = 0.2629 test loss = 0.3830\n","Iteration 9518: train loss = 0.2629 test loss = 0.3830\n","Iteration 9519: train loss = 0.2629 test loss = 0.3830\n","Iteration 9520: train loss = 0.2628 test loss = 0.3830\n","Iteration 9521: train loss = 0.2628 test loss = 0.3830\n","Iteration 9522: train loss = 0.2628 test loss = 0.3830\n","Iteration 9523: train loss = 0.2628 test loss = 0.3830\n","Iteration 9524: train loss = 0.2628 test loss = 0.3830\n","Iteration 9525: train loss = 0.2627 test loss = 0.3829\n","Iteration 9526: train loss = 0.2627 test loss = 0.3829\n","Iteration 9527: train loss = 0.2627 test loss = 0.3829\n","Iteration 9528: train loss = 0.2627 test loss = 0.3829\n","Iteration 9529: train loss = 0.2626 test loss = 0.3829\n","Iteration 9530: train loss = 0.2626 test loss = 0.3829\n","Iteration 9531: train loss = 0.2626 test loss = 0.3829\n","Iteration 9532: train loss = 0.2626 test loss = 0.3828\n","Iteration 9533: train loss = 0.2626 test loss = 0.3828\n","Iteration 9534: train loss = 0.2625 test loss = 0.3828\n","Iteration 9535: train loss = 0.2625 test loss = 0.3828\n","Iteration 9536: train loss = 0.2625 test loss = 0.3828\n","Iteration 9537: train loss = 0.2625 test loss = 0.3828\n","Iteration 9538: train loss = 0.2625 test loss = 0.3828\n","Iteration 9539: train loss = 0.2624 test loss = 0.3828\n","Iteration 9540: train loss = 0.2624 test loss = 0.3827\n","Iteration 9541: train loss = 0.2624 test loss = 0.3827\n","Iteration 9542: train loss = 0.2624 test loss = 0.3827\n","Iteration 9543: train loss = 0.2623 test loss = 0.3827\n","Iteration 9544: train loss = 0.2623 test loss = 0.3827\n","Iteration 9545: train loss = 0.2623 test loss = 0.3827\n","Iteration 9546: train loss = 0.2623 test loss = 0.3827\n","Iteration 9547: train loss = 0.2623 test loss = 0.3826\n","Iteration 9548: train loss = 0.2622 test loss = 0.3826\n","Iteration 9549: train loss = 0.2622 test loss = 0.3826\n","Iteration 9550: train loss = 0.2622 test loss = 0.3826\n","Iteration 9551: train loss = 0.2622 test loss = 0.3826\n","Iteration 9552: train loss = 0.2621 test loss = 0.3826\n","Iteration 9553: train loss = 0.2621 test loss = 0.3826\n","Iteration 9554: train loss = 0.2621 test loss = 0.3826\n","Iteration 9555: train loss = 0.2621 test loss = 0.3825\n","Iteration 9556: train loss = 0.2621 test loss = 0.3825\n","Iteration 9557: train loss = 0.2620 test loss = 0.3825\n","Iteration 9558: train loss = 0.2620 test loss = 0.3825\n","Iteration 9559: train loss = 0.2620 test loss = 0.3825\n","Iteration 9560: train loss = 0.2620 test loss = 0.3825\n","Iteration 9561: train loss = 0.2620 test loss = 0.3825\n","Iteration 9562: train loss = 0.2619 test loss = 0.3825\n","Iteration 9563: train loss = 0.2619 test loss = 0.3824\n","Iteration 9564: train loss = 0.2619 test loss = 0.3824\n","Iteration 9565: train loss = 0.2619 test loss = 0.3824\n","Iteration 9566: train loss = 0.2618 test loss = 0.3824\n","Iteration 9567: train loss = 0.2618 test loss = 0.3824\n","Iteration 9568: train loss = 0.2618 test loss = 0.3824\n","Iteration 9569: train loss = 0.2618 test loss = 0.3824\n","Iteration 9570: train loss = 0.2618 test loss = 0.3823\n","Iteration 9571: train loss = 0.2617 test loss = 0.3823\n","Iteration 9572: train loss = 0.2617 test loss = 0.3823\n","Iteration 9573: train loss = 0.2617 test loss = 0.3823\n","Iteration 9574: train loss = 0.2617 test loss = 0.3823\n","Iteration 9575: train loss = 0.2617 test loss = 0.3823\n","Iteration 9576: train loss = 0.2616 test loss = 0.3823\n","Iteration 9577: train loss = 0.2616 test loss = 0.3823\n","Iteration 9578: train loss = 0.2616 test loss = 0.3822\n","Iteration 9579: train loss = 0.2616 test loss = 0.3822\n","Iteration 9580: train loss = 0.2615 test loss = 0.3822\n","Iteration 9581: train loss = 0.2615 test loss = 0.3822\n","Iteration 9582: train loss = 0.2615 test loss = 0.3822\n","Iteration 9583: train loss = 0.2615 test loss = 0.3822\n","Iteration 9584: train loss = 0.2615 test loss = 0.3822\n","Iteration 9585: train loss = 0.2614 test loss = 0.3822\n","Iteration 9586: train loss = 0.2614 test loss = 0.3821\n","Iteration 9587: train loss = 0.2614 test loss = 0.3821\n","Iteration 9588: train loss = 0.2614 test loss = 0.3821\n","Iteration 9589: train loss = 0.2614 test loss = 0.3821\n","Iteration 9590: train loss = 0.2613 test loss = 0.3821\n","Iteration 9591: train loss = 0.2613 test loss = 0.3821\n","Iteration 9592: train loss = 0.2613 test loss = 0.3821\n","Iteration 9593: train loss = 0.2613 test loss = 0.3820\n","Iteration 9594: train loss = 0.2612 test loss = 0.3820\n","Iteration 9595: train loss = 0.2612 test loss = 0.3820\n","Iteration 9596: train loss = 0.2612 test loss = 0.3820\n","Iteration 9597: train loss = 0.2612 test loss = 0.3820\n","Iteration 9598: train loss = 0.2612 test loss = 0.3820\n","Iteration 9599: train loss = 0.2611 test loss = 0.3820\n","Iteration 9600: train loss = 0.2611 test loss = 0.3820\n","Iteration 9601: train loss = 0.2611 test loss = 0.3819\n","Iteration 9602: train loss = 0.2611 test loss = 0.3819\n","Iteration 9603: train loss = 0.2610 test loss = 0.3819\n","Iteration 9604: train loss = 0.2610 test loss = 0.3819\n","Iteration 9605: train loss = 0.2610 test loss = 0.3819\n","Iteration 9606: train loss = 0.2610 test loss = 0.3819\n","Iteration 9607: train loss = 0.2610 test loss = 0.3819\n","Iteration 9608: train loss = 0.2609 test loss = 0.3819\n","Iteration 9609: train loss = 0.2609 test loss = 0.3818\n","Iteration 9610: train loss = 0.2609 test loss = 0.3818\n","Iteration 9611: train loss = 0.2609 test loss = 0.3818\n","Iteration 9612: train loss = 0.2609 test loss = 0.3818\n","Iteration 9613: train loss = 0.2608 test loss = 0.3818\n","Iteration 9614: train loss = 0.2608 test loss = 0.3818\n","Iteration 9615: train loss = 0.2608 test loss = 0.3818\n","Iteration 9616: train loss = 0.2608 test loss = 0.3817\n","Iteration 9617: train loss = 0.2607 test loss = 0.3817\n","Iteration 9618: train loss = 0.2607 test loss = 0.3817\n","Iteration 9619: train loss = 0.2607 test loss = 0.3817\n","Iteration 9620: train loss = 0.2607 test loss = 0.3817\n","Iteration 9621: train loss = 0.2607 test loss = 0.3817\n","Iteration 9622: train loss = 0.2606 test loss = 0.3817\n","Iteration 9623: train loss = 0.2606 test loss = 0.3817\n","Iteration 9624: train loss = 0.2606 test loss = 0.3816\n","Iteration 9625: train loss = 0.2606 test loss = 0.3816\n","Iteration 9626: train loss = 0.2606 test loss = 0.3816\n","Iteration 9627: train loss = 0.2605 test loss = 0.3816\n","Iteration 9628: train loss = 0.2605 test loss = 0.3816\n","Iteration 9629: train loss = 0.2605 test loss = 0.3816\n","Iteration 9630: train loss = 0.2605 test loss = 0.3816\n","Iteration 9631: train loss = 0.2604 test loss = 0.3816\n","Iteration 9632: train loss = 0.2604 test loss = 0.3815\n","Iteration 9633: train loss = 0.2604 test loss = 0.3815\n","Iteration 9634: train loss = 0.2604 test loss = 0.3815\n","Iteration 9635: train loss = 0.2604 test loss = 0.3815\n","Iteration 9636: train loss = 0.2603 test loss = 0.3815\n","Iteration 9637: train loss = 0.2603 test loss = 0.3815\n","Iteration 9638: train loss = 0.2603 test loss = 0.3815\n","Iteration 9639: train loss = 0.2603 test loss = 0.3814\n","Iteration 9640: train loss = 0.2603 test loss = 0.3814\n","Iteration 9641: train loss = 0.2602 test loss = 0.3814\n","Iteration 9642: train loss = 0.2602 test loss = 0.3814\n","Iteration 9643: train loss = 0.2602 test loss = 0.3814\n","Iteration 9644: train loss = 0.2602 test loss = 0.3814\n","Iteration 9645: train loss = 0.2601 test loss = 0.3814\n","Iteration 9646: train loss = 0.2601 test loss = 0.3814\n","Iteration 9647: train loss = 0.2601 test loss = 0.3813\n","Iteration 9648: train loss = 0.2601 test loss = 0.3813\n","Iteration 9649: train loss = 0.2601 test loss = 0.3813\n","Iteration 9650: train loss = 0.2600 test loss = 0.3813\n","Iteration 9651: train loss = 0.2600 test loss = 0.3813\n","Iteration 9652: train loss = 0.2600 test loss = 0.3813\n","Iteration 9653: train loss = 0.2600 test loss = 0.3813\n","Iteration 9654: train loss = 0.2600 test loss = 0.3813\n","Iteration 9655: train loss = 0.2599 test loss = 0.3812\n","Iteration 9656: train loss = 0.2599 test loss = 0.3812\n","Iteration 9657: train loss = 0.2599 test loss = 0.3812\n","Iteration 9658: train loss = 0.2599 test loss = 0.3812\n","Iteration 9659: train loss = 0.2598 test loss = 0.3812\n","Iteration 9660: train loss = 0.2598 test loss = 0.3812\n","Iteration 9661: train loss = 0.2598 test loss = 0.3812\n","Iteration 9662: train loss = 0.2598 test loss = 0.3812\n","Iteration 9663: train loss = 0.2598 test loss = 0.3811\n","Iteration 9664: train loss = 0.2597 test loss = 0.3811\n","Iteration 9665: train loss = 0.2597 test loss = 0.3811\n","Iteration 9666: train loss = 0.2597 test loss = 0.3811\n","Iteration 9667: train loss = 0.2597 test loss = 0.3811\n","Iteration 9668: train loss = 0.2597 test loss = 0.3811\n","Iteration 9669: train loss = 0.2596 test loss = 0.3811\n","Iteration 9670: train loss = 0.2596 test loss = 0.3810\n","Iteration 9671: train loss = 0.2596 test loss = 0.3810\n","Iteration 9672: train loss = 0.2596 test loss = 0.3810\n","Iteration 9673: train loss = 0.2596 test loss = 0.3810\n","Iteration 9674: train loss = 0.2595 test loss = 0.3810\n","Iteration 9675: train loss = 0.2595 test loss = 0.3810\n","Iteration 9676: train loss = 0.2595 test loss = 0.3810\n","Iteration 9677: train loss = 0.2595 test loss = 0.3810\n","Iteration 9678: train loss = 0.2594 test loss = 0.3809\n","Iteration 9679: train loss = 0.2594 test loss = 0.3809\n","Iteration 9680: train loss = 0.2594 test loss = 0.3809\n","Iteration 9681: train loss = 0.2594 test loss = 0.3809\n","Iteration 9682: train loss = 0.2594 test loss = 0.3809\n","Iteration 9683: train loss = 0.2593 test loss = 0.3809\n","Iteration 9684: train loss = 0.2593 test loss = 0.3809\n","Iteration 9685: train loss = 0.2593 test loss = 0.3809\n","Iteration 9686: train loss = 0.2593 test loss = 0.3808\n","Iteration 9687: train loss = 0.2593 test loss = 0.3808\n","Iteration 9688: train loss = 0.2592 test loss = 0.3808\n","Iteration 9689: train loss = 0.2592 test loss = 0.3808\n","Iteration 9690: train loss = 0.2592 test loss = 0.3808\n","Iteration 9691: train loss = 0.2592 test loss = 0.3808\n","Iteration 9692: train loss = 0.2591 test loss = 0.3808\n","Iteration 9693: train loss = 0.2591 test loss = 0.3808\n","Iteration 9694: train loss = 0.2591 test loss = 0.3807\n","Iteration 9695: train loss = 0.2591 test loss = 0.3807\n","Iteration 9696: train loss = 0.2591 test loss = 0.3807\n","Iteration 9697: train loss = 0.2590 test loss = 0.3807\n","Iteration 9698: train loss = 0.2590 test loss = 0.3807\n","Iteration 9699: train loss = 0.2590 test loss = 0.3807\n","Iteration 9700: train loss = 0.2590 test loss = 0.3807\n","Iteration 9701: train loss = 0.2590 test loss = 0.3806\n","Iteration 9702: train loss = 0.2589 test loss = 0.3806\n","Iteration 9703: train loss = 0.2589 test loss = 0.3806\n","Iteration 9704: train loss = 0.2589 test loss = 0.3806\n","Iteration 9705: train loss = 0.2589 test loss = 0.3806\n","Iteration 9706: train loss = 0.2588 test loss = 0.3806\n","Iteration 9707: train loss = 0.2588 test loss = 0.3806\n","Iteration 9708: train loss = 0.2588 test loss = 0.3806\n","Iteration 9709: train loss = 0.2588 test loss = 0.3805\n","Iteration 9710: train loss = 0.2588 test loss = 0.3805\n","Iteration 9711: train loss = 0.2587 test loss = 0.3805\n","Iteration 9712: train loss = 0.2587 test loss = 0.3805\n","Iteration 9713: train loss = 0.2587 test loss = 0.3805\n","Iteration 9714: train loss = 0.2587 test loss = 0.3805\n","Iteration 9715: train loss = 0.2587 test loss = 0.3805\n","Iteration 9716: train loss = 0.2586 test loss = 0.3805\n","Iteration 9717: train loss = 0.2586 test loss = 0.3804\n","Iteration 9718: train loss = 0.2586 test loss = 0.3804\n","Iteration 9719: train loss = 0.2586 test loss = 0.3804\n","Iteration 9720: train loss = 0.2586 test loss = 0.3804\n","Iteration 9721: train loss = 0.2585 test loss = 0.3804\n","Iteration 9722: train loss = 0.2585 test loss = 0.3804\n","Iteration 9723: train loss = 0.2585 test loss = 0.3804\n","Iteration 9724: train loss = 0.2585 test loss = 0.3804\n","Iteration 9725: train loss = 0.2584 test loss = 0.3803\n","Iteration 9726: train loss = 0.2584 test loss = 0.3803\n","Iteration 9727: train loss = 0.2584 test loss = 0.3803\n","Iteration 9728: train loss = 0.2584 test loss = 0.3803\n","Iteration 9729: train loss = 0.2584 test loss = 0.3803\n","Iteration 9730: train loss = 0.2583 test loss = 0.3803\n","Iteration 9731: train loss = 0.2583 test loss = 0.3803\n","Iteration 9732: train loss = 0.2583 test loss = 0.3803\n","Iteration 9733: train loss = 0.2583 test loss = 0.3802\n","Iteration 9734: train loss = 0.2583 test loss = 0.3802\n","Iteration 9735: train loss = 0.2582 test loss = 0.3802\n","Iteration 9736: train loss = 0.2582 test loss = 0.3802\n","Iteration 9737: train loss = 0.2582 test loss = 0.3802\n","Iteration 9738: train loss = 0.2582 test loss = 0.3802\n","Iteration 9739: train loss = 0.2581 test loss = 0.3802\n","Iteration 9740: train loss = 0.2581 test loss = 0.3802\n","Iteration 9741: train loss = 0.2581 test loss = 0.3801\n","Iteration 9742: train loss = 0.2581 test loss = 0.3801\n","Iteration 9743: train loss = 0.2581 test loss = 0.3801\n","Iteration 9744: train loss = 0.2580 test loss = 0.3801\n","Iteration 9745: train loss = 0.2580 test loss = 0.3801\n","Iteration 9746: train loss = 0.2580 test loss = 0.3801\n","Iteration 9747: train loss = 0.2580 test loss = 0.3801\n","Iteration 9748: train loss = 0.2580 test loss = 0.3800\n","Iteration 9749: train loss = 0.2579 test loss = 0.3800\n","Iteration 9750: train loss = 0.2579 test loss = 0.3800\n","Iteration 9751: train loss = 0.2579 test loss = 0.3800\n","Iteration 9752: train loss = 0.2579 test loss = 0.3800\n","Iteration 9753: train loss = 0.2579 test loss = 0.3800\n","Iteration 9754: train loss = 0.2578 test loss = 0.3800\n","Iteration 9755: train loss = 0.2578 test loss = 0.3800\n","Iteration 9756: train loss = 0.2578 test loss = 0.3799\n","Iteration 9757: train loss = 0.2578 test loss = 0.3799\n","Iteration 9758: train loss = 0.2577 test loss = 0.3799\n","Iteration 9759: train loss = 0.2577 test loss = 0.3799\n","Iteration 9760: train loss = 0.2577 test loss = 0.3799\n","Iteration 9761: train loss = 0.2577 test loss = 0.3799\n","Iteration 9762: train loss = 0.2577 test loss = 0.3799\n","Iteration 9763: train loss = 0.2576 test loss = 0.3799\n","Iteration 9764: train loss = 0.2576 test loss = 0.3798\n","Iteration 9765: train loss = 0.2576 test loss = 0.3798\n","Iteration 9766: train loss = 0.2576 test loss = 0.3798\n","Iteration 9767: train loss = 0.2576 test loss = 0.3798\n","Iteration 9768: train loss = 0.2575 test loss = 0.3798\n","Iteration 9769: train loss = 0.2575 test loss = 0.3798\n","Iteration 9770: train loss = 0.2575 test loss = 0.3798\n","Iteration 9771: train loss = 0.2575 test loss = 0.3798\n","Iteration 9772: train loss = 0.2575 test loss = 0.3797\n","Iteration 9773: train loss = 0.2574 test loss = 0.3797\n","Iteration 9774: train loss = 0.2574 test loss = 0.3797\n","Iteration 9775: train loss = 0.2574 test loss = 0.3797\n","Iteration 9776: train loss = 0.2574 test loss = 0.3797\n","Iteration 9777: train loss = 0.2573 test loss = 0.3797\n","Iteration 9778: train loss = 0.2573 test loss = 0.3797\n","Iteration 9779: train loss = 0.2573 test loss = 0.3797\n","Iteration 9780: train loss = 0.2573 test loss = 0.3796\n","Iteration 9781: train loss = 0.2573 test loss = 0.3796\n","Iteration 9782: train loss = 0.2572 test loss = 0.3796\n","Iteration 9783: train loss = 0.2572 test loss = 0.3796\n","Iteration 9784: train loss = 0.2572 test loss = 0.3796\n","Iteration 9785: train loss = 0.2572 test loss = 0.3796\n","Iteration 9786: train loss = 0.2572 test loss = 0.3796\n","Iteration 9787: train loss = 0.2571 test loss = 0.3796\n","Iteration 9788: train loss = 0.2571 test loss = 0.3795\n","Iteration 9789: train loss = 0.2571 test loss = 0.3795\n","Iteration 9790: train loss = 0.2571 test loss = 0.3795\n","Iteration 9791: train loss = 0.2571 test loss = 0.3795\n","Iteration 9792: train loss = 0.2570 test loss = 0.3795\n","Iteration 9793: train loss = 0.2570 test loss = 0.3795\n","Iteration 9794: train loss = 0.2570 test loss = 0.3795\n","Iteration 9795: train loss = 0.2570 test loss = 0.3795\n","Iteration 9796: train loss = 0.2569 test loss = 0.3794\n","Iteration 9797: train loss = 0.2569 test loss = 0.3794\n","Iteration 9798: train loss = 0.2569 test loss = 0.3794\n","Iteration 9799: train loss = 0.2569 test loss = 0.3794\n","Iteration 9800: train loss = 0.2569 test loss = 0.3794\n","Iteration 9801: train loss = 0.2568 test loss = 0.3794\n","Iteration 9802: train loss = 0.2568 test loss = 0.3794\n","Iteration 9803: train loss = 0.2568 test loss = 0.3794\n","Iteration 9804: train loss = 0.2568 test loss = 0.3793\n","Iteration 9805: train loss = 0.2568 test loss = 0.3793\n","Iteration 9806: train loss = 0.2567 test loss = 0.3793\n","Iteration 9807: train loss = 0.2567 test loss = 0.3793\n","Iteration 9808: train loss = 0.2567 test loss = 0.3793\n","Iteration 9809: train loss = 0.2567 test loss = 0.3793\n","Iteration 9810: train loss = 0.2567 test loss = 0.3793\n","Iteration 9811: train loss = 0.2566 test loss = 0.3793\n","Iteration 9812: train loss = 0.2566 test loss = 0.3792\n","Iteration 9813: train loss = 0.2566 test loss = 0.3792\n","Iteration 9814: train loss = 0.2566 test loss = 0.3792\n","Iteration 9815: train loss = 0.2565 test loss = 0.3792\n","Iteration 9816: train loss = 0.2565 test loss = 0.3792\n","Iteration 9817: train loss = 0.2565 test loss = 0.3792\n","Iteration 9818: train loss = 0.2565 test loss = 0.3792\n","Iteration 9819: train loss = 0.2565 test loss = 0.3792\n","Iteration 9820: train loss = 0.2564 test loss = 0.3791\n","Iteration 9821: train loss = 0.2564 test loss = 0.3791\n","Iteration 9822: train loss = 0.2564 test loss = 0.3791\n","Iteration 9823: train loss = 0.2564 test loss = 0.3791\n","Iteration 9824: train loss = 0.2564 test loss = 0.3791\n","Iteration 9825: train loss = 0.2563 test loss = 0.3791\n","Iteration 9826: train loss = 0.2563 test loss = 0.3791\n","Iteration 9827: train loss = 0.2563 test loss = 0.3791\n","Iteration 9828: train loss = 0.2563 test loss = 0.3790\n","Iteration 9829: train loss = 0.2563 test loss = 0.3790\n","Iteration 9830: train loss = 0.2562 test loss = 0.3790\n","Iteration 9831: train loss = 0.2562 test loss = 0.3790\n","Iteration 9832: train loss = 0.2562 test loss = 0.3790\n","Iteration 9833: train loss = 0.2562 test loss = 0.3790\n","Iteration 9834: train loss = 0.2561 test loss = 0.3790\n","Iteration 9835: train loss = 0.2561 test loss = 0.3790\n","Iteration 9836: train loss = 0.2561 test loss = 0.3789\n","Iteration 9837: train loss = 0.2561 test loss = 0.3789\n","Iteration 9838: train loss = 0.2561 test loss = 0.3789\n","Iteration 9839: train loss = 0.2560 test loss = 0.3789\n","Iteration 9840: train loss = 0.2560 test loss = 0.3789\n","Iteration 9841: train loss = 0.2560 test loss = 0.3789\n","Iteration 9842: train loss = 0.2560 test loss = 0.3789\n","Iteration 9843: train loss = 0.2560 test loss = 0.3788\n","Iteration 9844: train loss = 0.2559 test loss = 0.3788\n","Iteration 9845: train loss = 0.2559 test loss = 0.3788\n","Iteration 9846: train loss = 0.2559 test loss = 0.3788\n","Iteration 9847: train loss = 0.2559 test loss = 0.3788\n","Iteration 9848: train loss = 0.2559 test loss = 0.3788\n","Iteration 9849: train loss = 0.2558 test loss = 0.3788\n","Iteration 9850: train loss = 0.2558 test loss = 0.3788\n","Iteration 9851: train loss = 0.2558 test loss = 0.3787\n","Iteration 9852: train loss = 0.2558 test loss = 0.3787\n","Iteration 9853: train loss = 0.2557 test loss = 0.3787\n","Iteration 9854: train loss = 0.2557 test loss = 0.3787\n","Iteration 9855: train loss = 0.2557 test loss = 0.3787\n","Iteration 9856: train loss = 0.2557 test loss = 0.3787\n","Iteration 9857: train loss = 0.2557 test loss = 0.3787\n","Iteration 9858: train loss = 0.2556 test loss = 0.3787\n","Iteration 9859: train loss = 0.2556 test loss = 0.3786\n","Iteration 9860: train loss = 0.2556 test loss = 0.3786\n","Iteration 9861: train loss = 0.2556 test loss = 0.3786\n","Iteration 9862: train loss = 0.2556 test loss = 0.3786\n","Iteration 9863: train loss = 0.2555 test loss = 0.3786\n","Iteration 9864: train loss = 0.2555 test loss = 0.3786\n","Iteration 9865: train loss = 0.2555 test loss = 0.3786\n","Iteration 9866: train loss = 0.2555 test loss = 0.3786\n","Iteration 9867: train loss = 0.2555 test loss = 0.3785\n","Iteration 9868: train loss = 0.2554 test loss = 0.3785\n","Iteration 9869: train loss = 0.2554 test loss = 0.3785\n","Iteration 9870: train loss = 0.2554 test loss = 0.3785\n","Iteration 9871: train loss = 0.2554 test loss = 0.3785\n","Iteration 9872: train loss = 0.2554 test loss = 0.3785\n","Iteration 9873: train loss = 0.2553 test loss = 0.3785\n","Iteration 9874: train loss = 0.2553 test loss = 0.3785\n","Iteration 9875: train loss = 0.2553 test loss = 0.3784\n","Iteration 9876: train loss = 0.2553 test loss = 0.3784\n","Iteration 9877: train loss = 0.2552 test loss = 0.3784\n","Iteration 9878: train loss = 0.2552 test loss = 0.3784\n","Iteration 9879: train loss = 0.2552 test loss = 0.3784\n","Iteration 9880: train loss = 0.2552 test loss = 0.3784\n","Iteration 9881: train loss = 0.2552 test loss = 0.3784\n","Iteration 9882: train loss = 0.2551 test loss = 0.3784\n","Iteration 9883: train loss = 0.2551 test loss = 0.3784\n","Iteration 9884: train loss = 0.2551 test loss = 0.3783\n","Iteration 9885: train loss = 0.2551 test loss = 0.3783\n","Iteration 9886: train loss = 0.2551 test loss = 0.3783\n","Iteration 9887: train loss = 0.2550 test loss = 0.3783\n","Iteration 9888: train loss = 0.2550 test loss = 0.3783\n","Iteration 9889: train loss = 0.2550 test loss = 0.3783\n","Iteration 9890: train loss = 0.2550 test loss = 0.3783\n","Iteration 9891: train loss = 0.2550 test loss = 0.3783\n","Iteration 9892: train loss = 0.2549 test loss = 0.3782\n","Iteration 9893: train loss = 0.2549 test loss = 0.3782\n","Iteration 9894: train loss = 0.2549 test loss = 0.3782\n","Iteration 9895: train loss = 0.2549 test loss = 0.3782\n","Iteration 9896: train loss = 0.2549 test loss = 0.3782\n","Iteration 9897: train loss = 0.2548 test loss = 0.3782\n","Iteration 9898: train loss = 0.2548 test loss = 0.3782\n","Iteration 9899: train loss = 0.2548 test loss = 0.3782\n","Iteration 9900: train loss = 0.2548 test loss = 0.3781\n","Iteration 9901: train loss = 0.2547 test loss = 0.3781\n","Iteration 9902: train loss = 0.2547 test loss = 0.3781\n","Iteration 9903: train loss = 0.2547 test loss = 0.3781\n","Iteration 9904: train loss = 0.2547 test loss = 0.3781\n","Iteration 9905: train loss = 0.2547 test loss = 0.3781\n","Iteration 9906: train loss = 0.2546 test loss = 0.3781\n","Iteration 9907: train loss = 0.2546 test loss = 0.3781\n","Iteration 9908: train loss = 0.2546 test loss = 0.3780\n","Iteration 9909: train loss = 0.2546 test loss = 0.3780\n","Iteration 9910: train loss = 0.2546 test loss = 0.3780\n","Iteration 9911: train loss = 0.2545 test loss = 0.3780\n","Iteration 9912: train loss = 0.2545 test loss = 0.3780\n","Iteration 9913: train loss = 0.2545 test loss = 0.3780\n","Iteration 9914: train loss = 0.2545 test loss = 0.3780\n","Iteration 9915: train loss = 0.2545 test loss = 0.3780\n","Iteration 9916: train loss = 0.2544 test loss = 0.3779\n","Iteration 9917: train loss = 0.2544 test loss = 0.3779\n","Iteration 9918: train loss = 0.2544 test loss = 0.3779\n","Iteration 9919: train loss = 0.2544 test loss = 0.3779\n","Iteration 9920: train loss = 0.2544 test loss = 0.3779\n","Iteration 9921: train loss = 0.2543 test loss = 0.3779\n","Iteration 9922: train loss = 0.2543 test loss = 0.3779\n","Iteration 9923: train loss = 0.2543 test loss = 0.3779\n","Iteration 9924: train loss = 0.2543 test loss = 0.3778\n","Iteration 9925: train loss = 0.2543 test loss = 0.3778\n","Iteration 9926: train loss = 0.2542 test loss = 0.3778\n","Iteration 9927: train loss = 0.2542 test loss = 0.3778\n","Iteration 9928: train loss = 0.2542 test loss = 0.3778\n","Iteration 9929: train loss = 0.2542 test loss = 0.3778\n","Iteration 9930: train loss = 0.2541 test loss = 0.3778\n","Iteration 9931: train loss = 0.2541 test loss = 0.3778\n","Iteration 9932: train loss = 0.2541 test loss = 0.3777\n","Iteration 9933: train loss = 0.2541 test loss = 0.3777\n","Iteration 9934: train loss = 0.2541 test loss = 0.3777\n","Iteration 9935: train loss = 0.2540 test loss = 0.3777\n","Iteration 9936: train loss = 0.2540 test loss = 0.3777\n","Iteration 9937: train loss = 0.2540 test loss = 0.3777\n","Iteration 9938: train loss = 0.2540 test loss = 0.3777\n","Iteration 9939: train loss = 0.2540 test loss = 0.3777\n","Iteration 9940: train loss = 0.2539 test loss = 0.3776\n","Iteration 9941: train loss = 0.2539 test loss = 0.3776\n","Iteration 9942: train loss = 0.2539 test loss = 0.3776\n","Iteration 9943: train loss = 0.2539 test loss = 0.3776\n","Iteration 9944: train loss = 0.2539 test loss = 0.3776\n","Iteration 9945: train loss = 0.2538 test loss = 0.3776\n","Iteration 9946: train loss = 0.2538 test loss = 0.3776\n","Iteration 9947: train loss = 0.2538 test loss = 0.3776\n","Iteration 9948: train loss = 0.2538 test loss = 0.3775\n","Iteration 9949: train loss = 0.2538 test loss = 0.3775\n","Iteration 9950: train loss = 0.2537 test loss = 0.3775\n","Iteration 9951: train loss = 0.2537 test loss = 0.3775\n","Iteration 9952: train loss = 0.2537 test loss = 0.3775\n","Iteration 9953: train loss = 0.2537 test loss = 0.3775\n","Iteration 9954: train loss = 0.2537 test loss = 0.3775\n","Iteration 9955: train loss = 0.2536 test loss = 0.3775\n","Iteration 9956: train loss = 0.2536 test loss = 0.3774\n","Iteration 9957: train loss = 0.2536 test loss = 0.3774\n","Iteration 9958: train loss = 0.2536 test loss = 0.3774\n","Iteration 9959: train loss = 0.2535 test loss = 0.3774\n","Iteration 9960: train loss = 0.2535 test loss = 0.3774\n","Iteration 9961: train loss = 0.2535 test loss = 0.3774\n","Iteration 9962: train loss = 0.2535 test loss = 0.3774\n","Iteration 9963: train loss = 0.2535 test loss = 0.3774\n","Iteration 9964: train loss = 0.2534 test loss = 0.3773\n","Iteration 9965: train loss = 0.2534 test loss = 0.3773\n","Iteration 9966: train loss = 0.2534 test loss = 0.3773\n","Iteration 9967: train loss = 0.2534 test loss = 0.3773\n","Iteration 9968: train loss = 0.2534 test loss = 0.3773\n","Iteration 9969: train loss = 0.2533 test loss = 0.3773\n","Iteration 9970: train loss = 0.2533 test loss = 0.3773\n","Iteration 9971: train loss = 0.2533 test loss = 0.3773\n","Iteration 9972: train loss = 0.2533 test loss = 0.3772\n","Iteration 9973: train loss = 0.2533 test loss = 0.3772\n","Iteration 9974: train loss = 0.2532 test loss = 0.3772\n","Iteration 9975: train loss = 0.2532 test loss = 0.3772\n","Iteration 9976: train loss = 0.2532 test loss = 0.3772\n","Iteration 9977: train loss = 0.2532 test loss = 0.3772\n","Iteration 9978: train loss = 0.2532 test loss = 0.3772\n","Iteration 9979: train loss = 0.2531 test loss = 0.3772\n","Iteration 9980: train loss = 0.2531 test loss = 0.3772\n","Iteration 9981: train loss = 0.2531 test loss = 0.3771\n","Iteration 9982: train loss = 0.2531 test loss = 0.3771\n","Iteration 9983: train loss = 0.2531 test loss = 0.3771\n","Iteration 9984: train loss = 0.2530 test loss = 0.3771\n","Iteration 9985: train loss = 0.2530 test loss = 0.3771\n","Iteration 9986: train loss = 0.2530 test loss = 0.3771\n","Iteration 9987: train loss = 0.2530 test loss = 0.3771\n","Iteration 9988: train loss = 0.2529 test loss = 0.3771\n","Iteration 9989: train loss = 0.2529 test loss = 0.3770\n","Iteration 9990: train loss = 0.2529 test loss = 0.3770\n","Iteration 9991: train loss = 0.2529 test loss = 0.3770\n","Iteration 9992: train loss = 0.2529 test loss = 0.3770\n","Iteration 9993: train loss = 0.2528 test loss = 0.3770\n","Iteration 9994: train loss = 0.2528 test loss = 0.3770\n","Iteration 9995: train loss = 0.2528 test loss = 0.3770\n","Iteration 9996: train loss = 0.2528 test loss = 0.3770\n","Iteration 9997: train loss = 0.2528 test loss = 0.3769\n","Iteration 9998: train loss = 0.2527 test loss = 0.3769\n","Iteration 9999: train loss = 0.2527 test loss = 0.3769\n"]}]},{"cell_type":"code","source":["p_test = model(X_test)"],"metadata":{"id":"g-Eol8IVDWz0","executionInfo":{"status":"ok","timestamp":1684220724391,"user_tz":420,"elapsed":348,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}}},"id":"g-Eol8IVDWz0","execution_count":18,"outputs":[]},{"cell_type":"code","source":["p = []\n","for i in p_test:\n","    if i < .5:\n","        p.append(0)\n","    else:\n","        p.append(1)\n","        \n","p = np.array(p)\n","p"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lAmlwvfiDXYW","executionInfo":{"status":"ok","timestamp":1684220726829,"user_tz":420,"elapsed":368,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}},"outputId":"05343341-6025-4a31-b632-5171793be4dc"},"id":"lAmlwvfiDXYW","execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 1, 0, ..., 1, 0, 1])"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["classification_report(y_test, p, output_dict=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iHCvN6NTDbbY","executionInfo":{"status":"ok","timestamp":1684220729797,"user_tz":420,"elapsed":620,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}},"outputId":"f9d846cd-3aaf-4eb7-de6d-ebed9241489d"},"id":"iHCvN6NTDbbY","execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'0.0': {'precision': 0.8616125150421179,\n","  'recall': 0.8592,\n","  'f1-score': 0.8604045663929502,\n","  'support': 5000},\n"," '1.0': {'precision': 0.8595931392102114,\n","  'recall': 0.862,\n","  'f1-score': 0.8607948871579788,\n","  'support': 5000},\n"," 'accuracy': 0.8606,\n"," 'macro avg': {'precision': 0.8606028271261646,\n","  'recall': 0.8606,\n","  'f1-score': 0.8605997267754645,\n","  'support': 10000},\n"," 'weighted avg': {'precision': 0.8606028271261646,\n","  'recall': 0.8606,\n","  'f1-score': 0.8605997267754645,\n","  'support': 10000}}"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","id":"1a68f614","metadata":{"id":"1a68f614"},"source":["# 7.\tUsing the same data from HW-4, exercise 4, create a DL network using Conv1D’s to perform document classification.  Do not use Embeddings yet. Try at least two network architectures."]},{"cell_type":"code","source":["import numpy as np\n","from tensorflow import keras\n","from tensorflow.keras.datasets import reuters\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, Dense, Dropout\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical\n","\n","# Load the Reuters dataset\n","num_words = 10000  # number of most frequent words to consider\n","max_sequence_length = 500  # maximum length of sequences\n","(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=num_words, maxlen=max_sequence_length)\n","\n","# Preprocess the data\n","num_classes = np.max(y_train) + 1\n","x_train = pad_sequences(x_train, maxlen=max_sequence_length)\n","x_test = pad_sequences(x_test, maxlen=max_sequence_length)\n","y_train = to_categorical(y_train, num_classes)\n","y_test = to_categorical(y_test, num_classes)\n","\n","# Define the first network architecture\n","model1 = Sequential()\n","model1.add(Conv1D(128, 5, activation='relu', input_shape=(max_sequence_length, 1)))\n","model1.add(GlobalMaxPooling1D())\n","model1.add(Dense(128, activation='relu'))\n","model1.add(Dropout(0.5))\n","model1.add(Dense(num_classes, activation='softmax'))\n","\n","# Compile and train the first model\n","model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","model1.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_test, y_test))\n","\n","# Define the second network architecture\n","model2 = Sequential()\n","model2.add(Conv1D(64, 3, activation='relu', input_shape=(max_sequence_length, 1)))\n","model2.add(Conv1D(64, 3, activation='relu'))\n","model2.add(GlobalMaxPooling1D())\n","model2.add(Dense(64, activation='relu'))\n","model2.add(Dropout(0.5))\n","model2.add(Dense(num_classes, activation='softmax'))\n","\n","# Compile and train the second model\n","model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","model2.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_test, y_test))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p5kPWbYgdGDj","executionInfo":{"status":"ok","timestamp":1684222040274,"user_tz":420,"elapsed":26875,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}},"outputId":"99bc20f6-e403-4f12-ee72-5e85151c62b4"},"id":"p5kPWbYgdGDj","execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","270/270 [==============================] - 3s 5ms/step - loss: 48.0500 - accuracy: 0.3055 - val_loss: 3.5666 - val_accuracy: 0.3697\n","Epoch 2/10\n","270/270 [==============================] - 1s 4ms/step - loss: 3.4521 - accuracy: 0.3597 - val_loss: 3.3155 - val_accuracy: 0.3743\n","Epoch 3/10\n","270/270 [==============================] - 1s 4ms/step - loss: 3.2001 - accuracy: 0.3613 - val_loss: 3.1008 - val_accuracy: 0.3743\n","Epoch 4/10\n","270/270 [==============================] - 1s 4ms/step - loss: 3.0022 - accuracy: 0.3618 - val_loss: 2.9203 - val_accuracy: 0.3748\n","Epoch 5/10\n","270/270 [==============================] - 1s 4ms/step - loss: 2.8390 - accuracy: 0.3618 - val_loss: 2.7742 - val_accuracy: 0.3748\n","Epoch 6/10\n","270/270 [==============================] - 1s 4ms/step - loss: 2.7096 - accuracy: 0.3617 - val_loss: 2.6599 - val_accuracy: 0.3752\n","Epoch 7/10\n","270/270 [==============================] - 1s 4ms/step - loss: 2.6102 - accuracy: 0.3618 - val_loss: 2.5734 - val_accuracy: 0.3752\n","Epoch 8/10\n","270/270 [==============================] - 1s 4ms/step - loss: 2.5369 - accuracy: 0.3621 - val_loss: 2.5106 - val_accuracy: 0.3752\n","Epoch 9/10\n","270/270 [==============================] - 1s 4ms/step - loss: 2.4844 - accuracy: 0.3623 - val_loss: 2.4663 - val_accuracy: 0.3752\n","Epoch 10/10\n","270/270 [==============================] - 1s 4ms/step - loss: 2.4482 - accuracy: 0.3620 - val_loss: 2.4361 - val_accuracy: 0.3752\n","Epoch 1/10\n","270/270 [==============================] - 3s 5ms/step - loss: 34.2956 - accuracy: 0.3225 - val_loss: 3.5751 - val_accuracy: 0.3706\n","Epoch 2/10\n","270/270 [==============================] - 1s 4ms/step - loss: 3.4468 - accuracy: 0.3612 - val_loss: 3.3561 - val_accuracy: 0.3664\n","Epoch 3/10\n","270/270 [==============================] - 1s 4ms/step - loss: 3.2109 - accuracy: 0.3609 - val_loss: 3.1048 - val_accuracy: 0.3757\n","Epoch 4/10\n","270/270 [==============================] - 1s 4ms/step - loss: 3.0100 - accuracy: 0.3619 - val_loss: 2.9255 - val_accuracy: 0.3757\n","Epoch 5/10\n","270/270 [==============================] - 1s 4ms/step - loss: 2.8471 - accuracy: 0.3621 - val_loss: 2.7786 - val_accuracy: 0.3757\n","Epoch 6/10\n","270/270 [==============================] - 1s 4ms/step - loss: 2.7168 - accuracy: 0.3623 - val_loss: 2.6633 - val_accuracy: 0.3757\n","Epoch 7/10\n","270/270 [==============================] - 1s 4ms/step - loss: 2.6558 - accuracy: 0.3606 - val_loss: 2.5755 - val_accuracy: 0.3762\n","Epoch 8/10\n","270/270 [==============================] - 1s 5ms/step - loss: 2.5477 - accuracy: 0.3614 - val_loss: 2.5196 - val_accuracy: 0.3752\n","Epoch 9/10\n","270/270 [==============================] - 1s 5ms/step - loss: 2.4917 - accuracy: 0.3616 - val_loss: 2.4662 - val_accuracy: 0.3762\n","Epoch 10/10\n","270/270 [==============================] - 1s 4ms/step - loss: 2.4514 - accuracy: 0.3621 - val_loss: 2.4349 - val_accuracy: 0.3762\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fdbebd5d5a0>"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["# Get predictions for the test data\n","y_pred1 = model1.predict(x_test)\n","y_pred2 = model2.predict(x_test)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1_LSom-BdMQH","executionInfo":{"status":"ok","timestamp":1684222043144,"user_tz":420,"elapsed":736,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}},"outputId":"ce520950-c152-4c74-c0a6-84a58a19b800"},"id":"1_LSom-BdMQH","execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["68/68 [==============================] - 0s 1ms/step\n","68/68 [==============================] - 0s 2ms/step\n"]}]},{"cell_type":"code","source":["# Convert probabilities to class labels\n","y_pred_labels1 = np.argmax(y_pred1, axis=1)\n","y_pred_labels2 = np.argmax(y_pred2, axis=1)\n"],"metadata":{"id":"_GtcZajXdO9S","executionInfo":{"status":"ok","timestamp":1684222053112,"user_tz":420,"elapsed":347,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}}},"id":"_GtcZajXdO9S","execution_count":29,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import classification_report, accuracy_score\n","\n","# Evaluate model1\n","print(\"Model 1:\")\n","print(classification_report(np.argmax(y_test, axis=1), y_pred_labels1))\n","print(\"Accuracy:\", accuracy_score(np.argmax(y_test, axis=1), y_pred_labels1))\n","\n","# Evaluate model2\n","print(\"Model 2:\")\n","print(classification_report(np.argmax(y_test, axis=1), y_pred_labels2))\n","print(\"Accuracy:\", accuracy_score(np.argmax(y_test, axis=1), y_pred_labels2))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Y1wNzX6dRPJ","executionInfo":{"status":"ok","timestamp":1684222065297,"user_tz":420,"elapsed":340,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}},"outputId":"502ea645-7d1a-4024-cd8a-baec1e9c7504"},"id":"7Y1wNzX6dRPJ","execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Model 1:\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00         9\n","           1       0.00      0.00      0.00       101\n","           2       0.00      0.00      0.00        20\n","           3       0.38      1.00      0.55       811\n","           4       0.00      0.00      0.00       461\n","           5       0.00      0.00      0.00         5\n","           6       0.00      0.00      0.00        14\n","           7       0.00      0.00      0.00         3\n","           8       0.00      0.00      0.00        34\n","           9       0.00      0.00      0.00        25\n","          10       0.00      0.00      0.00        28\n","          11       0.00      0.00      0.00        74\n","          12       0.00      0.00      0.00        12\n","          13       0.00      0.00      0.00        36\n","          14       0.00      0.00      0.00         2\n","          15       0.00      0.00      0.00         9\n","          16       0.00      0.00      0.00        90\n","          17       0.00      0.00      0.00        11\n","          18       0.00      0.00      0.00        17\n","          19       0.00      0.00      0.00       117\n","          20       0.00      0.00      0.00        61\n","          21       0.00      0.00      0.00        24\n","          22       0.00      0.00      0.00         7\n","          23       0.00      0.00      0.00        12\n","          24       0.00      0.00      0.00        19\n","          25       0.00      0.00      0.00        30\n","          26       0.00      0.00      0.00         6\n","          27       0.00      0.00      0.00         4\n","          28       0.00      0.00      0.00        10\n","          29       0.00      0.00      0.00         4\n","          30       0.00      0.00      0.00        12\n","          31       0.00      0.00      0.00        13\n","          32       0.00      0.00      0.00         8\n","          33       0.00      0.00      0.00         5\n","          34       0.00      0.00      0.00         6\n","          35       0.00      0.00      0.00         6\n","          36       0.00      0.00      0.00        10\n","          37       0.00      0.00      0.00         2\n","          38       0.00      0.00      0.00         3\n","          39       0.00      0.00      0.00         5\n","          40       0.00      0.00      0.00         8\n","          41       0.00      0.00      0.00         8\n","          42       0.00      0.00      0.00         3\n","          43       0.00      0.00      0.00         6\n","          44       0.00      0.00      0.00         4\n","          45       0.00      0.00      0.00         1\n","\n","    accuracy                           0.38      2156\n","   macro avg       0.01      0.02      0.01      2156\n","weighted avg       0.14      0.38      0.21      2156\n","\n","Accuracy: 0.3752319109461967\n","Model 2:\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00         9\n","           1       0.00      0.00      0.00       101\n","           2       0.00      0.00      0.00        20\n","           3       0.38      1.00      0.55       811\n","           4       0.00      0.00      0.00       461\n","           5       0.00      0.00      0.00         5\n","           6       0.00      0.00      0.00        14\n","           7       0.00      0.00      0.00         3\n","           8       0.00      0.00      0.00        34\n","           9       0.00      0.00      0.00        25\n","          10       0.00      0.00      0.00        28\n","          11       0.00      0.00      0.00        74\n","          12       0.00      0.00      0.00        12\n","          13       0.00      0.00      0.00        36\n","          14       0.00      0.00      0.00         2\n","          15       0.00      0.00      0.00         9\n","          16       0.00      0.00      0.00        90\n","          17       0.00      0.00      0.00        11\n","          18       0.00      0.00      0.00        17\n","          19       0.00      0.00      0.00       117\n","          20       0.00      0.00      0.00        61\n","          21       0.00      0.00      0.00        24\n","          22       0.00      0.00      0.00         7\n","          23       0.00      0.00      0.00        12\n","          24       0.00      0.00      0.00        19\n","          25       0.00      0.00      0.00        30\n","          26       0.00      0.00      0.00         6\n","          27       0.00      0.00      0.00         4\n","          28       0.00      0.00      0.00        10\n","          29       0.00      0.00      0.00         4\n","          30       0.00      0.00      0.00        12\n","          31       0.00      0.00      0.00        13\n","          32       0.00      0.00      0.00         8\n","          33       0.00      0.00      0.00         5\n","          34       0.00      0.00      0.00         6\n","          35       0.00      0.00      0.00         6\n","          36       0.00      0.00      0.00        10\n","          37       0.00      0.00      0.00         2\n","          38       0.00      0.00      0.00         3\n","          39       0.00      0.00      0.00         5\n","          40       0.00      0.00      0.00         8\n","          41       0.00      0.00      0.00         8\n","          42       0.00      0.00      0.00         3\n","          43       0.00      0.00      0.00         6\n","          44       0.00      0.00      0.00         4\n","          45       0.00      0.00      0.00         1\n","\n","    accuracy                           0.38      2156\n","   macro avg       0.01      0.02      0.01      2156\n","weighted avg       0.14      0.38      0.21      2156\n","\n","Accuracy: 0.3761595547309833\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":5}