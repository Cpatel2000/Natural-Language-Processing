{"cells":[{"cell_type":"markdown","source":["### imports"],"metadata":{"id":"L263t8-GBEXc"},"id":"L263t8-GBEXc"},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import gensim\n","import gensim.downloader as api\n","import tensorflow as tf\n","import os\n","\n","from tensorflow import keras\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import *\n","from tensorflow.keras.datasets import imdb\n","from keras import preprocessing\n","from keras.datasets import imdb\n","from keras.layers import Bidirectional\n","from keras.models import Model\n","from keras.layers import Input, LSTM, Dense\n","\n","from random import shuffle\n","from sklearn.manifold import TSNE\n","from gensim.models import Word2Vec\n","\n","!pip install nltk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w3xoy4dTBHj0","executionInfo":{"status":"ok","timestamp":1653616042039,"user_tz":420,"elapsed":6046,"user":{"displayName":"Justin Goh","userId":"02749663324647441700"}},"outputId":"69d4eab5-a3a1-4a93-8be4-7641134872c9"},"id":"w3xoy4dTBHj0","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"]}]},{"cell_type":"code","source":["!pip install gensim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xfrAGh39A9YM","executionInfo":{"status":"ok","timestamp":1653616044699,"user_tz":420,"elapsed":2669,"user":{"displayName":"Justin Goh","userId":"02749663324647441700"}},"outputId":"1ca5dcd3-dcab-449e-e6ca-232a0a135fb9"},"id":"xfrAGh39A9YM","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (6.0.0)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n","Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n"]}]},{"cell_type":"markdown","id":"93eddf41","metadata":{"id":"93eddf41"},"source":["# 1. Sentiment Analysis\n","\n","Implement the sentiment analysis of the previous homeworks using a bidirectional LSTM."]},{"cell_type":"markdown","source":["### Embedding 50"],"metadata":{"id":"vOCiL7w5Xdlv"},"id":"vOCiL7w5Xdlv"},{"cell_type":"code","source":["def CreateModel():\n","    #embedding_matrix = get_weights()\n","\n","    x_i = Input(200) \n","    x   = Embedding(1000, 50, \n","                    input_length=maxlen,\n","                    trainable=False)(x_i)\n","                              \n","\n","    x = Bidirectional(LSTM(64, return_sequences=True, input_shape=(None,1)))(x)\n","    x = Dropout(0.2)(x)\n","\n","    x = Bidirectional(LSTM(32))(x)\n","    x = Dropout(0.2)(x)\n","    \n","    x = Dense(64, activation=\"relu\")(x)\n","    x = Dropout(0.1)(x)\n","\n","  \n","    x = Dense(1, activation=\"sigmoid\")(x)\n","\n","    return keras.models.Model(x_i, x)"],"metadata":{"id":"4XZU1vQT_92P"},"id":"4XZU1vQT_92P","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Loading the data\n","num_words = 10000\n","maxlen = 200\n","(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=num_words)\n","\n","# Creating the model and preprocessing the data\n","# We pad the sentences here with zeros so it becomes a matrix. \n","x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n","x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)    \n","\n","model = CreateModel()\n","model.summary()\n","model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"acc\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EPzl77rH_94u","executionInfo":{"status":"ok","timestamp":1653333311815,"user_tz":420,"elapsed":6542,"user":{"displayName":"Justin Goh","userId":"02749663324647441700"}},"outputId":"e025029c-6220-4ec4-b0c6-96c6bb031929"},"id":"EPzl77rH_94u","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_5\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_6 (InputLayer)        [(None, 200)]             0         \n","                                                                 \n"," embedding_5 (Embedding)     (None, 200, 50)           50000     \n","                                                                 \n"," bidirectional_8 (Bidirectio  (None, 200, 128)         58880     \n"," nal)                                                            \n","                                                                 \n"," dropout_12 (Dropout)        (None, 200, 128)          0         \n","                                                                 \n"," bidirectional_9 (Bidirectio  (None, 64)               41216     \n"," nal)                                                            \n","                                                                 \n"," dropout_13 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_9 (Dense)             (None, 64)                4160      \n","                                                                 \n"," dropout_14 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_10 (Dense)            (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 154,321\n","Trainable params: 104,321\n","Non-trainable params: 50,000\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# Fitting the model \n","model.fit(\n","    x_train, y_train, epochs=20, batch_size=64,\n","    validation_split=0.2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zktrEW3wByp-","executionInfo":{"status":"ok","timestamp":1653333581830,"user_tz":420,"elapsed":267695,"user":{"displayName":"Justin Goh","userId":"02749663324647441700"}},"outputId":"f48bd3b7-6d5f-4472-dd2f-1e1dd4a20ae6"},"id":"zktrEW3wByp-","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","313/313 [==============================] - 19s 44ms/step - loss: 0.6900 - acc: 0.5290 - val_loss: 0.6722 - val_acc: 0.5810\n","Epoch 2/20\n","313/313 [==============================] - 12s 40ms/step - loss: 0.6629 - acc: 0.6054 - val_loss: 0.6188 - val_acc: 0.6580\n","Epoch 3/20\n","313/313 [==============================] - 12s 40ms/step - loss: 0.6394 - acc: 0.6364 - val_loss: 0.6455 - val_acc: 0.6284\n","Epoch 4/20\n","313/313 [==============================] - 13s 40ms/step - loss: 0.6283 - acc: 0.6532 - val_loss: 0.6129 - val_acc: 0.6674\n","Epoch 5/20\n","313/313 [==============================] - 12s 40ms/step - loss: 0.6220 - acc: 0.6597 - val_loss: 0.6121 - val_acc: 0.6658\n","Epoch 6/20\n","313/313 [==============================] - 13s 41ms/step - loss: 0.6151 - acc: 0.6647 - val_loss: 0.6274 - val_acc: 0.6508\n","Epoch 7/20\n","313/313 [==============================] - 12s 40ms/step - loss: 0.6088 - acc: 0.6683 - val_loss: 0.6024 - val_acc: 0.6778\n","Epoch 8/20\n","313/313 [==============================] - 14s 43ms/step - loss: 0.5962 - acc: 0.6751 - val_loss: 0.5733 - val_acc: 0.6968\n","Epoch 9/20\n","313/313 [==============================] - 13s 41ms/step - loss: 0.5926 - acc: 0.6785 - val_loss: 0.5754 - val_acc: 0.6954\n","Epoch 10/20\n","313/313 [==============================] - 12s 40ms/step - loss: 0.5833 - acc: 0.6862 - val_loss: 0.5739 - val_acc: 0.6956\n","Epoch 11/20\n","313/313 [==============================] - 12s 40ms/step - loss: 0.5787 - acc: 0.6891 - val_loss: 0.5920 - val_acc: 0.6766\n","Epoch 12/20\n","313/313 [==============================] - 12s 40ms/step - loss: 0.5759 - acc: 0.6915 - val_loss: 0.5684 - val_acc: 0.6928\n","Epoch 13/20\n","313/313 [==============================] - 12s 40ms/step - loss: 0.5690 - acc: 0.6967 - val_loss: 0.5660 - val_acc: 0.7034\n","Epoch 14/20\n","313/313 [==============================] - 12s 40ms/step - loss: 0.5642 - acc: 0.6981 - val_loss: 0.6095 - val_acc: 0.6656\n","Epoch 15/20\n","313/313 [==============================] - 13s 40ms/step - loss: 0.5611 - acc: 0.7014 - val_loss: 0.5684 - val_acc: 0.7004\n","Epoch 16/20\n","313/313 [==============================] - 12s 40ms/step - loss: 0.5577 - acc: 0.7056 - val_loss: 0.5744 - val_acc: 0.6852\n","Epoch 17/20\n","313/313 [==============================] - 12s 40ms/step - loss: 0.5485 - acc: 0.7101 - val_loss: 0.5828 - val_acc: 0.6914\n","Epoch 18/20\n","313/313 [==============================] - 12s 40ms/step - loss: 0.5445 - acc: 0.7143 - val_loss: 0.5499 - val_acc: 0.7108\n","Epoch 19/20\n","313/313 [==============================] - 12s 40ms/step - loss: 0.5412 - acc: 0.7154 - val_loss: 0.5499 - val_acc: 0.7114\n","Epoch 20/20\n","313/313 [==============================] - 12s 40ms/step - loss: 0.5374 - acc: 0.7197 - val_loss: 0.5494 - val_acc: 0.7088\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fedbaa2df90>"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["eval_result = model.evaluate(x_test, y_test)\n","prediction = model.predict(x_test)\n","prediction = prediction[:5] \n","label = y_test[:5] "],"metadata":{"id":"aZBUO-fmSOMn"},"id":"aZBUO-fmSOMn","execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(eval_result[1])\n","print(prediction) \n","print(label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ewYs8hscTLWH","executionInfo":{"status":"ok","timestamp":1653332740996,"user_tz":420,"elapsed":163,"user":{"displayName":"Justin Goh","userId":"02749663324647441700"}},"outputId":"786efee3-30f7-4ce5-f818-8a0f89d71907"},"id":"ewYs8hscTLWH","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.34699515]\n"," [0.67189467]\n"," [0.6448168 ]\n"," [0.7286762 ]\n"," [0.9937203 ]]\n","[0 1 1 0 1]\n"]}]},{"cell_type":"markdown","source":["### W2V Embedding"],"metadata":{"id":"Owbm0S1yXhue"},"id":"Owbm0S1yXhue"},{"cell_type":"code","source":["keyed_vectors = api.load(\"word2vec-google-news-300\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":169},"id":"TH3k1vIxevxj","executionInfo":{"status":"error","timestamp":1685937308963,"user_tz":420,"elapsed":11,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}},"outputId":"6c9a13ca-c8ed-4d85-97e7-d394f903dbb2"},"id":"TH3k1vIxevxj","execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-f40c2ce050b7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkeyed_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word2vec-google-news-300\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'api' is not defined"]}]},{"cell_type":"code","source":["# Function to prepare embedding layer\n","def prepare_embedding():\n","  d = imdb.get_word_index()\n","  word_index = dict((y,x) for x,y in d.items()) \n","  embeddings_index = {}\n","  \n","  # This block reads in the embedding from Glove\n","  f = open(os.path.join('/content/drive/MyDrive/Colab Notebooks/ELEN532_NLP/Lab8', 'glove.6B.50d.txt'))\n","  for line in f:\n","      values = line.split()\n","      word = values[0]\n","      coefs = np.asarray(values[1:], dtype='float32')\n","      embeddings_index[word] = coefs\n","  f.close() \n","\n","  # Computes embedding matrix\n","  embedding_matrix= np.zeros((len(word_index), 50))  \n","  for i, word in word_index.items():\n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None:\n","        # words not found in embedding index will be zeros\n","        embedding_matrix[i] = embedding_vector\n","\n","  \n","  return embedding_matrix "],"metadata":{"id":"-P6nawS205jw","executionInfo":{"status":"aborted","timestamp":1685937308963,"user_tz":420,"elapsed":7,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}}},"id":"-P6nawS205jw","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_weights(key_vec):\n","\n","    \"\"\"Loads in w2v embedding and returns weights in the form of a np.array \"\"\"\n","  \n","    # Loading GoogleNews \n","    # keyed_vectors = api.load(\"word2vec-google-news-300\")\n","\n","\n","    # vectors themselves, a 2D numpy array\n","    weights = key_vec.vectors      \n","\n","    return weights"],"metadata":{"id":"i3HgJlRMXsUI","executionInfo":{"status":"aborted","timestamp":1685937308964,"user_tz":420,"elapsed":8,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}}},"id":"i3HgJlRMXsUI","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def CreateModel():\n","    embedding_matrix = get_weights(keyed_vectors)\n","    # embedding_matrix = prepare_embedding()\n","\n","    x_i = Input(300) \n","    x   = Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], \n","                    weights=[embedding_matrix],\n","                    input_length=maxlen,\n","                    trainable=False)(x_i)\n","                              \n","\n","    x = Bidirectional(LSTM(128, return_sequences=True, input_shape=(None,1)))(x)\n","    x = Dropout(0.2)(x)\n","\n","    x = Bidirectional(LSTM(32))(x)\n","    x = Dropout(0.2)(x)\n","    \n","    x = Dense(64, activation=\"relu\")(x)\n","    x = Dropout(0.1)(x)\n","\n","  \n","    x = Dense(1, activation=\"sigmoid\")(x)\n","\n","    return keras.models.Model(x_i, x)"],"metadata":{"id":"95Lcuq3gXsWm","executionInfo":{"status":"aborted","timestamp":1685937308964,"user_tz":420,"elapsed":7,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}}},"id":"95Lcuq3gXsWm","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Loading the data\n","num_words = 10000\n","maxlen = 300\n","(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=num_words)\n","\n","# Creating the model and preprocessing the data\n","# We pad the sentences here with zeros so it becomes a matrix. \n","x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n","x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)    \n","\n","model = CreateModel()\n","model.summary()\n","model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"acc\"])"],"metadata":{"id":"OVX3NXW5Xlb0","executionInfo":{"status":"aborted","timestamp":1685937308964,"user_tz":420,"elapsed":7,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}}},"id":"OVX3NXW5Xlb0","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Fitting the model \n","model.fit(\n","    x_train, y_train, epochs=10, batch_size=64,\n","    validation_split=0.2)"],"metadata":{"id":"tAsX8s0bXlhd","executionInfo":{"status":"aborted","timestamp":1685937308964,"user_tz":420,"elapsed":7,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}}},"id":"tAsX8s0bXlhd","execution_count":null,"outputs":[]},{"cell_type":"code","source":["eval_result = model.evaluate(x_test, y_test)\n","eval_result[1]"],"metadata":{"id":"we3bw6RnXn6N","executionInfo":{"status":"aborted","timestamp":1685937308965,"user_tz":420,"elapsed":8,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}}},"id":"we3bw6RnXn6N","execution_count":null,"outputs":[]},{"cell_type":"code","source":["prediction = model.predict(x_test)\n","prediction = prediction[:5] \n","label = y_test[:5] \n","print(prediction) \n","print(label)"],"metadata":{"id":"201ZOMz2Xn9d","executionInfo":{"status":"aborted","timestamp":1685937308965,"user_tz":420,"elapsed":8,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}}},"id":"201ZOMz2Xn9d","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"d1329350","metadata":{"id":"d1329350"},"source":["# 2. Seq2Seq\n","\n","In this homework, you will create a seq2seq network that __answers questions similar to the questions trained in the training set.__ This dataset is from https://www.kaggle.com/datasets/rtatman/questionanswer-dataset\n","\n","Your network should use an embedding layer as input."]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VzfeFrY9Hinu","executionInfo":{"status":"ok","timestamp":1653610418868,"user_tz":420,"elapsed":1025,"user":{"displayName":"Justin Goh","userId":"02749663324647441700"}},"outputId":"92a0d0bf-4142-4558-b241-ae9565c3d5f4"},"id":"VzfeFrY9Hinu","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}]},{"cell_type":"code","source":["filenames = ['S08_question_answer_pairs.txt', 'S09_question_answer_pairs.txt', 'S10_question_answer_pairs.txt']\n","\n","df = []\n","for fn in filenames:\n","    dfi = pd.read_csv(fn, sep='\\t',encoding=\"latin1\")\n","    dfi = dfi[['Question', 'Answer']]\n","    df.append(dfi)\n","df = pd.concat(df)\n","# remove all rows having NAN values\n","df = df.dropna()\n","questions = df['Question'].tolist()\n","# select all answers and put them in a list\n","answers = df['Answer'].tolist()"],"metadata":{"id":"vHVswIg_Ij9B"},"id":"vHVswIg_Ij9B","execution_count":null,"outputs":[]},{"cell_type":"code","source":["df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"F6eu-oBlDhOK","executionInfo":{"status":"ok","timestamp":1653621069220,"user_tz":420,"elapsed":155,"user":{"displayName":"Justin Goh","userId":"02749663324647441700"}},"outputId":"bc71bc99-a3c0-46a3-a389-365d544ce268"},"id":"F6eu-oBlDhOK","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                               Question  \\\n","0     Was Abraham Lincoln the sixteenth President of...   \n","1     Was Abraham Lincoln the sixteenth President of...   \n","2     Did Lincoln sign the National Banking Act of 1...   \n","3     Did Lincoln sign the National Banking Act of 1...   \n","4                      Did his mother die of pneumonia?   \n","...                                                 ...   \n","1452          What areas do the Grevy's Zebras inhabit?   \n","1454  Which species of zebra is known as the common ...   \n","1455  Which species of zebra is known as the common ...   \n","1456                     At what age can a zebra breed?   \n","1457                     At what age can a zebra breed?   \n","\n","                                                 Answer  \n","0                                                   yes  \n","1                                                  Yes.  \n","2                                                   yes  \n","3                                                  Yes.  \n","4                                                    no  \n","...                                                 ...  \n","1452  semi-arid grasslands of Ethiopia and northern ...  \n","1454  Plains Zebra (Equus quagga, formerly Equus bur...  \n","1455                                       Plains Zebra  \n","1456                                        five or six  \n","1457                                             5 or 6  \n","\n","[3422 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-2473b76e-f056-4eef-aee7-651b7f332414\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Question</th>\n","      <th>Answer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Was Abraham Lincoln the sixteenth President of...</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Was Abraham Lincoln the sixteenth President of...</td>\n","      <td>Yes.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Did Lincoln sign the National Banking Act of 1...</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Did Lincoln sign the National Banking Act of 1...</td>\n","      <td>Yes.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Did his mother die of pneumonia?</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1452</th>\n","      <td>What areas do the Grevy's Zebras inhabit?</td>\n","      <td>semi-arid grasslands of Ethiopia and northern ...</td>\n","    </tr>\n","    <tr>\n","      <th>1454</th>\n","      <td>Which species of zebra is known as the common ...</td>\n","      <td>Plains Zebra (Equus quagga, formerly Equus bur...</td>\n","    </tr>\n","    <tr>\n","      <th>1455</th>\n","      <td>Which species of zebra is known as the common ...</td>\n","      <td>Plains Zebra</td>\n","    </tr>\n","    <tr>\n","      <th>1456</th>\n","      <td>At what age can a zebra breed?</td>\n","      <td>five or six</td>\n","    </tr>\n","    <tr>\n","      <th>1457</th>\n","      <td>At what age can a zebra breed?</td>\n","      <td>5 or 6</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3422 rows Ã— 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2473b76e-f056-4eef-aee7-651b7f332414')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2473b76e-f056-4eef-aee7-651b7f332414 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2473b76e-f056-4eef-aee7-651b7f332414');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":81}]},{"cell_type":"code","source":["df.iloc[2074]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2N7Fw_B_RU02","executionInfo":{"status":"ok","timestamp":1653620082672,"user_tz":420,"elapsed":141,"user":{"displayName":"Justin Goh","userId":"02749663324647441700"}},"outputId":"edf0804a-cfbb-4d45-aecb-1063c0d75e7b"},"id":"2N7Fw_B_RU02","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Question                                    What is Santiago?\n","Answer      Santiago is Spanish for St. James. It is also ...\n","Name: 665, dtype: object"]},"metadata":{},"execution_count":69}]},{"cell_type":"code","source":["df = df.drop(df.index[2074])\n","df = df[df.Answer != \"no\"]\n","df = df[df.Answer != \"Yes.\"]"],"metadata":{"id":"y-PJqvZIBn2V"},"id":"y-PJqvZIBn2V","execution_count":null,"outputs":[]},{"cell_type":"code","source":["for txt in target_texts:\n","  if len(txt) ==  max([len(txt) for txt in target_texts]):\n","    print(target_texts.index(txt))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qz_EEJEeP8mp","executionInfo":{"status":"ok","timestamp":1653620103301,"user_tz":420,"elapsed":538,"user":{"displayName":"Justin Goh","userId":"02749663324647441700"}},"outputId":"4d9c9026-636d-4cdf-8420-678ead9968b1"},"id":"qz_EEJEeP8mp","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["140\n","425\n"]}]},{"cell_type":"code","execution_count":null,"id":"c67147b8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c67147b8","executionInfo":{"status":"ok","timestamp":1653613686981,"user_tz":420,"elapsed":150,"user":{"displayName":"Justin Goh","userId":"02749663324647441700"}},"outputId":"c47300b4-803a-4c33-fb01-b99383d22e0a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["1                                                   Yes.\n","3                                                   Yes.\n","5                                                    No.\n","6                                              18 months\n","7                                             18 months.\n","                             ...                        \n","814                                        from G3 to C8\n","815                                        from G3 to C8\n","819                                            Indonesia\n","820    Arnold Schlick's Spiegel der Orgelmacher und O...\n","821            by a bright, sharp tone and high register\n","Name: Answer, Length: 1432, dtype: object"]},"metadata":{},"execution_count":43}],"source":["df[\"Answer\"] "]},{"cell_type":"code","source":["batch_size = 64 \n","epochs = 100\n","latent_dim = 256"],"metadata":{"id":"iwzMg16hIzY4"},"id":"iwzMg16hIzY4","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Vectorize data \n","\n","input_texts = [] # list of all \"Questions\"\n","target_texts = [] # list of all corresponding \"Answers\"\n","input_char = set() # list of unique letters, tokenized letters (includes numbers, punctuations)\n","target_char = set() # list of unique letters \n","\n","\n","for line in range(len(df[\"Question\"])):\n","  input_text = df[\"Question\"].iloc[line]\n","  #if type(input_text) != str: # Converting all texts in questions column to str type\n","    #input_text = str(input_text)\n","  input_texts.append(input_text)\n","\n","  target_text = df[\"Answer\"].iloc[line]\n","  #if type(target_text) != str: # Converting all texts in answer column to str type\n","    #target_text = str(target_text)\n","  target_text = '\\t' + target_text + '\\n'\n","  target_texts.append(target_text)\n","\n","\n","  for char in input_text:\n","      if char not in input_char:\n","          input_char.add(char)\n","  for char in target_text:\n","      if char not in target_char:\n","          target_char.add(char)\n","\n","input_char = sorted(list(input_char))\n","target_char = sorted(list(target_char))\n","  \n","# Counting the number of tokens after sorting \n","num_encoder_tokens = len(input_char)\n","num_decoder_tokens = len(target_char)\n","\n","# Finds the longest sentence in input and target texts list \n","max_encoder_seq_length = max([len(txt) for txt in input_texts])\n","max_decoder_seq_length = max([len(txt) for txt in target_texts])\n","\n","\n","# Create a dictionary for input & target chracter tokens \n","input_token_index = dict(\n","    [(char, i) for i, char in enumerate(input_char)])\n","target_token_index = dict(\n","    [(char, i) for i, char in enumerate(target_char)])\n","\n","\n","# Create numpy array of for encoder, decoder input data & decoder target data\n","encoder_input_data = np.zeros(\n","    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n","    dtype='float32')\n","decoder_input_data = np.zeros(\n","    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n","    dtype='float32')\n","decoder_target_data = np.zeros(\n","    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n","    dtype='float32')\n","\n","# \"input_text\" refers to a single element in list \"input_texts\". Same for target text\n","for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n","    for t, char in enumerate(input_text):\n","        encoder_input_data[i, t, input_token_index[char]] = 1.\n","    for t, char in enumerate(target_text):\n","        decoder_input_data[i, t, target_token_index[char]] = 1.\n","        if t > 0:\n","            decoder_target_data[i, t - 1, target_token_index[char]] = 1."],"metadata":{"id":"5j87TZJVkmmL"},"id":"5j87TZJVkmmL","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define an input sequence and process it.\n","encoder_inputs = Input(shape=(None, num_encoder_tokens)) # input is the number of encoder tokens \n","encoder = LSTM(latent_dim, return_state=True)\n","encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n","\n","# We discard `encoder_outputs` and only keep the states.\n","encoder_states = [state_h, state_c]\n","\n","# Set up the decoder, using `encoder_states` as initial state.\n","decoder_inputs = Input(shape=(None, num_decoder_tokens))\n","\n","# We set up our decoder to return full output sequences, and to return internal states as well. \n","# We don't use the return states in the training model, but we will use them in inference.\n","decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n","decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n","                                     initial_state=encoder_states)\n","\n","decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","# Define the model that will turn\n","# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"],"metadata":{"id":"Jr9zwC9grMAB"},"id":"Jr9zwC9grMAB","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training the model\n","model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n","model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          validation_split=0.2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-qlfjBlHvCIJ","executionInfo":{"status":"ok","timestamp":1653621471515,"user_tz":420,"elapsed":386037,"user":{"displayName":"Justin Goh","userId":"02749663324647441700"}},"outputId":"f5fb4afc-379f-4e5f-ee31-37ac6832c7ef"},"id":"-qlfjBlHvCIJ","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","40/40 [==============================] - 8s 119ms/step - loss: 0.2390 - val_loss: 0.3423\n","Epoch 2/100\n","40/40 [==============================] - 4s 92ms/step - loss: 0.2341 - val_loss: 0.3427\n","Epoch 3/100\n","40/40 [==============================] - 4s 92ms/step - loss: 0.2327 - val_loss: 0.3362\n","Epoch 4/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2311 - val_loss: 0.3341\n","Epoch 5/100\n","40/40 [==============================] - 4s 92ms/step - loss: 0.2296 - val_loss: 0.3322\n","Epoch 6/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2284 - val_loss: 0.3304\n","Epoch 7/100\n","40/40 [==============================] - 4s 92ms/step - loss: 0.2273 - val_loss: 0.3255\n","Epoch 8/100\n","40/40 [==============================] - 4s 92ms/step - loss: 0.2256 - val_loss: 0.3264\n","Epoch 9/100\n","40/40 [==============================] - 4s 92ms/step - loss: 0.2251 - val_loss: 0.3237\n","Epoch 10/100\n","40/40 [==============================] - 4s 92ms/step - loss: 0.2241 - val_loss: 0.3245\n","Epoch 11/100\n","40/40 [==============================] - 4s 92ms/step - loss: 0.2229 - val_loss: 0.3242\n","Epoch 12/100\n","40/40 [==============================] - 4s 92ms/step - loss: 0.2227 - val_loss: 0.3211\n","Epoch 13/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2223 - val_loss: 0.3212\n","Epoch 14/100\n","40/40 [==============================] - 4s 95ms/step - loss: 0.2221 - val_loss: 0.3199\n","Epoch 15/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2212 - val_loss: 0.3203\n","Epoch 16/100\n","40/40 [==============================] - 4s 92ms/step - loss: 0.2207 - val_loss: 0.3216\n","Epoch 17/100\n","40/40 [==============================] - 4s 92ms/step - loss: 0.2203 - val_loss: 0.3227\n","Epoch 18/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2199 - val_loss: 0.3194\n","Epoch 19/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2194 - val_loss: 0.3210\n","Epoch 20/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2191 - val_loss: 0.3190\n","Epoch 21/100\n","40/40 [==============================] - 4s 92ms/step - loss: 0.2190 - val_loss: 0.3156\n","Epoch 22/100\n","40/40 [==============================] - 4s 92ms/step - loss: 0.2181 - val_loss: 0.3178\n","Epoch 23/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2180 - val_loss: 0.3158\n","Epoch 24/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2173 - val_loss: 0.3049\n","Epoch 25/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2175 - val_loss: 0.3145\n","Epoch 26/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2167 - val_loss: 0.3136\n","Epoch 27/100\n","40/40 [==============================] - 4s 92ms/step - loss: 0.2165 - val_loss: 0.3138\n","Epoch 28/100\n","40/40 [==============================] - 4s 92ms/step - loss: 0.2161 - val_loss: 0.3135\n","Epoch 29/100\n","40/40 [==============================] - 4s 92ms/step - loss: 0.2155 - val_loss: 0.3175\n","Epoch 30/100\n","40/40 [==============================] - 4s 92ms/step - loss: 0.2161 - val_loss: 0.3137\n","Epoch 31/100\n","40/40 [==============================] - 4s 92ms/step - loss: 0.2150 - val_loss: 0.3167\n","Epoch 32/100\n","40/40 [==============================] - 4s 92ms/step - loss: 0.2150 - val_loss: 0.3097\n","Epoch 33/100\n","40/40 [==============================] - 4s 92ms/step - loss: 0.2143 - val_loss: 0.3164\n","Epoch 34/100\n","40/40 [==============================] - 4s 92ms/step - loss: 0.2144 - val_loss: 0.3111\n","Epoch 35/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2138 - val_loss: 0.3126\n","Epoch 36/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2135 - val_loss: 0.3117\n","Epoch 37/100\n","40/40 [==============================] - 4s 92ms/step - loss: 0.2130 - val_loss: 0.3108\n","Epoch 38/100\n","40/40 [==============================] - 4s 92ms/step - loss: 0.2127 - val_loss: 0.3096\n","Epoch 39/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2122 - val_loss: 0.3103\n","Epoch 40/100\n","40/40 [==============================] - 4s 92ms/step - loss: 0.2132 - val_loss: 0.3095\n","Epoch 41/100\n","40/40 [==============================] - 4s 92ms/step - loss: 0.2111 - val_loss: 0.3075\n","Epoch 42/100\n","40/40 [==============================] - 4s 92ms/step - loss: 0.2117 - val_loss: 0.3087\n","Epoch 43/100\n","40/40 [==============================] - 4s 92ms/step - loss: 0.2111 - val_loss: 0.3078\n","Epoch 44/100\n","40/40 [==============================] - 4s 92ms/step - loss: 0.2109 - val_loss: 0.3071\n","Epoch 45/100\n","40/40 [==============================] - 4s 92ms/step - loss: 0.2102 - val_loss: 0.3076\n","Epoch 46/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2106 - val_loss: 0.3064\n","Epoch 47/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2095 - val_loss: 0.2840\n","Epoch 48/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2084 - val_loss: 0.3048\n","Epoch 49/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2090 - val_loss: 0.3076\n","Epoch 50/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2093 - val_loss: 0.3067\n","Epoch 51/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2095 - val_loss: 0.3038\n","Epoch 52/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2087 - val_loss: 0.3071\n","Epoch 53/100\n","40/40 [==============================] - 4s 92ms/step - loss: 0.2085 - val_loss: 0.3056\n","Epoch 54/100\n","40/40 [==============================] - 4s 92ms/step - loss: 0.2084 - val_loss: 0.3060\n","Epoch 55/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2084 - val_loss: 0.3061\n","Epoch 56/100\n","40/40 [==============================] - 4s 92ms/step - loss: 0.2081 - val_loss: 0.3042\n","Epoch 57/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2080 - val_loss: 0.3034\n","Epoch 58/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2068 - val_loss: 0.3009\n","Epoch 59/100\n","40/40 [==============================] - 4s 92ms/step - loss: 0.2074 - val_loss: 0.3031\n","Epoch 60/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2069 - val_loss: 0.3018\n","Epoch 61/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2073 - val_loss: 0.3002\n","Epoch 62/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2059 - val_loss: 0.2954\n","Epoch 63/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2057 - val_loss: 0.3038\n","Epoch 64/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2063 - val_loss: 0.3056\n","Epoch 65/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2066 - val_loss: 0.3037\n","Epoch 66/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2058 - val_loss: 0.3031\n","Epoch 67/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2054 - val_loss: 0.3019\n","Epoch 68/100\n","40/40 [==============================] - 4s 92ms/step - loss: 0.2059 - val_loss: 0.3014\n","Epoch 69/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2052 - val_loss: 0.3014\n","Epoch 70/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2050 - val_loss: 0.2955\n","Epoch 71/100\n","40/40 [==============================] - 4s 92ms/step - loss: 0.2057 - val_loss: 0.3000\n","Epoch 72/100\n","40/40 [==============================] - 4s 92ms/step - loss: 0.2043 - val_loss: 0.3040\n","Epoch 73/100\n","40/40 [==============================] - 4s 92ms/step - loss: 0.2059 - val_loss: 0.3001\n","Epoch 74/100\n","40/40 [==============================] - 4s 92ms/step - loss: 0.2046 - val_loss: 0.2993\n","Epoch 75/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2039 - val_loss: 0.3015\n","Epoch 76/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2028 - val_loss: 0.3035\n","Epoch 77/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2031 - val_loss: 0.3011\n","Epoch 78/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2042 - val_loss: 0.3013\n","Epoch 79/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2030 - val_loss: 0.2978\n","Epoch 80/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2011 - val_loss: 0.2938\n","Epoch 81/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.1987 - val_loss: 0.3002\n","Epoch 82/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2018 - val_loss: 0.2927\n","Epoch 83/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2026 - val_loss: 0.2994\n","Epoch 84/100\n","40/40 [==============================] - 4s 92ms/step - loss: 0.2026 - val_loss: 0.2981\n","Epoch 85/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2020 - val_loss: 0.2980\n","Epoch 86/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2013 - val_loss: 0.2967\n","Epoch 87/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2018 - val_loss: 0.2998\n","Epoch 88/100\n","40/40 [==============================] - 4s 92ms/step - loss: 0.2030 - val_loss: 0.2984\n","Epoch 89/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2028 - val_loss: 0.2987\n","Epoch 90/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.1998 - val_loss: 0.2949\n","Epoch 91/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2007 - val_loss: 0.2950\n","Epoch 92/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.1997 - val_loss: 0.2891\n","Epoch 93/100\n","40/40 [==============================] - 4s 92ms/step - loss: 0.2003 - val_loss: 0.2938\n","Epoch 94/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.2002 - val_loss: 0.2927\n","Epoch 95/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.1973 - val_loss: 0.2807\n","Epoch 96/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.1940 - val_loss: 0.2876\n","Epoch 97/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.1951 - val_loss: 0.2871\n","Epoch 98/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.1975 - val_loss: 0.2917\n","Epoch 99/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.1980 - val_loss: 0.2942\n","Epoch 100/100\n","40/40 [==============================] - 4s 93ms/step - loss: 0.1974 - val_loss: 0.2868\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f45c3172190>"]},"metadata":{},"execution_count":86}]},{"cell_type":"code","source":["# INFERENCE MODE\n","\n","# Decoding test sentence STEPS:\n","# 1) Encode the input sentence and retrieve the initial decoder state\n","# 2) Run one step of the decoder with this initial state and a \"start of sequence\" token as target. The output will be the next target character.\n","# 3) Append the target character predicted and repeat.\n","\n","# Inference setup \n","encoder_model = Model(encoder_inputs, encoder_states)\n","\n","decoder_state_input_h = Input(shape=(latent_dim,))\n","decoder_state_input_c = Input(shape=(latent_dim,))\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","decoder_outputs, state_h, state_c = decoder_lstm(\n","    decoder_inputs, initial_state=decoder_states_inputs)\n","decoder_states = [state_h, state_c]\n","decoder_outputs = decoder_dense(decoder_outputs)\n","decoder_model = Model(\n","    [decoder_inputs] + decoder_states_inputs,\n","    [decoder_outputs] + decoder_states)\n","\n","reverse_input_char_index = dict(\n","    (i, char) for char, i in input_token_index.items())\n","reverse_target_char_index = dict(\n","    (i, char) for char, i in target_token_index.items())"],"metadata":{"id":"pH4RVbkXkmFk"},"id":"pH4RVbkXkmFk","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def decode_sequence(input_seq):\n","    # Encode the input as state vectors.\n","    states_value = encoder_model.predict(input_seq)\n","\n","    # Generate empty target sequence of length 1.\n","    target_seq = np.zeros((1, 1, num_decoder_tokens))\n","    # Populate the first character of target sequence with the start character.\n","    target_seq[0, 0, target_token_index['\\t']] = 1.\n","\n","    # Sampling loop for a batch of sequences\n","    # (to simplify, here we assume a batch of size 1).\n","    stop_condition = False\n","    decoded_sentence = ''\n","    while not stop_condition:\n","        output_tokens, h, c = decoder_model.predict(\n","            [target_seq] + states_value)\n","\n","        # Sample a token\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        sampled_char = reverse_target_char_index[sampled_token_index]\n","        decoded_sentence += sampled_char\n","\n","        # Exit condition: either hit max length\n","        # or find stop character.\n","        if (sampled_char == '\\n' or\n","           len(decoded_sentence) > max_decoder_seq_length):\n","            stop_condition = True\n","\n","        # Update the target sequence (of length 1).\n","        target_seq = np.zeros((1, 1, num_decoder_tokens))\n","        target_seq[0, 0, sampled_token_index] = 1.\n","\n","        # Update states\n","        states_value = [h, c]\n","\n","    return decoded_sentence"],"metadata":{"id":"R5X-tlxBpKAq"},"id":"R5X-tlxBpKAq","execution_count":null,"outputs":[]},{"cell_type":"code","source":["for seq_index in range(100):\n","    input_seq = encoder_input_data[seq_index: seq_index + 1]\n","    decoded_sentence = decode_sequence(input_seq)\n","    print('-')\n","    print('Input sentence:', input_texts[seq_index])\n","    print('Decoded sentence:', decoded_sentence)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BOE6i4fHvPtZ","executionInfo":{"status":"ok","timestamp":1653621495878,"user_tz":420,"elapsed":24186,"user":{"displayName":"Justin Goh","userId":"02749663324647441700"}},"outputId":"caaa9253-a962-47d0-f86c-a2a8e87a489d"},"id":"BOE6i4fHvPtZ","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["-\n","Input sentence: Was Abraham Lincoln the sixteenth President of the United States?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Did Lincoln sign the National Banking Act of 1863?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Did his mother die of pneumonia?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: How many long was Lincoln's formal education?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: How many long was Lincoln's formal education?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: When did Lincoln begin his political career?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: When did Lincoln begin his political career?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: What did The Legal Tender Act of 1862 establish?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: What did The Legal Tender Act of 1862 establish?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Who suggested Lincoln grow a beard?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Who suggested Lincoln grow a beard?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: When did the Gettysburg address argue that America was born?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: When did the Gettysburg address argue that America was born?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Did Lincoln beat John C. Breckinridge in the 1860 election?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Was Abraham Lincoln the first President of the United States?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Was Abraham Lincoln the first President of the United States?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Did Lincoln start his political career in 1832?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Did Lincoln start his political career in 1832?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Did Lincoln ever represent Alton & Sangamon Railroad?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Did Lincoln ever represent Alton & Sangamon Railroad?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Which county was Lincoln born in?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Which county was Lincoln born in?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: When did Lincoln first serve as President?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: When did Lincoln first serve as President?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Who assassinated Lincoln?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Who assassinated Lincoln?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Did Lincoln win the election of 1860?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Did Lincoln win the election of 1860?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Who was the general in charge at the Battle of Antietam?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Who was the general in charge at the Battle of Antietam?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Why did Lincoln issue the Emancipation Proclamation?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Why did Lincoln issue the Emancipation Proclamation?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Do scholars rank lincoln among the top three presidents?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Did lincoln have 18 months of schooling?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Was Lincoln chosen as a presidential candidate in 1860?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: How old was Lincoln in 1816?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: When was the first photgraph of lincoln taken?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: How long was Lincoln's legal Career?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: What trail did Lincoln use a Farmers' Almanac in? \n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Did Abraham Lincoln live in the Frontier?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Did Lincoln's Wife's Family support slavery?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Who is most noted for his contributions to the theory of molarity and molecular weight?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Who graduated in ecclesiastical law at the early age of 20 and began to practice?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Who graduated in ecclesiastical law at the early age of 20 and began to practice?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: When did he publish another memoria?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: When did he become a professor?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Is it true that he became a professor in 1820?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Was Lorenzo Romano Amedeo Carlo Avogadro an Italian savant?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Was Amedeo Avogadro born in Turin August 9th 1776 to a noble ancient family of Piedmont, Italy?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Is he most noted for his contributions to the theory of molarity and molecular weight?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Was King Victor Emmanuel III there to pay homage to Avogadro ?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Is Avogadro 's number commonly used to compute the results of chemical reactions ?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Did the scientific community not reserve great attention to his theory ?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Was King Victor Emmanuel III there to pay homage to Avogadro ?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Can the title of this famous 1811 paper be roughly translated into english?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: What happened in 1833?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: What happened in 1833?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Who determined the dependence of the boiling of water with atmospheric pressure?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: What is named after him?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: When did he publish a collection?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Is it true that he published a collection in 1738?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Is it true that thermometer had 100 for the freezing point?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Was Celsius born in Uppsala in Sweden?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Was Anders Celsius (November 27, 1701 April 25, 1744) a Swedish astronomer?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Is The Celsius crater on the Moon named after him?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Who was the first to perform and publish careful experiments aiming at the definition of an international temperature scale on scientific grounds ?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: The Celsius crater on the Moon is what?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Is the Celsius crater on the Moon named after him ?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Had his thermometer 100 for the freezing point of water and 0 for the boiling point ?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Was Celsius born in Uppsala in Sweden ?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Is the Celsius crater on the Moon named after him ?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Did he not determine the dependence of the boiling of water with atmospheric pressure -LRB- in excellent agreement with modern data -RRB- ?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: What happened from 1730 to 1744?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: What happened in 1745?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Are beetles insects?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Are beetles insects?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Can beetles be found in polar regions?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Can beetles be found in polar regions?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Do beetles antennae function primarily as organs of smell?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Do beetles antennae function primarily as organs of smell?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: What are the three sections of a beetle?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: What are the three sections of a beetle?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Which defense mechanism uses colour or shape to deceive potential enemies?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Which defense mechanism uses colour or shape to deceive potential enemies?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Which type of beetle is a pest of potato plants?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Which type of beetle is a pest of potato plants?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: How can beetle larvae be differentiated from other insect larvae?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: How can beetle larvae be differentiated from other insect larvae?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: What do beetles eat?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: What do beetles eat?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: What are the similarities between beetles and grasshoppers?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: What are the similarities between beetles and grasshoppers?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Are certain species of beetles considered pests?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Are certain species of beetles considered pests?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Is a beetle's general anatomy uniform?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Is a beetle's general anatomy uniform?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Are beetles endopterygotes?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: Are beetles endopterygotes?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: How many species of beetles are there?\n","Decoded sentence: Yes\n","\n","-\n","Input sentence: How many species of beetles are there?\n","Decoded sentence: Yes\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"aYmG55O3vPwC"},"id":"aYmG55O3vPwC","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"cZAPg-n8vPyy"},"id":"cZAPg-n8vPyy","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"E0EOlup-vP1r"},"id":"E0EOlup-vP1r","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9d4DR8tMvP48"},"id":"9d4DR8tMvP48","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"provenance":[],"collapsed_sections":["L263t8-GBEXc","vOCiL7w5Xdlv","Owbm0S1yXhue","d1329350"],"machine_shape":"hm"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}