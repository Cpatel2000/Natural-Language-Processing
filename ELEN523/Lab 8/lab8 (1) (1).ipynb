{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"ol7ogZKGMNS-","outputId":"f443b04d-caab-4ef1-90e9-4d31a3e1e2a5"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-06-09 23:41:30.513929: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n","2023-06-09 23:41:30.569818: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n","2023-06-09 23:41:30.570745: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-06-09 23:41:31.700049: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]}],"source":["import math\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.preprocessing.text import Tokenizer"]},{"cell_type":"markdown","source":["Chitvan Patel & Allen Shelton"],"metadata":{"id":"eGzy6sqnMoAV"}},{"cell_type":"markdown","metadata":{"id":"4zcLOIleMNS_"},"source":["# 1. Introduction\n","\n","In this lab, you will see the power of word embeddings, and how embeddings can be used in different applications.\n","\n","Summarize the papers that were distributed with the module."]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R4C5mK9kPjLr","executionInfo":{"status":"ok","timestamp":1687204821065,"user_tz":420,"elapsed":177,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}},"outputId":"3dc8fc3c-0ae3-4491-f3e9-db345f1763dc"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: nvidia-smi: command not found\n"]}]},{"cell_type":"markdown","source":["**Effective Approaches to Attention-based Neural Machine Translation**\n","\n","The task of Machine Translation (MT) involves understanding natural language and has traditionally been challenging to improve performance. However, the introduction of neural networks in MT has led to significant advancements, surpassing the performance of conventional phrase-based translation.\n","\n","To enhance the performance of Neural Machine Translation (NMT), the authors utilized additive attention. This was necessary because incorporating all the information from a source sentence into a fixed-length vector, known as a context vector, posed difficulties. To overcome this, the authors employed soft-alignment, which enabled joint learning of alignment and translation.\n","\n","From a probabilistic standpoint, translation involves finding a target sentence that maximizes the conditional probability given a source sentence. The authors proposed two attention mechanisms: global attention and local attention. The local attention mechanism, which is a novel approach, considers the trade-off between soft and hard attention models proposed by Xu et al. (2015).\n","\n","NMT has gained popularity due to its state-of-the-art performance in large-scale translation tasks, such as English to French/German. It requires minimal domain knowledge and is conceptually simple. Furthermore, NMT has a smaller memory footprint compared to systems that rely on extensive phrase tables and language models. Additionally, NMT exhibits the ability to handle long word sentences effectively.\n","\n","In non-attention-based RNN architectures, the source representation S is used only once to initialize the decoder hidden state. In contrast, attention-based networks consider a set of source hidden states S throughout the translation process. Global attention is computationally expensive and less effective for long sentences, while local attention focuses on a subset of hidden states to address this issue.\n","\n","The input-feeding approach was introduced to ensure that future alignment decisions incorporate past alignment information. This is achieved by concatenating the previous alignment information, represented as h_bar(t), with inputs at subsequent time steps. This approach enables the model to be fully aware of previous alignment choices and facilitates the creation of a deep network that spans horizontally and vertically."],"metadata":{"id":"LSgx_n-xMaOl"}},{"cell_type":"markdown","source":["**Attention is all you need**\n","\n","The paper aims to address the limitations of sequential computation in recurrent neural networks (RNNs), long short-term memory networks (LSTMs), and gated RNNs for sequence modeling tasks like machine translation and language modeling. These approaches process sequences word-by-word in a sequential manner, hindering parallelization and causing issues with long-range dependencies.\n","\n","To overcome these challenges, attention mechanisms have been proposed. They allow for modeling dependencies without considering their distance in the input or output sequences and have become integral to sequence modeling. However, attention mechanisms are typically used in combination with recurrent networks.\n","\n","The paper introduces the Transformer model, which relies solely on attention mechanisms to capture global dependencies between inputs and outputs. This architecture enables significantly more parallelization and achieves remarkable translation quality with relatively short training times.\n","\n","The Transformer follows an encoder-decoder structure, using stacked self-attention and point-wise fully connected layers for both the encoder and decoder. It utilizes scaled dot-product attention and multi-head attention to jointly attend to information from different representation subspaces at different positions.\n","\n","Compared to recurrent layers, self-attention layers in the Transformer have lower computational complexity per layer and allow for more efficient parallelization. This makes the Transformer faster for machine translation tasks, especially when the sequence length is smaller than the representation dimensionality.\n","\n","The paper highlights that the Transformer outperforms previous models on English-to-German and English-to-French translation tasks, achieving a new state-of-the-art performance. The authors also express their intention to explore the application of the Transformer in other domains involving different modalities like images, audio, and video.\n","\n","The Transformer architecture presented in the paper has gained significant attention and popularity, leading to its implementation and adoption in various natural language processing (NLP) tasks. Additionally, an annotated version of the paper, accompanied by PyTorch code, has been released to facilitate understanding and further experimentation with the Transformer model."],"metadata":{"id":"-kIeVXuZMa2I"}},{"cell_type":"markdown","source":["**Deep contextualized word representations**\n","\n","Word representations are crucial in Natural Language Processing (NLP) systems as they enable us to convert text into numerical representations that computers can understand. Over the years, various word representations have been developed to capture the semantics and syntactic dependencies of words. However, creating accurate word representations that account for the complexities of human language is a challenging task.\n","\n","Good word representations should group similar words together, reflecting their semantic similarities. Additionally, they need to consider language polysemy, where a word can have multiple meanings in different contexts. For example, the word \"apple\" can refer to a fruit or a technology company. Previous approaches, such as label encoding or one-hot encoding, have limitations in terms of bias and computational efficiency.\n","\n","To address these issues, Deep Contextualized Word Representations (ELMo) gained attention. ELMo breaks down words into atomic units, capturing insights into word formation. It recognizes that words can have different meanings depending on the context and computes representations by considering the entire sequence as input.\n","\n","ELMo incorporates Convolutional Neural Networks (CNNs) to extract character-based embeddings and capture n-gram features. These embeddings handle out-of-vocabulary words effectively and provide finer language details. Bi-directional Long Short-Term Memory (LSTM) layers consider input from both past and future contexts, preserving information about the entire sequence.\n","\n","Unlike previous models, ELMo uses a linear combination of all LSTM hidden states, giving different weights to each layer based on the task at hand. Higher-level layers capture context-dependent aspects of word meaning, while lower-level layers model language syntax. This allows for rich word representations with different properties for various NLP tasks.\n","\n","Experimental results demonstrate the power of ELMo, surpassing state-of-the-art performance across various NLP problems. ELMo's representations can be easily incorporated into existing architectures, enabling transfer learning and semi-supervised learning. This approach has proven effective in computer vision, and ELMo opens up similar possibilities in language models.\n","\n","In conclusion, ELMo introduces a general approach to learning high-quality deep context-dependent word representations. It offers the potential for leveraging pre-trained representations and applying them to different NLP tasks, reducing the need for task-specific model training from scratch. The future holds exciting prospects for further advancements in language model transfer learning."],"metadata":{"id":"jcDxUbyaMeAu"}},{"cell_type":"markdown","metadata":{"id":"ijPSRcZvMNTB"},"source":["# 2. GloVe\n","\n","We will first read imdb movie reviews to train a GloVe embeddings.\n","\n","GloVe is computed from a co-occurrence matrix $X$ as follows:\n","\n","$\n","J = \\sum_{i=1,j=1}^{V,V} f(X_{ij}) (w_i^T w_j + b_i + b_j - log(X_{ij}))^2\n","$\n","\n","$f(X_{ij}) = (X_{ij} / X_{\\max})^\\alpha$ if $X_{ij} < X_{\\max}$; otherwise it is $1$.\n","\n","$\n","\\nabla_{w_i} J = f(X_{ij}) w_j (w_i^T w_j + b_i + b_j - log(X_{ij}))\n","$\n","\n","$\n","\\nabla_{w_j} J = f(X_{ij}) w_i (w_i^T w_j + b_i + b_j - log(X_{ij}))\n","$\n","\n","$\n","\\nabla_{b_i} J = \\nabla_{b_j} J = f(X_{ij}) (w_i^T w_j + b_i + b_j - log(X_{ij}))\n","$"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"HDvRgW9XMNTB"},"outputs":[],"source":["from keras import preprocessing\n","from keras.datasets import imdb\n","from random import shuffle"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"bCT_pKVdMNTB","outputId":"9fe196f9-1ee4-443d-9cab-4734a5b99fe4"},"outputs":[{"data":{"text/plain":["\"[START] this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert redford's is an amazing actor and now the same being director norman's father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for retail and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also congratulations to the two little boy's that played the part's of norman and paul they were just brilliant children are often left out of the praising list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["start_char = 1\n","oov_char = 2\n","index_from = 3\n","\n","(x_train, _), _ = imdb.load_data(\n","    start_char=start_char, oov_char=oov_char, index_from=index_from\n",")\n","\n","word_index = imdb.get_word_index()\n","inverted_word_index = dict(\n","    (i + index_from, word) for (word, i) in word_index.items()\n",")\n","# Update `inverted_word_index` to include `start_char` and `oov_char`\n","inverted_word_index[start_char] = \"[START]\"\n","inverted_word_index[oov_char] = \"[OOV]\"\n","vocab_size = max(word_index.values()) + index_from\n","\n","decoded_sequence = \" \".join(inverted_word_index[i] for i in x_train[0])\n","decoded_sequence"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"CZM9uVUMMNTC"},"outputs":[],"source":["from tqdm import tqdm\n","import os\n","\n","window = 10\n","left_window = window // 2\n","right_window = window - left_window\n","\n","def gen_X():\n","    if os.path.exists('indexes.npy') and os.path.exists('X.npy'): return\n","    X = np.zeros((vocab_size, vocab_size), dtype=np.float32)\n","    indexes = set()\n","    for s in tqdm(x_train):\n","        for i in range(len(s)):\n","            w = s[i]\n","            j_indexes = np.concatenate([\n","                np.arange(max(0, i - left_window), i),\n","                np.arange(i+1, min(len(s), i + right_window + 1))])\n","            for j in j_indexes:\n","                d = 1.0 / (j - i)\n","                c = s[j]\n","                X[w, c] += d\n","    indexes = []\n","    all_idx = np.arange(vocab_size)\n","    for i in tqdm(range(vocab_size)):\n","        mask = X[i] != 0\n","        if np.sum(mask) == 0: continue\n","        for j in all_idx[mask]:\n","            indexes.append((i, j))\n","\n","    indexes = np.array(indexes, dtype=np.int64)\n","\n","    # generate f function\n","    np.save('X.npy', X.astype(np.float32))\n","    np.save('indexes.npy', indexes)\n","\n","gen_X()"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"-TRQ8R5TMNTC"},"outputs":[],"source":["embedding_size = 50"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"kJ6xbgyPMNTC"},"outputs":[],"source":["import torch\n","\n","class Glove(torch.nn.Module):\n","    def __init__(self, vocab_size, embedding_size):\n","        super().__init__()\n","        self.W = torch.nn.Embedding(vocab_size, embedding_size)\n","        self.C = torch.nn.Embedding(vocab_size, embedding_size)\n","        self.b_w = torch.nn.Embedding(vocab_size, 1)\n","        self.b_c = torch.nn.Embedding(vocab_size, 1)\n","\n","    def loss(self, index, Xij, Xmax=1000, alpha=0.75):\n","        i = index[:, 0]\n","        j = index[:, 1]\n","\n","        f = torch.where(Xij < Xmax, torch.pow(Xij / Xmax, alpha), 1)\n","        loss = f * torch.pow(\n","            torch.einsum('ij,ij->i', self.W(i), self.C(j)) +\n","            self.b_w(i) + self.b_c(j) - torch.log10(Xij + 1e-6), 2)\n","\n","        return loss.mean()"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"P0ndsozsMNTD"},"outputs":[],"source":["glove = Glove(vocab_size, embedding_size)\n","\n","# load but leave vectors in disk\n","X = np.load('X.npy', mmap_mode='r')\n","indexes = np.load('indexes.npy', mmap_mode='r')\n","\n","shuffle_idx = np.arange(len(indexes))\n","np.random.shuffle(shuffle_idx)"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"pftJyv8pMNTD","outputId":"76c31d5f-4554-42b3-a19f-41037cf29b06"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["glove.load_state_dict(torch.load('glove.pth'))"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"3ljpZTyPMNTD"},"outputs":[],"source":["device = 'cuda'"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"ozZwuaDvMNTD","outputId":"f83533ff-104d-4088-c05b-5c1e8a51f76c"},"outputs":[{"name":"stdout","output_type":"stream","text":["... done wth transferring to device\n"]}],"source":["glove = glove.to(device)\n","\n","print('... done wth transferring to device')"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"tags":[],"id":"c1m5fAKbMNTD","outputId":"c29928ea-4f63-4f0d-d890-06e2c5da28d3"},"outputs":[{"name":"stdout","output_type":"stream","text":["epoch 0\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [02:33<00:00,  9.18it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 0: 0.06248276188863554 good.bad = -0.03340145945549011\n","epoch 1\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.61it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 1: 0.03317142643326118 good.bad = -0.024984167888760567\n","epoch 2\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.61it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 2: 0.02259632499285334 good.bad = -0.019734593108296394\n","epoch 3\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:35<00:00, 14.64it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 3: 0.016814856449294556 good.bad = -0.016693606972694397\n","epoch 4\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 4: 0.01317681285463194 good.bad = -0.015193117782473564\n","epoch 5\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 5: 0.010713815233368573 good.bad = -0.014707675203680992\n","epoch 6\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:37<00:00, 14.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 6: 0.008965125818839594 good.bad = -0.014870867133140564\n","epoch 7\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:35<00:00, 14.69it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 7: 0.007675514038440066 good.bad = -0.015435706824064255\n","epoch 8\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:35<00:00, 14.66it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 8: 0.006705324119785502 good.bad = -0.016230471432209015\n","epoch 9\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 9: 0.0059518910743945755 good.bad = -0.01714819110929966\n","epoch 10\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 10: 0.005358907364116604 good.bad = -0.018106093630194664\n","epoch 11\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 11: 0.004886389062889053 good.bad = -0.0190516896545887\n","epoch 12\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:35<00:00, 14.71it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 12: 0.004506001805263535 good.bad = -0.019947195425629616\n","epoch 13\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 13: 0.004192515127393964 good.bad = -0.020767763257026672\n","epoch 14\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:35<00:00, 14.78it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 14: 0.003935289593559302 good.bad = -0.02149774506688118\n","epoch 15\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:35<00:00, 14.66it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 15: 0.0037211891508982698 good.bad = -0.022129258140921593\n","epoch 16\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:35<00:00, 14.71it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 16: 0.00354880151451562 good.bad = -0.02265794388949871\n","epoch 17\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 17: 0.0033935965560840647 good.bad = -0.023084860295057297\n","epoch 18\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 18: 0.0032625092655831278 good.bad = -0.023411406204104424\n","epoch 19\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 19: 0.0031515206024713576 good.bad = -0.02364262193441391\n","epoch 20\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.63it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 20: 0.003058399775254398 good.bad = -0.023783963173627853\n","epoch 21\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:37<00:00, 14.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 21: 0.0029800133399327296 good.bad = -0.02384157106280327\n","epoch 22\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 22: 0.00290548521039338 good.bad = -0.023821726441383362\n","epoch 23\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.58it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 23: 0.002846150808831763 good.bad = -0.023731477558612823\n","epoch 24\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 24: 0.002789799406257826 good.bad = -0.023576965555548668\n","epoch 25\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:35<00:00, 14.66it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 25: 0.002743588176844277 good.bad = -0.02336505986750126\n","epoch 26\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:35<00:00, 14.66it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 26: 0.002701136177435544 good.bad = -0.02310149185359478\n","epoch 27\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.58it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 27: 0.002670788661215547 good.bad = -0.022792331874370575\n","epoch 28\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:35<00:00, 14.66it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 28: 0.0026328542877114593 good.bad = -0.02244432456791401\n","epoch 29\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 29: 0.0026045046213954634 good.bad = -0.022059030830860138\n","epoch 30\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.58it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 30: 0.0025779960065536547 good.bad = -0.02164446748793125\n","epoch 31\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.62it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 31: 0.002554772372251489 good.bad = -0.021204203367233276\n","epoch 32\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.56it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 32: 0.0025331759622347046 good.bad = -0.02074250392615795\n","epoch 33\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:35<00:00, 14.66it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 33: 0.0025143549287048733 good.bad = -0.020263075828552246\n","epoch 34\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:35<00:00, 14.66it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 34: 0.0024983906591463556 good.bad = -0.019768062978982925\n","epoch 35\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:35<00:00, 14.67it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 35: 0.002484748463496049 good.bad = -0.019261859357357025\n","epoch 36\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 36: 0.0024703890957713816 good.bad = -0.018747352063655853\n","epoch 37\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.61it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 37: 0.0024594494773843905 good.bad = -0.01822620816528797\n","epoch 38\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:35<00:00, 14.77it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 38: 0.002445270789843517 good.bad = -0.017701920121908188\n","epoch 39\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:35<00:00, 14.64it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 39: 0.0024365651301933564 good.bad = -0.017176667228341103\n","epoch 40\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.61it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 40: 0.002425451380378 good.bad = -0.016650931909680367\n","epoch 41\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 41: 0.002417023250629323 good.bad = -0.01612660475075245\n","epoch 42\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:37<00:00, 14.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 42: 0.0024096596174876727 good.bad = -0.015606082044541836\n","epoch 43\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:37<00:00, 14.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 43: 0.002402121242006505 good.bad = -0.01509122084826231\n","epoch 44\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 44: 0.00239915789077655 good.bad = -0.014580445364117622\n","epoch 45\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:35<00:00, 14.67it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 45: 0.0023900524178251384 good.bad = -0.014077920466661453\n","epoch 46\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:35<00:00, 14.73it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 46: 0.0023852556617847674 good.bad = -0.013583346270024776\n","epoch 47\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:35<00:00, 14.69it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 47: 0.0023798566462399167 good.bad = -0.013097896240651608\n","epoch 48\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:35<00:00, 14.68it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 48: 0.0023737788460137872 good.bad = -0.012620002031326294\n","epoch 49\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.62it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 49: 0.002374002364135987 good.bad = -0.012153136543929577\n","epoch 50\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:35<00:00, 14.72it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 50: 0.0023657625007900505 good.bad = -0.01169655378907919\n","epoch 51\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:35<00:00, 14.72it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 51: 0.0023615060749486937 good.bad = -0.011250740848481655\n","epoch 52\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:35<00:00, 14.67it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 52: 0.0023597445945898435 good.bad = -0.01081642135977745\n","epoch 53\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:35<00:00, 14.70it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 53: 0.002354899912432923 good.bad = -0.010392813012003899\n","epoch 54\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:34<00:00, 14.81it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 54: 0.002354936657789962 good.bad = -0.009982115589082241\n","epoch 55\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:35<00:00, 14.69it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 55: 0.0023487493633193184 good.bad = -0.009580831974744797\n","epoch 56\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:35<00:00, 14.70it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 56: 0.0023462268027553196 good.bad = -0.00919290166348219\n","epoch 57\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:35<00:00, 14.70it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 57: 0.0023436834794979583 good.bad = -0.008815707638859749\n","epoch 58\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:35<00:00, 14.77it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 58: 0.0023412997855098913 good.bad = -0.008450955152511597\n","epoch 59\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:35<00:00, 14.66it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 59: 0.0023392193291992534 good.bad = -0.00809763465076685\n","epoch 60\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:35<00:00, 14.69it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 60: 0.002337520486497887 good.bad = -0.007756185717880726\n","epoch 61\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.53it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 61: 0.0023380232371267235 good.bad = -0.007426075171679258\n","epoch 62\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:37<00:00, 14.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 62: 0.002333400629832015 good.bad = -0.007107153069227934\n","epoch 63\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.64it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 63: 0.0023316660809357156 good.bad = -0.006799257360398769\n","epoch 64\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.53it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 64: 0.002329948551358748 good.bad = -0.006502607371658087\n","epoch 65\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:37<00:00, 14.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 65: 0.002331054501825433 good.bad = -0.006216910667717457\n","epoch 66\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.63it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 66: 0.002328756836067315 good.bad = -0.005972929298877716\n","epoch 67\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 67: 0.002326344055938949 good.bad = -0.0056764367036521435\n","epoch 68\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:35<00:00, 14.65it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 68: 0.0023294759312730774 good.bad = -0.005421353038400412\n","epoch 69\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:35<00:00, 14.66it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 69: 0.0023237707596305375 good.bad = -0.005176565144211054\n","epoch 70\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 70: 0.002325895865981424 good.bad = -0.004941058345139027\n","epoch 71\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:35<00:00, 14.72it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 71: 0.0023213513086556567 good.bad = -0.00471485685557127\n","epoch 72\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:35<00:00, 14.65it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 72: 0.0023220601384743413 good.bad = -0.00449789222329855\n","epoch 73\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 73: 0.0023232495284629356 good.bad = -0.004289791453629732\n","epoch 74\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 74: 0.0023183781322211132 good.bad = -0.004090576432645321\n","epoch 75\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 75: 0.0023183026508878904 good.bad = -0.0038987495936453342\n","epoch 76\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:35<00:00, 14.67it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 76: 0.0023216753356652565 good.bad = -0.0037153454031795263\n","epoch 77\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.62it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 77: 0.0023159891868663085 good.bad = -0.003539860248565674\n","epoch 78\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 78: 0.002316918812677251 good.bad = -0.003371940925717354\n","epoch 79\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:35<00:00, 14.68it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 79: 0.002314940580122133 good.bad = -0.0032112221233546734\n","epoch 80\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.61it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 80: 0.0023168411248386755 good.bad = -0.003057246096432209\n","epoch 81\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:35<00:00, 14.64it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 81: 0.0023144929168092956 good.bad = -0.002910197712481022\n","epoch 82\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.61it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 82: 0.002313349203470087 good.bad = -0.0027696702163666487\n","epoch 83\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.58it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 83: 0.0023154124236016062 good.bad = -0.002635475480929017\n","epoch 84\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 84: 0.0023127273888844213 good.bad = -0.002507021650671959\n","epoch 85\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:35<00:00, 14.70it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 85: 0.0023109349874560836 good.bad = -0.002385345520451665\n","epoch 86\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:35<00:00, 14.64it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 86: 0.0023110343689791645 good.bad = -0.002267694566398859\n","epoch 87\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.52it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 87: 0.0023111563118744733 good.bad = -0.00215611862950027\n","epoch 88\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 88: 0.0023096024057516346 good.bad = -0.0020496349316090345\n","epoch 89\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.63it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 89: 0.0023094096450960375 good.bad = -0.0019481094786897302\n","epoch 90\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.62it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 90: 0.0023086791465123553 good.bad = -0.0018512142123654485\n","epoch 91\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 91: 0.0023095542325528864 good.bad = -0.0017658504657447338\n","epoch 92\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:35<00:00, 14.64it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 92: 0.0023137365322430815 good.bad = -0.0016709745395928621\n","epoch 93\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:37<00:00, 14.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 93: 0.002307774529260421 good.bad = -0.0015874382806941867\n","epoch 94\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.53it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 94: 0.0023074586391018115 good.bad = -0.001507174107246101\n","epoch 95\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.58it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 95: 0.0023080542326898205 good.bad = -0.0014313148567453027\n","epoch 96\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 96: 0.0023077587320326806 good.bad = -0.0013589588925242424\n","epoch 97\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:35<00:00, 14.70it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 97: 0.002306541762964343 good.bad = -0.0012901582522317767\n","epoch 98\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:35<00:00, 14.75it/s]\n"]},{"name":"stdout","output_type":"stream","text":["... 98: 0.0023127468219988076 good.bad = -0.0012249466963112354\n","epoch 99\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1405/1405 [01:36<00:00, 14.53it/s]"]},{"name":"stdout","output_type":"stream","text":["... 99: 0.0023090753530307915 good.bad = -0.001161817810498178\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["optimizer = torch.optim.Adagrad(glove.parameters(), lr=0.005, weight_decay=0.95)\n","\n","good = torch.tensor(word_index['good'] + index_from, dtype=torch.int64).to('cuda')\n","bad = torch.tensor(word_index['bad'] + index_from, dtype=torch.int64).to('cuda')\n","\n","epochs = 100\n","batch_size = 8192\n","Xmax = 1000.0\n","for epoch in range(epochs):\n","    print('epoch', epoch)\n","    np.random.shuffle(shuffle_idx)\n","    loss_v = []\n","    for i in tqdm(range(0, len(shuffle_idx), batch_size)):\n","        index_batch = shuffle_idx[i:i+batch_size]\n","        index_batch = np.array([indexes[ii] for ii in index_batch])\n","        X_batch = np.concatenate(\n","            [[X[ii,jj]] for ii, jj in index_batch ]).astype(np.float32)\n","        X_batch = np.clip(X_batch, 0.0, Xmax)\n","        index_batch = torch.from_numpy(np.array(index_batch).astype(np.int64)).to('cuda')\n","        X_batch = torch.from_numpy(X_batch.astype(np.float32)).to('cuda')\n","        loss = glove.loss(index_batch, X_batch, Xmax)\n","        loss_v.append(loss.item())\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","    good_v = glove.W(good).detach().cpu().numpy()\n","    bad_v = glove.W(bad).detach().cpu().numpy()\n","    good_v = good_v / np.linalg.norm(good_v)\n","    bad_v = bad_v / np.linalg.norm(bad_v)\n","\n","    print(f'... {epoch}: {np.mean(loss_v)} good.bad = {np.dot(good_v, bad_v)}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"cndQlIObMNTE"},"outputs":[],"source":["torch.save(glove.state_dict(), 'glove.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"FrRHAhy4MNTE","outputId":"48dbc61f-96d9-4b64-d62f-0ad89814f98a"},"outputs":[{"data":{"text/plain":["-0.0011618178"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["good = torch.tensor(word_index['good'] + index_from, dtype=torch.int64).to('cuda')\n","bad = torch.tensor(word_index['bad'] + index_from, dtype=torch.int64).to('cuda')\n","\n","good_v = glove.W(good).detach().cpu().numpy()\n","bad_v = glove.W(bad).detach().cpu().numpy()\n","good_v = good_v / np.linalg.norm(good_v)\n","bad_v = bad_v / np.linalg.norm(bad_v)\n","\n","np.dot(good_v, bad_v)"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"IwZLBCtFMNTE","outputId":"063797f9-a300-4065-e0ee-ac9f0bdfa6b5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Synonym for positive: buoy  Dot product: 0.23424024879932404\n","Antonym for positive: worzel  Dot product: -0.21876290440559387\n"]}],"source":["positive = torch.tensor(word_index['positive'] + index_from, dtype=torch.int64)\n","positive_v = glove.W(positive).detach().cpu().numpy()\n","\n","synonym = ('',0)\n","antonym = ('',1)\n","for word in word_index.values():\n","    if inverted_word_index[word + index_from] != 'positive':\n","        word_v = glove.W(torch.tensor(word, dtype=torch.int64)).detach().cpu().numpy()\n","        similarity = np.dot(word_v, positive_v)\n","        if similarity > synonym[1]:\n","            synonym = (inverted_word_index[word + index_from],similarity)\n","        if similarity < antonym[1]:\n","            antonym = (inverted_word_index[word + index_from],similarity)\n","\n","print(f\"Synonym for positive: {synonym[0]}  Dot product: {synonym[1]}\")\n","print(f\"Antonym for positive: {antonym[0]}  Dot product: {antonym[1]}\")"]},{"cell_type":"markdown","metadata":{"id":"dJndWGmvMNTE"},"source":["Now explain with your own words how Glove works.  Find which word is a synonym for `positive` and an antonym for `positive`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-X8qkVswMNTE","outputId":"5ee8418f-2ad7-4ee9-b1b7-b3002e7497bd"},"outputs":[{"name":"stdout","output_type":"stream","text":["that -0.8571522583437434\n","deal 0.8781584108127223\n"]}],"source":["# your code goes here"]},{"cell_type":"markdown","metadata":{"id":"j6wByJuJMNTE"},"source":["# 3. Second Attempt to Build a Large Language Model\n","\n","In an attempt to create our first generator network before we start using transformers, you will build a large language model using a Convolutional (causal) and Embeddings.\n","\n","We will split this task into two task.\n","\n","- First task is to try to predict the next word.\n","- Second task is to implement and train a network that will use the head to predict the sentiment of the sentence."]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"Yk5t_SsjMNTE"},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch.nn import functional as F\n","import string\n","import os\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"ixw-E2pQMNTE","outputId":"d48b6ced-168a-4ab6-d8c1-e4732a4c89b2"},"outputs":[{"name":"stdout","output_type":"stream","text":["[79, 76, 83, 83, 86, 7, 94, 86, 89, 83, 75]\n","['[START]', '[OOV]', '[OOV]', 'h', 'e', 'l', 'l', 'o', ' ', 'w', 'o', 'r', 'l', 'd']\n"]}],"source":["class Tokenizer:\n","    def __init__(self):\n","        self.chars = ['\\00', '\\01'] + sorted(list(set(string.printable)))\n","        self.vocab_size = len(self.chars)\n","        self.stoi = { ch:i for i,ch in enumerate(self.chars) }\n","        self.itos = { i:ch for i,ch in enumerate(self.chars) }\n","\n","        self.itos[0] = '[START]'\n","        self.itos[1] = '[OOV]'\n","\n","    def encode(self, sentence):\n","        return [self.stoi[c] if c in self.stoi else 1 for c in sentence]\n","\n","    def decode(self, indexes):\n","        return [self.itos[i] for i in indexes]\n","\n","    def start(self): return '\\00'\n","\n","    def oov(self): return '\\01'\n","\n","tokenizer = Tokenizer()\n","print(tokenizer.encode('hello world'))\n","print(tokenizer.decode([0] + [1] + tokenizer.encode('\\x96hello world')))"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"kJiysTSRMNTF"},"outputs":[],"source":["def process_songs(df):\n","    songs = tokenizer.start().join(df.text.to_numpy())\n","    songs = tokenizer.start() + songs.replace('\\r', '', -1)\n","    return tokenizer.encode(songs)"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"frjKqRNdMNTF"},"outputs":[],"source":["# Download the song dataset from\n","# https://www.kaggle.com/datasets/notshrirang/spotify-million-song-dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"XjiIalxVMNTF","outputId":"c76ea4dc-79ed-4da2-9139-4a0db9a4131d"},"outputs":[{"name":"stdout","output_type":"stream","text":["57650 songs\n"]}],"source":["df = pd.read_csv('spotify_millsongdata.csv')\n","print(len(df), 'songs')"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"Q0eQlcT6MNTF","outputId":"c4a4094f-3925-49a1-c2b5-183f8da6f794"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>artist</th>\n","      <th>song</th>\n","      <th>link</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ABBA</td>\n","      <td>Ahe's My Kind Of Girl</td>\n","      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n","      <td>Look at her face, it's a wonderful face  \\r\\nA...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ABBA</td>\n","      <td>Andante, Andante</td>\n","      <td>/a/abba/andante+andante_20002708.html</td>\n","      <td>Take it easy with me, please  \\r\\nTouch me gen...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ABBA</td>\n","      <td>As Good As New</td>\n","      <td>/a/abba/as+good+as+new_20003033.html</td>\n","      <td>I'll never know why I had to go  \\r\\nWhy I had...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ABBA</td>\n","      <td>Bang</td>\n","      <td>/a/abba/bang_20598415.html</td>\n","      <td>Making somebody happy is a question of give an...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ABBA</td>\n","      <td>Bang-A-Boomerang</td>\n","      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n","      <td>Making somebody happy is a question of give an...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  artist                   song                                        link  \\\n","0   ABBA  Ahe's My Kind Of Girl  /a/abba/ahes+my+kind+of+girl_20598417.html   \n","1   ABBA       Andante, Andante       /a/abba/andante+andante_20002708.html   \n","2   ABBA         As Good As New        /a/abba/as+good+as+new_20003033.html   \n","3   ABBA                   Bang                  /a/abba/bang_20598415.html   \n","4   ABBA       Bang-A-Boomerang      /a/abba/bang+a+boomerang_20002668.html   \n","\n","                                                text  \n","0  Look at her face, it's a wonderful face  \\r\\nA...  \n","1  Take it easy with me, please  \\r\\nTouch me gen...  \n","2  I'll never know why I had to go  \\r\\nWhy I had...  \n","3  Making somebody happy is a question of give an...  \n","4  Making somebody happy is a question of give an...  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"-GwusDV6MNTF"},"outputs":[],"source":["if not os.path.exists('spotify_x_train.bin') or not os.path.exists('spotify_x_test.bin'):\n","    train_size = int(len(df) * 0.9)\n","    x_train = process_songs(df.iloc[:train_size])\n","    x_test = process_songs(df.iloc[train_size:])\n","    assert np.max(x_train) < 256\n","    print(len(x_train), len(x_test))\n","\n","    x_train = np.array(x_train, dtype=np.uint8)\n","    x_test = np.array(x_test, dtype=np.uint8)\n","\n","    x_train.tofile('spotify_x_train.bin')\n","    x_test.tofile('spotify_x_test.bin')"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"0NvMAiX1MNTF"},"outputs":[],"source":["# we will use mmap to reduce memory in this jupyter notebook\n","x_train = np.memmap('spotify_x_train.bin', dtype=np.uint8, mode='r')\n","x_test = np.memmap('spotify_x_test.bin', dtype=np.uint8, mode='r')"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"IyAnArKIMNTF","outputId":"e39ce7b9-8f05-4316-f3ec-ecf4e2149e17"},"outputs":[{"data":{"text/plain":["(61025756,)"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["x_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"DMFUsAlMMNTF","outputId":"817a63c7-11c1-4b24-e50c-229b29c8f48d"},"outputs":[{"data":{"text/plain":["(410, 4186)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["df.text.apply(len).min(), df.text.apply(len).max()"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"AF1XI_38MNTF","outputId":"09621a01-e156-40ac-c953-3cadb34c75d0"},"outputs":[{"data":{"text/plain":["643"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["len(df.artist.unique())"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"27vnNcvkMNTG"},"outputs":[],"source":["# this code is derived from nanogpt (https://github.com/karpathy/nanoGPT)\n","\n","class CausalSelfAttention(nn.Module):\n","    def __init__(self, transformers_size, n_heads, dropout,\n","                 max_seqlen, bias):\n","        super().__init__()\n","        assert transformers_size % n_heads == 0\n","        self.c_attn = nn.Linear(\n","                transformers_size, 3 * transformers_size, bias=bias)\n","        # output projection\n","        self.c_proj = nn.Linear(transformers_size,\n","                                transformers_size, bias=bias)\n","        # regularization\n","        self.attn_dropout = nn.Dropout(dropout)\n","        self.resid_dropout = nn.Dropout(dropout)\n","        self.n_heads = n_heads\n","        self.transformers_size = transformers_size\n","        self.dropout = dropout\n","\n","        self.register_buffer(\n","            \"bias\", torch.tril(torch.ones(max_seqlen, max_seqlen))\n","            .view(1, 1, max_seqlen, max_seqlen))\n","\n","    def forward(self, x):\n","        B, T, C = x.size()\n","\n","        # calculate query, key, values for all heads in batch\n","        # and move head forward to be the batch dim\n","        q, k, v  = self.c_attn(x).split(self.transformers_size, dim=2)\n","        # (B, nh, T, hs)\n","        k = k.view(B, T, self.n_heads, C // self.n_heads).transpose(1, 2)\n","        q = q.view(B, T, self.n_heads, C // self.n_heads).transpose(1, 2)\n","        v = v.view(B, T, self.n_heads, C // self.n_heads).transpose(1, 2)\n","\n","        # causal self-attention; Self-attend:\n","        #     (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n","        # manual implementation of attention\n","        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n","        att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n","        att = F.softmax(att, dim=-1)\n","        att = self.attn_dropout(att)\n","        y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n","        # re-assemble all head outputs side by side\n","        y = y.transpose(1, 2).contiguous().view(B, T, C)\n","\n","        # output projection\n","        y = self.resid_dropout(self.c_proj(y))\n","        return y\n","\n","class FeedForward(nn.Module):\n","    def __init__(self, transformers_size, dropout, bias=False):\n","        super().__init__()\n","        n = 4\n","        self.c_fc    = nn.Linear(\n","            transformers_size, n * transformers_size, bias=bias)\n","        self.c_proj  = nn.Linear(\n","            n * transformers_size, transformers_size, bias=bias)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        x = self.c_fc(x)\n","        x = nn.GELU(approximate='tanh')(x)\n","        x = self.c_proj(x)\n","        x = self.dropout(x)\n","        return x\n","\n","class Block(nn.Module):\n","    def __init__(\n","            self, transformers_size, num_heads, dropout,\n","            max_seqlen, bias=False):\n","        super().__init__()\n","        self.ln_1 = nn.LayerNorm(transformers_size)\n","        self.attn = CausalSelfAttention(\n","            transformers_size, num_heads, dropout, max_seqlen, bias=bias)\n","        self.ln_2 = nn.LayerNorm(transformers_size)\n","        self.mlp = FeedForward(transformers_size, dropout, bias)\n","\n","    def forward(self, x):\n","        x = x + self.attn(self.ln_1(x))\n","        x = x + self.mlp(self.ln_2(x))\n","        return x\n","\n","class LLM(nn.Module):\n","    def __init__(self, n_layers, num_heads, embedding_size, vocab_size, max_seqlen, dropout):\n","        super().__init__()\n","        self.max_seqlen = max_seqlen\n","        self.wte = nn.Embedding(vocab_size, embedding_size)\n","        self.wpe = nn.Embedding(max_seqlen, embedding_size)\n","        self.dropout = nn.Dropout(dropout)\n","        self.blocks = nn.ModuleList([\n","            Block(embedding_size, num_heads, dropout, max_seqlen, bias=True)\n","            for _ in range(n_layers)\n","        ])\n","        self.ln_f = nn.LayerNorm(embedding_size)\n","        self.lm_head = nn.Linear(\n","            embedding_size, vocab_size, bias=False)\n","\n","        # from GPT2 / nanoGPT\n","\n","        self.wte.weight = self.lm_head.weight\n","        self.apply(self._init_weights)\n","        for pn, p in self.named_parameters():\n","            if pn.endswith('c_proj.weight'):\n","                torch.nn.init.normal_(\n","                    p, mean=0.0, std=0.02/math.sqrt(2 * n_layers))\n","\n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n","            if module.bias is not None:\n","                torch.nn.init.zeros_(module.bias)\n","        elif isinstance(module, nn.Embedding):\n","            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n","\n","    def configure_optimizers(self, weight_decay, learning_rate, betas, device_type):\n","        \"\"\"\n","        This long function is unfortunately doing something very simple\n","        and is being very defensive:\n","        We are separating out all parameters of the model into two buckets:\n","        those that will experience weight decay for regularization and those\n","        that won't (biases, and layernorm/embedding weights).\n","        We are then returning the PyTorch optimizer object.\n","        \"\"\"\n","\n","        # separate out all parameters to those that will and won't\n","        # experience regularizing weight decay\n","        decay = set()\n","        no_decay = set()\n","        whitelist_weight_modules = (torch.nn.Linear, torch.nn.Conv1d)\n","        blacklist_weight_modules = (torch.nn.LayerNorm, torch.nn.Embedding)\n","        for mn, m in self.named_modules():\n","            for pn, p in m.named_parameters():\n","                fpn = '%s.%s' % (mn, pn) if mn else pn # full param name\n","                # random note: because named_modules and named_parameters\n","                # are recursive we will see the same tensors p many many\n","                # times. but doing it this way allows us to know which\n","                # parent module any tensor p belongs to...\n","                if pn.endswith('bias'):\n","                    # all biases will not be decayed\n","                    no_decay.add(fpn)\n","                elif (\n","                    pn.endswith('weight') and\n","                    isinstance(m, whitelist_weight_modules)):\n","                    # weights of whitelist modules will be weight decayed\n","                    decay.add(fpn)\n","                elif (\n","                    pn.endswith('weight') and\n","                    isinstance(m, blacklist_weight_modules)):\n","\n","                    # weights of blacklist modules will NOT be weight decayed\n","                    no_decay.add(fpn)\n","\n","        # subtle: 'transformer.wte.weight' and 'lm_head.weight' are tied,\n","        # so they will appear in the no_decay and decay sets respectively\n","        # after the above.\n","        # In addition, because named_parameters() doesn't return duplicates,\n","        # it will only return the first occurence, key'd by\n","        # 'transformer.wte.weight', below. so let's manually remove\n","        # 'lm_head.weight' from decay set. This will include\n","        # this tensor into optimization via transformer.wte.weight only,\n","        # and not decayed.\n","        decay.remove('lm_head.weight')\n","\n","        # validate that we considered every parameter\n","        param_dict = {pn: p for pn, p in self.named_parameters()}\n","        inter_params = decay & no_decay\n","        union_params = decay | no_decay\n","        assert len(inter_params) == 0, (\n","            f\"parameters {str(inter_params)} made into \" +\n","            \"both decay/no_decay sets!\")\n","        assert len(param_dict.keys() - union_params) == 0, (\n","            f\"parameters {str(param_dict.keys() - union_params)} were not \" +\n","            \"separated into either decay/no_decay set!\")\n","\n","        # create the pytorch optimizer object\n","        optim_groups = [\n","            {\"params\": [param_dict[pn] for pn in sorted(list(decay))],\n","             \"weight_decay\": weight_decay},\n","            {\"params\": [param_dict[pn] for pn in sorted(list(no_decay))],\n","             \"weight_decay\": 0.0},\n","        ]\n","        optimizer = torch.optim.AdamW(\n","            optim_groups, lr=learning_rate, betas=betas)\n","\n","        return optimizer\n","\n","    def forward(self, idx, targets=None, only_head=False):\n","        device = idx.device\n","        B, T = idx.shape\n","\n","        assert T <= self.max_seqlen\n","\n","        tok_emb = self.wte(idx) # (B, T, C)\n","\n","        B, T, C = tok_emb.shape\n","\n","        pos = torch.arange(\n","            0, T, dtype=torch.long, device=device).unsqueeze(0)\n","        pos_emb = self.wpe(pos)\n","        x = self.dropout(tok_emb + pos_emb)\n","        for block in self.blocks:\n","            x = block(x)\n","\n","        if only_head:\n","            return x\n","\n","        if targets is not None:\n","            logits = self.lm_head(x)\n","            B, T, C = logits.shape\n","            logits = logits.view(B*T, C)\n","            targets = targets.view(B*T)\n","            loss = F.cross_entropy(logits, targets)\n","        else:\n","            logits = self.lm_head(x[:, [-1], :])\n","            loss = None\n","\n","        return logits, loss"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"6LlxL2CjMNTG","outputId":"f56bce4f-3faf-4e03-aeaf-e74d421b7067"},"outputs":[{"data":{"text/plain":["102"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["max_seqlen = 1024\n","emb_size = 240\n","n_layers = 6\n","num_heads = 6\n","vocab_size = tokenizer.vocab_size\n","vocab_size"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"I-FYdrCvMNTG","outputId":"a6e8fb72-9182-458e-fa25-ba6d0b8fe701"},"outputs":[{"data":{"text/plain":["'4436K parameters (including embeddings)'"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["import math\n","device = 'cuda'\n","\n","model = LLM(n_layers=n_layers, num_heads=num_heads, embedding_size=emb_size,\n","            vocab_size=vocab_size, max_seqlen=max_seqlen,\n","            dropout=0.2)\n","\n","model = model.to(device)\n","\n","n_params = sum(p.numel() for n, p in model.named_parameters() if p.requires_grad)\n","f'{n_params // 1000}K parameters (including embeddings)'"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"TGEiC4DBMNTG"},"outputs":[],"source":["batch_size = 32\n","\n","loss_f = F.cross_entropy\n","\n","def get_batch(data):\n","    ix = torch.randint(len(data) - max_seqlen, (batch_size,))\n","    x = torch.stack([\n","        torch.from_numpy(data[i:i+max_seqlen].astype(np.int64)) for i in ix])\n","    y = torch.stack([\n","        torch.from_numpy(data[i+1:i+max_seqlen+1].astype(np.int64)) for i in ix])\n","    x, y = x.to(device), y.to(device)\n","    return x, y\n","\n","@torch.no_grad()\n","def estimate_loss(x_train, x_test, eval_iters=100):\n","    def _internal(model):\n","        dataset = {'train': x_train, 'val': x_test}\n","        out = {}\n","        model.eval()\n","        for split in ['train', 'val']:\n","            losses = torch.zeros(eval_iters)\n","            for k in range(eval_iters):\n","                X, Y = get_batch(dataset[split])\n","                p, loss = model(X, Y)\n","                losses[k] = loss.item()\n","            out[split] = losses.mean()\n","        model.train()\n","        return out\n","    return _internal\n"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"uc3_oiYkMNTH","outputId":"bc22c985-4645-42f1-fd53-08c99156ef1c"},"outputs":[{"data":{"text/plain":["(tensor([84, 80, 85, 75,  7, 84, 76,  7, 86, 77], device='cuda:0'),\n"," tensor([80, 85, 75,  7, 84, 76,  7, 86, 77,  7], device='cuda:0'))"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["x1, y1 = get_batch(x_train)\n","x1[0][:10], y1[0][:10]"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"3Q6nJVkFMNTH"},"outputs":[],"source":["import math\n","\n","def get_lr_func(warmup_iters, learning_rate, lr_decay_iters,  min_lr):\n","    def __get_lr__(it):\n","        nonlocal decay_ratio\n","        # 1) linear warmup for warmup_iters steps\n","        if it < warmup_iters:\n","            return learning_rate * it / warmup_iters\n","        # 2) if it > lr_decay_iters, return min learning rate\n","        if it > lr_decay_iters:\n","            return min_lr\n","        # 3) in between, use cosine decay down to min learning rate\n","        decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n","        assert 0 <= decay_ratio <= 1\n","        coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio)) # coeff ranges 0..1\n","        return min_lr + coeff * (learning_rate - min_lr)\n","\n","    decay_ratio = 0\n","    return __get_lr__\n","\n","learning_rate = 0.002\n","get_lr = get_lr_func(1000, learning_rate, 100000, learning_rate/10)"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"QaWuoWqIMNTH"},"outputs":[],"source":["iter_num = 0\n","logs = []"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"WZpyfpHKMNTH","outputId":"0198aa03-11e1-4cf3-c86a-40ecbde74469"},"outputs":[{"name":"stdout","output_type":"stream","text":["step 0: train loss 4.6200, val loss 4.6201\n","step 100: train loss 2.6529, val loss 2.6510\n","step 200: train loss 2.4043, val loss 2.4106\n","step 300: train loss 2.3772, val loss 2.3864\n","step 400: train loss 2.3744, val loss 2.3832\n","step 500: train loss 2.3586, val loss 2.3644\n","step 600: train loss 2.3430, val loss 2.3492\n","step 700: train loss 2.2407, val loss 2.2479\n","step 800: train loss 1.8395, val loss 1.8504\n","step 900: train loss 1.6825, val loss 1.6958\n","step 1000: train loss 1.5341, val loss 1.5571\n","step 1100: train loss 1.4353, val loss 1.4656\n","step 1200: train loss 1.3367, val loss 1.3732\n","step 1300: train loss 1.2721, val loss 1.3113\n","step 1400: train loss 1.2036, val loss 1.2295\n","step 1500: train loss 1.1566, val loss 1.1858\n","step 1600: train loss 1.1174, val loss 1.1465\n","step 1700: train loss 1.0894, val loss 1.1184\n","step 1800: train loss 1.0783, val loss 1.1088\n","step 1900: train loss 1.0500, val loss 1.0810\n","step 2000: train loss 1.0507, val loss 1.0809\n","step 2100: train loss 1.0372, val loss 1.0660\n","step 4800: train loss 0.9283, val loss 0.9662\n","step 4900: train loss 0.9198, val loss 0.9552\n","step 5000: train loss 0.9271, val loss 0.9533\n","step 5100: train loss 0.9355, val loss 0.9625\n","step 5200: train loss 0.9382, val loss 0.9631\n","step 5300: train loss 0.9230, val loss 0.9570\n","step 5400: train loss 0.9179, val loss 0.9402\n","step 5500: train loss 0.9249, val loss 0.9560\n","step 5600: train loss 0.9345, val loss 0.9556\n","step 5700: train loss 0.9090, val loss 0.9516\n","step 5800: train loss 0.9211, val loss 0.9571\n","step 5900: train loss 0.9151, val loss 0.9490\n","step 6000: train loss 0.9128, val loss 0.9558\n","step 6100: train loss 0.9142, val loss 0.9530\n","step 6200: train loss 0.9175, val loss 0.9478\n","step 6300: train loss 0.9172, val loss 0.9449\n","step 6400: train loss 0.9044, val loss 0.9375\n","step 6500: train loss 0.9061, val loss 0.9463\n","step 6600: train loss 0.8986, val loss 0.9383\n","step 6700: train loss 0.9100, val loss 0.9417\n","step 6800: train loss 0.9029, val loss 0.9423\n","step 6900: train loss 0.9091, val loss 0.9443\n"]}],"source":["epochs = 7000\n","\n","estimate_loss_f = estimate_loss(x_train, x_test, eval_iters=100)\n","\n","optimizer = model.configure_optimizers(\n","    weight_decay=1e-1, learning_rate=learning_rate, betas=(0.9, 0.95), device_type=device)\n","\n","for iter_num in range(iter_num, iter_num + epochs):\n","    learning_rate = get_lr(iter_num)\n","    for param_group in optimizer.param_groups:\n","        param_group['lr'] = learning_rate\n","\n","    if iter_num % 100 == 0:\n","        losses = estimate_loss_f(model)\n","        print(\n","            f'step {iter_num}: train loss {losses[\"train\"]:.4f}, '\n","            f'val loss {losses[\"val\"]:.4f}')\n","        logs.append((iter_num, losses['train'], losses['val']))\n","\n","    xb, yb = get_batch(x_train)\n","    pb, loss = model(xb, yb)\n","\n","    loss.backward()\n","    optimizer.step()\n","    optimizer.zero_grad()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"drkfzOLZMNTH"},"outputs":[],"source":["torch.save(model.state_dict(), 'model.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yvz8lYEeMNTH","outputId":"afe12fac-4e9c-46c8-c2cf-d75e2f7afb03"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["plt.plot([v[1] for v in logs][1:], label='train')\n","plt.plot([v[2] for v in logs][1:], label='val')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dBDbiEbfMNTI","outputId":"188c343b-4ccb-488c-f0eb-5c9d51050bc7"},"outputs":[{"data":{"text/plain":["memmap([ 0, 48, 14, 84,  7, 85, 86, 91,  7, 90, 91, 86, 85, 76, 75,  7,\n","        73, 92, 91,  7], dtype=uint8)"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["x_test[0:20]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YJlovN4DMNTI","outputId":"e855662f-71ae-410d-dc9a-be5bf2287406"},"outputs":[{"name":"stdout","output_type":"stream","text":["[START]I'm not stoned but \n"]}],"source":["print(''.join(tokenizer.decode(x_test[0:20])))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YDf8x5o6MNTI"},"outputs":[],"source":["@torch.no_grad()\n","def generate(idx, max_new_tokens, top_k=None):\n","    for _ in range(max_new_tokens):\n","        idx_cond = idx if idx.size(1) <= max_seqlen else idx[:, -max_seqlen:]\n","        logits, _ = model(idx_cond)\n","        logits = logits[:, -1, :]\n","        if top_k is not None:\n","            v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n","            logits[logits < v[:, [-1]]] = -float('Inf')\n","        probs = F.softmax(logits, dim=-1)\n","        idx_next = torch.multinomial(probs, num_samples=1)\n","        if idx_next == 0: break\n","        idx = torch.cat((idx, idx_next), dim=1)\n","    return idx"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MIjvFM6FMNTI","outputId":"1f07eb03-f8b3-4af4-bd07-7596262b3bb6"},"outputs":[{"data":{"text/plain":["array([[ 0, 48, 14, 84,  7, 85, 86, 91,  7, 90, 91, 86, 85, 76, 75,  7,\n","        73, 92, 91,  7, 48, 14, 84,  7, 85, 86, 91,  7, 91, 86,  7, 83,\n","        72, 91, 76,  7,  7,  3, 48,  7, 83, 86, 93, 76,  7, 80, 91,  7,\n","         7,  3, 41, 92, 91,  7, 48, 14, 83, 83,  7, 85, 76, 93, 76, 89,\n","         7, 96, 76, 84, 19,  7, 73, 72, 73, 96,  7,  7,  3,  7,  7,  3,\n","        48,  7, 94, 72, 85, 85, 72,  7, 90, 94, 86, 89, 83, 75,  7, 94,\n","        72, 85, 91,  7, 91, 86,  7, 91, 79, 76,  7, 91, 86,  7, 75, 72,\n","        85, 74, 76,  7,  7,  3, 53, 86, 91, 79, 80, 85, 14,  7, 91, 89,\n","        92, 76,  7, 96, 86, 92,  7, 82, 85, 76, 94,  7,  7,  3,  7,  7,\n","         3, 64, 86, 92, 19,  7, 48, 14, 84,  7, 85, 86, 91,  7, 74, 89,\n","        92, 87, 91, 80, 85, 14,  7, 84, 96,  7, 83, 80, 77, 76,  7,  7,\n","         3, 41, 92, 91,  7, 48, 14, 84,  7, 85, 86, 91,  7, 90, 91, 72,\n","        91, 91, 76, 89,  7,  7,  3, 59, 79, 72, 91,  7, 48,  7, 83, 86,\n","        93, 76,  7, 80, 91, 14, 90,  7, 78, 86, 80, 85, 14,  7, 72, 90,\n","         7, 91, 72, 82, 76, 89,  7,  7,  3,  7,  7,  3, 53, 86, 91,  7,\n","        90, 91, 72, 85, 75, 76, 75,  7, 73, 92, 91,  7, 48,  7, 94, 72,\n","        85, 91,  7, 91, 86,  7, 90, 91, 72, 96,  7,  7,  3, 41, 92, 91,\n","         7, 96, 86, 92,  7, 85, 76, 76, 75,  7, 72, 90,  7, 48,  7, 83,\n","        80, 93, 76,  7,  7,  3, 64, 86, 92, 89,  7, 90, 79, 86, 94,  7,\n","        84, 76,  7, 91, 86,  7, 82, 85, 86, 94,  7,  7,  3,  7,  7,  3,\n","        48,  7, 82, 85, 86, 94,  7, 73, 72, 73, 96,  7, 91, 86,  7, 78,\n","        86, 91, 91, 72,  7, 90, 91, 72, 82, 76,  7,  7,  3,  7,  7,  3,\n","        48, 85, 90, 72, 85, 91, 72, 85, 76,  7,  7,  3, 14, 74, 79, 92,\n","        84, 87, 76, 89,  7, 94, 76, 76, 82,  7, 86, 85,  7, 91, 79, 76,\n","         7, 83, 80, 85, 76,  7,  7,  3, 54, 85, 76,  7, 91, 86,  7, 78,\n","        86, 19,  7,  7,  3, 59, 79, 76,  7, 83, 86, 93, 76,  7, 80, 91,\n","        14, 90,  7, 94, 72, 85, 91, 80, 85, 14,  7,  7,  3, 48,  7, 83,\n","        86, 93, 76,  7, 80, 91,  7, 80, 91,  7, 80, 90,  7, 91, 76, 76,\n","        75,  7, 96, 86, 92, 89,  7, 90, 79, 86, 94, 75,  7, 86, 85,  7,\n","         7,  3, 14, 74, 72, 92, 87, 80, 77, 72, 83, 83, 90,  7,  7,  3,\n","        59, 86,  7, 91, 79, 80, 85, 78,  7, 48, 14, 93, 76,  7, 73, 76,\n","        76, 85,  7, 73, 92, 91,  7, 91, 86,  7, 78, 86, 91,  7, 91, 86,\n","         7, 73, 76, 38,  7,  7,  3, 48, 91, 14, 90,  7, 78, 86, 85, 14,\n","         7, 91, 86,  7, 75, 72, 85, 82,  7, 86, 85,  7, 91, 79, 89, 80,\n","        85, 78,  7,  7,  3, 59, 86,  7, 91, 76, 76, 91,  7, 96, 86, 92,\n","        89,  7, 90, 79, 86, 94, 83, 76, 91,  7, 96, 86, 92,  7, 94, 86,\n","        85, 75, 76, 89, 77, 92, 74, 82, 80, 85, 78, 38,  7,  7,  3, 48,\n","         7, 82, 85, 86, 91,  7, 91, 86,  7, 73, 76,  7, 80, 91, 14, 90,\n","         7, 89, 80, 78, 79, 91,  7,  7,  3,  7,  7,  3, 48,  7, 94, 80,\n","        83, 83,  7, 79, 72, 93, 76,  7, 72,  7, 77, 92, 78, 76, 90,  7,\n","        77, 86, 89,  7, 91, 79, 76,  7, 91, 76, 89, 89, 86, 89,  7, 94,\n","        72, 80, 85, 90,  7,  7,  3, 48, 91, 14, 90,  7, 78, 86, 91, 91,\n","        72,  7, 90, 91, 72, 85, 75, 76, 89,  7, 94, 72, 80, 91, 80, 85,\n","        78, 38,  7,  7,  3, 48,  7, 94, 72, 85, 91, 76, 75,  7, 96, 86,\n","        92,  7, 72, 83, 83,  7, 75, 86, 92, 73, 86, 92, 91,  7,  7,  3,\n","         7,  7,  3, 58, 86, 84, 76, 91, 79, 80, 85, 78, 14, 90,  7, 90,\n","        79, 86,  7, 94, 76, 85, 91,  7, 72, 85, 75,  7, 91, 86, 85,  7,\n","         7,  3, 47, 76,  7, 91, 72, 83, 82,  7, 72, 85, 75,  7, 91, 79,\n","        76,  7, 85, 80, 78, 79, 91,  7,  7,  3, 40, 79, 76, 86, 94,  7,\n","         7,  3, 58, 79, 76,  7, 94, 86, 85, 14, 91,  7, 94, 72, 80, 91,\n","         7, 72,  7, 90, 91, 72, 89, 90,  7,  7,  3, 48,  7, 94, 72, 85,\n","        91,  7, 72, 85, 75,  7, 91, 79, 80, 85, 78,  7,  7,  3, 54, 79,\n","        19,  7, 72, 79, 79, 79, 85, 85, 80, 78, 79, 91, 14, 90,  7, 91,\n","        79, 80, 85, 78,  7,  7,  3,  7,  7,  3, 48, 77,  7, 48,  7, 90,\n","        79, 76, 72, 89,  7, 96, 86, 92,  7, 72, 83, 83,  7, 84, 76, 83,\n","        86, 75, 96,  7,  7,  3, 59, 79, 72, 91,  7, 48,  7, 90, 79, 86,\n","        92, 83, 75,  7, 90, 72, 96,  7, 91, 79, 76,  7, 90, 91, 86, 87,\n","         7, 86, 89,  7, 72, 83, 83,  7, 73, 76,  7, 72, 85, 75,  7, 91,\n","        79, 80, 85, 78, 90,  7,  7,  3, 40, 85, 75,  7, 91, 79, 76,  7,\n","        85, 80, 78, 79, 91,  7,  7,  3, 48,  7, 94, 72, 85, 91, 76, 75,\n","         3,  3]])"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["idx = torch.from_numpy(np.array([x_test[0:20]]).astype(np.int64))\n","result = generate(idx.to(device), max_new_tokens=1024, top_k=10).detach().cpu().numpy()\n","result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nca8JJN4MNTI","outputId":"b087a81c-5890-4620-cbed-7cdf1b261358"},"outputs":[{"name":"stdout","output_type":"stream","text":["[START]I'm not stoned but I'm not to late  \n","I love it  \n","But I'll never yem, baby  \n","  \n","I wanna sworld want to the to dance  \n","Nothin' true you knew  \n","  \n","You, I'm not cruptin' my life  \n","But I'm not statter  \n","That I love it's goin' as taker  \n","  \n","Not standed but I want to stay  \n","But you need as I live  \n","Your show me to know  \n","  \n","I know baby to gotta stake  \n","  \n","Insantane  \n","'chumper week on the line  \n","One to go,  \n","The love it's wantin'  \n","I love it it is teed your showd on  \n","'caupifalls  \n","To thing I've been but to got to be?  \n","It's gon' to dank on thring  \n","To teet your showlet you wonderfucking?  \n","I knot to be it's right  \n","  \n","I will have a fuges for the terror wains  \n","It's gotta stander waiting?  \n","I wanted you all doubout  \n","  \n","Something's sho went and ton  \n","He talk and the night  \n","Aheow  \n","She won't wait a stars  \n","I want and thing  \n","Oh, ahhhnnight's thing  \n","  \n","If I shear you all melody  \n","That I should say the stop or all be and things  \n","And the night  \n","I wanted\n","\n","\n"]}],"source":["decoded_sequence = ''.join(tokenizer.decode(result[0]))\n","print(decoded_sequence)"]},{"cell_type":"markdown","metadata":{"id":"fJ4MOgttMNTI"},"source":["## Predicting Artist"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"ZOArKst6MNTI","outputId":"92251df2-5c00-4db3-d846-7eea6b0deba3"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>artist</th>\n","      <th>song</th>\n","      <th>link</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ABBA</td>\n","      <td>Ahe's My Kind Of Girl</td>\n","      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n","      <td>Look at her face, it's a wonderful face  \\r\\nA...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ABBA</td>\n","      <td>Andante, Andante</td>\n","      <td>/a/abba/andante+andante_20002708.html</td>\n","      <td>Take it easy with me, please  \\r\\nTouch me gen...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ABBA</td>\n","      <td>As Good As New</td>\n","      <td>/a/abba/as+good+as+new_20003033.html</td>\n","      <td>I'll never know why I had to go  \\r\\nWhy I had...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ABBA</td>\n","      <td>Bang</td>\n","      <td>/a/abba/bang_20598415.html</td>\n","      <td>Making somebody happy is a question of give an...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ABBA</td>\n","      <td>Bang-A-Boomerang</td>\n","      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n","      <td>Making somebody happy is a question of give an...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  artist                   song                                        link  \\\n","0   ABBA  Ahe's My Kind Of Girl  /a/abba/ahes+my+kind+of+girl_20598417.html   \n","1   ABBA       Andante, Andante       /a/abba/andante+andante_20002708.html   \n","2   ABBA         As Good As New        /a/abba/as+good+as+new_20003033.html   \n","3   ABBA                   Bang                  /a/abba/bang_20598415.html   \n","4   ABBA       Bang-A-Boomerang      /a/abba/bang+a+boomerang_20002668.html   \n","\n","                                                text  \n","0  Look at her face, it's a wonderful face  \\r\\nA...  \n","1  Take it easy with me, please  \\r\\nTouch me gen...  \n","2  I'll never know why I had to go  \\r\\nWhy I had...  \n","3  Making somebody happy is a question of give an...  \n","4  Making somebody happy is a question of give an...  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","df = pd.read_csv('spotify_millsongdata.csv')\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"bh_P2AESMNTI","outputId":"fe31f74b-64cd-4191-f84e-550663d724f5"},"outputs":[{"data":{"text/plain":["tensor([522, 522, 522, 591, 591, 591, 591, 591, 591, 591, 591, 591, 591, 591,\n","        591, 591, 591, 591, 591, 591, 591, 591, 591, 591, 591, 591, 591, 591,\n","        591, 591, 591, 591, 591, 591, 591, 591, 591, 591, 393, 393, 393, 393,\n","        393, 393, 393, 393, 393, 393, 393, 393, 393, 393, 393, 393, 393, 393,\n","        393, 393, 393, 393, 393, 393, 393, 393, 393, 393, 393, 393, 393, 393,\n","        393, 393, 393, 393, 393, 393, 393, 393, 393, 393, 393, 393, 393, 393,\n","        125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125,\n","        125, 125], dtype=torch.int32)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["ys = list(set(df.artist))\n","num_labels = len(ys)\n","y_train = torch.empty(len(df.artist), dtype=torch.int)\n","\n","for i, artist in enumerate(df.artist):\n","    y_train[i] = ys.index(artist)\n","\n","y_train[30000:30100]"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"zaiATCsIMNTJ","outputId":"242f0c49-8714-4e63-98cb-79288c01e91c"},"outputs":[{"name":"stdout","output_type":"stream","text":["0    [51, 86, 86, 82, 7, 72, 91, 7, 79, 76, 89, 7, ...\n","1    [59, 72, 82, 76, 7, 80, 91, 7, 76, 72, 90, 96,...\n","2    [48, 14, 83, 83, 7, 85, 76, 93, 76, 89, 7, 82,...\n","3    [52, 72, 82, 80, 85, 78, 7, 90, 86, 84, 76, 73...\n","4    [52, 72, 82, 80, 85, 78, 7, 90, 86, 84, 76, 73...\n","5    [62, 76, 83, 83, 19, 7, 96, 86, 92, 7, 79, 86,...\n","6    [43, 86, 94, 85, 7, 80, 85, 7, 91, 79, 76, 7, ...\n","7    [42, 79, 80, 88, 92, 80, 91, 80, 91, 72, 19, 7...\n","8    [48, 7, 94, 72, 90, 7, 86, 92, 91, 7, 94, 80, ...\n","9    [48, 14, 84, 7, 94, 72, 80, 91, 80, 85, 14, 7,...\n","Name: text, dtype: object\n"]}],"source":["x_train = df.text\n","for index, song in enumerate(x_train):\n","    x_train[index] = tokenizer.encode(song)\n","\n","print(x_train[:10])\n","x_train = x_train.to_numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"e11yVOVGMNTJ","outputId":"c501865c-6ee2-49ca-f476-131054d95866"},"outputs":[{"name":"stdout","output_type":"stream","text":["4186\n","410\n"]}],"source":["lens = [len(song) for song in x_train]\n","print(max(lens))\n","print(min(lens))"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"rPln3zmqMNTJ"},"outputs":[],"source":["maxlen = 1024\n","x_train_pad = torch.empty((len(x_train),maxlen), dtype=torch.int)\n","for i,x in enumerate(x_train):\n","    if len(x) < maxlen:\n","        x_train_pad[i] = torch.tensor(x_train[i] + ([0]*(maxlen-len(x))))\n","    elif len(x) > maxlen:\n","        x_train_pad[i] = torch.tensor(x_train[i][:maxlen])\n","    else:\n","        continue"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"cYbqyNg_MNTJ","outputId":"9c51a2d4-c0fa-494e-d403-4bcd645c9f26"},"outputs":[{"name":"stdout","output_type":"stream","text":["1024\n","1024\n"]}],"source":["lens = [len(song) for song in x_train_pad]\n","print(max(lens))\n","print(min(lens))"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"gQDqQTagMNTJ"},"outputs":[],"source":["class ArtistPredictor(nn.Module):\n","    def __init__(self, embedding_size, output_size):\n","        super().__init__()\n","        self.conv_0 = nn.Conv2d(in_channels = 1,\n","            out_channels = 16,\n","            kernel_size = (3, embedding_size))\n","        self.linear1 = nn.Linear(16*1022, 1000)\n","        self.linear2 = nn.Linear(1000, output_size)\n","\n","    def forward(self, x):\n","        out = x.unsqueeze(1)\n","        out = F.relu(self.conv_0(out).squeeze(3))\n","        out = out.flatten(start_dim=1)\n","        out = F.relu(self.linear1(out))\n","        out = nn.Sigmoid()(self.linear2(out))\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"VgrkQc4KMNTJ","outputId":"658955e8-19d7-4d2c-b855-7ee167acea80"},"outputs":[{"name":"stdout","output_type":"stream","text":["46120 11530 46120 11530\n"]}],"source":["indices = torch.randint(len(x_train_pad), (len(x_train_pad),))\n","\n","x_test = x_train_pad[indices[round(0.8*len(indices)):]]\n","x_train = x_train_pad[indices[:round(0.8*len(indices))]]\n","y_test = y_train[indices[round(0.8*len(indices)):]]\n","y_train = y_train[indices[:round(0.8*len(indices))]]\n","\n","print(len(x_train),len(x_test),len(y_train),len(y_test))"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"QiP3FH35MNTJ","outputId":"effd3b3b-368a-4ad6-8a72-e129b8b0f502"},"outputs":[{"data":{"text/plain":["102"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["max_seqlen = 1024\n","emb_size = 240\n","n_layers = 6\n","num_heads = 6\n","vocab_size = tokenizer.vocab_size\n","vocab_size"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"IohAhuZ9MNTK","outputId":"963c115f-e954-4ff8-8aae-ac44934c428c"},"outputs":[{"data":{"text/plain":["'4436K parameters (including embeddings)'"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["import math\n","\n","device = 'cuda'\n","head = LLM(n_layers=n_layers, num_heads=num_heads, embedding_size=emb_size,\n","            vocab_size=vocab_size, max_seqlen=max_seqlen,\n","            dropout=0.2)\n","\n","head.load_state_dict(torch.load('model.pth'))\n","head = head.to(device)\n","head.eval()\n","\n","n_params = sum(p.numel() for n, p in head.named_parameters() if p.requires_grad)\n","f'{n_params // 1000}K parameters (including embeddings)'"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"_ogsr-eqMNTK","outputId":"3518ca5d-8eff-4c77-ca30-3e6f431ff267"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 46120/46120 [11:54<00:00, 64.51it/s]\n","100%|██████████| 11530/11530 [00:59<00:00, 193.08it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 0, Train Loss: 6.486659779573459, Val Loss: 6.4876679025105775\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 46120/46120 [11:51<00:00, 64.85it/s]\n","100%|██████████| 11530/11530 [00:59<00:00, 192.84it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, Train Loss: 6.489256247735913, Val Loss: 6.495725933614236\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 46120/46120 [11:51<00:00, 64.87it/s]\n","100%|██████████| 11530/11530 [00:59<00:00, 192.94it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, Train Loss: 6.495248917135485, Val Loss: 6.495725933614236\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 46120/46120 [11:51<00:00, 64.86it/s]\n","100%|██████████| 11530/11530 [00:59<00:00, 192.84it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, Train Loss: 6.495248917135485, Val Loss: 6.495725933614236\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 46120/46120 [11:51<00:00, 64.86it/s]\n","100%|██████████| 11530/11530 [00:59<00:00, 192.84it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4, Train Loss: 6.495248917135485, Val Loss: 6.495725933614236\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 46120/46120 [11:50<00:00, 64.87it/s]\n","100%|██████████| 11530/11530 [00:59<00:00, 192.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5, Train Loss: 6.495248917135485, Val Loss: 6.495725933614236\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 46120/46120 [11:51<00:00, 64.84it/s]\n","100%|██████████| 11530/11530 [00:59<00:00, 192.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 6, Train Loss: 6.495248917135485, Val Loss: 6.495725933614236\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 46120/46120 [11:51<00:00, 64.85it/s]\n","100%|██████████| 11530/11530 [00:59<00:00, 192.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 7, Train Loss: 6.495248917135485, Val Loss: 6.495725933614236\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 46120/46120 [11:50<00:00, 64.87it/s]\n","100%|██████████| 11530/11530 [00:59<00:00, 192.93it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 8, Train Loss: 6.495248917135485, Val Loss: 6.495725933614236\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 46120/46120 [11:51<00:00, 64.87it/s]\n","100%|██████████| 11530/11530 [00:59<00:00, 192.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 9, Train Loss: 6.495248917135485, Val Loss: 6.495725933614236\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 46120/46120 [11:51<00:00, 64.85it/s]\n","100%|██████████| 11530/11530 [00:59<00:00, 192.81it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10, Train Loss: 6.495248917135485, Val Loss: 6.495725933614236\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 46120/46120 [11:51<00:00, 64.86it/s]\n","100%|██████████| 11530/11530 [00:59<00:00, 192.73it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 11, Train Loss: 6.495248917135485, Val Loss: 6.495725933614236\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["from tqdm import tqdm\n","#batch_size = 32\n","\n","artist_model = ArtistPredictor(emb_size, num_labels)\n","artist_model = artist_model.to(device)\n","\n","artist_optimizer = torch.optim.Adam(artist_model.parameters(), lr=0.001)\n","artist_loss_f = nn.CrossEntropyLoss()\n","\n","for epoch in range(12):\n","    artist_model.train()\n","    train_loss = 0\n","    for i in tqdm(range(len(x_train))):\n","        xb = x_train[i].to(device)\n","        yb = y_train[i].to(device)\n","        yb = yb.long()\n","        xb = xb.reshape(1,len(xb))\n","        out = head(xb, only_head=True)\n","        out = artist_model(out)\n","        loss = artist_loss_f(out[0], yb)\n","        train_loss += loss.item()\n","        loss.backward()\n","        artist_optimizer.step()\n","        artist_optimizer.zero_grad()\n","\n","    artist_model.eval()\n","    val_loss = 0\n","    with torch.no_grad():\n","        for i in tqdm(range(len(x_test))):\n","            xb = x_test[i].to(device)\n","            yb = y_test[i].to(device)\n","            yb = yb.long()\n","            xb = xb.reshape(1,len(xb))\n","            out = artist_model(head(xb, only_head=True))\n","            loss = artist_loss_f(out[0], yb)\n","            val_loss += loss.item()\n","    print(f\"Epoch {epoch}, Train Loss: {train_loss/len(x_train)}, Val Loss: {val_loss/len(x_test)}\")\n"]},{"cell_type":"markdown","source":[],"metadata":{"id":"XGScSSgnMmoT"}},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"_IXC4vpsMNTK","outputId":"8b82e2f3-1ec4-4b0c-81e4-91eb2e1955f9"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 11530/11530 [01:00<00:00, 189.32it/s]"]},{"name":"stdout","output_type":"stream","text":["Test Accuracy =  0.0016\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["num_correct = 0\n","for i in tqdm(range(len(x_test))):\n","    xb = x_test[i].to(device)\n","    yb = y_test[i].to(device)\n","    yb = yb.long()\n","    xb = xb.reshape(1,len(xb))\n","    out = artist_model(head(xb, only_head=True))\n","    num_correct += 1 if pred == yb else 0\n","print(f\"Test Accuracy ={100*num_correct / len(x_test): .4f}%\")"]}],"metadata":{"kernelspec":{"display_name":"ELEN-523-Env","language":"python","name":"elen-523-env"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}