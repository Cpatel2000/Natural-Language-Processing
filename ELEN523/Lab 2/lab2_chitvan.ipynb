{"cells":[{"cell_type":"markdown","metadata":{"id":"fb774609"},"source":["# 1. Summarize the paper on BPE"],"id":"fb774609"},{"cell_type":"markdown","metadata":{"id":"gWC_y-VKV8dx"},"source":["The paper explores the concept of encoding rare and unknown words as sequences of subword units. The idea is grounded in the understanding that certain word categories can be translated more effectively through smaller units, such as names, compounds, and loanwords. The authors adapt a data compression method called Byte Pair Encoding (BPE) for word segmentation, which replaces the most common pair of bytes in a sequence with a single, unused byte. Unlike other compression methods, BPE symbol sequences are still interpretable as subword units, and it allows the system to create and translate new words based on these subword units. The authors use an Attention Decoder/RNNSearch as the network for Neural Machine Translation (NMT) using different vocabularies, and it was found that the BPE approach produced competitive results. The main argument is that traditional word-level NMT models struggle with the translation of rare and unknown words, and subword models can enhance the translation of these words.\n","\n","\n","\n","\n"],"id":"gWC_y-VKV8dx"},{"cell_type":"markdown","metadata":{"id":"c6573876"},"source":["# 2. In regular expressions, what does \\d, \\D, \\w, \\W, \\s, \\S, {n}, {n,m}, {n,}, {,m} mean?"],"id":"c6573876"},{"cell_type":"markdown","metadata":{"id":"yrXlTAOHUuUy"},"source":["\n","\n","*   \\d: Matches any digit (0-9).\n","*   \\D: Matches any non-digit character.\n","\n","\n","*  \\w: Matches any alphanumeric character (a-z, A-Z, 0-9, and underscore _).\n","\n","*   \\W: Matches any non-alphanumeric character.\n","\n","*   \\s: Matches any whitespace character (space, tab, newline, etc.).\n","\n","*   \\S: Matches any non-whitespace character.\n","\n","*   {n}: Matches exactly n occurrences of the preceding character or group.\n","*   {n,m}: Matches at least n and at most m occurrences of the preceding character or group.\n","\n","\n","*   {n,}: Matches at least n occurrences of the preceding character or group.\n","\n","\n","*  {,m}: Matches at most m occurrences of the preceding character or group.\n","\n","\n","\n","\n","\n","\n","\n"],"id":"yrXlTAOHUuUy"},{"cell_type":"markdown","metadata":{"id":"88c32fd1"},"source":["# 3. Create a Python based tokenizer in NLTK that replaces contractions (I’m, You’re, didn’t) into the expanded forms (I am, You are, did not)."],"id":"88c32fd1"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1683580573071,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"},"user_tz":420},"id":"pPrUzgrZN8qk","outputId":"aef09c93-2358-4e1c-8214-c34b47ee6a9e"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["import nltk\n","from nltk.tokenize import word_tokenize\n","nltk.download('punkt')\n","\n","# Create a mapping of contractions and their expansions\n","contractions = {\n","    \"I'm\": \"I am\",\n","    \"you're\": \"you are\",\n","    \"didn't\": \"did not\",\n","    # Add more contractions and their expansions as needed\n","}\n","\n","# Create a tokenizer function that replaces contractions\n","def tokenizer(text):\n","    # Tokenize the text into words\n","    words = word_tokenize(text)\n","\n","    # Iterate over the words and replace contractions\n","    expanded_words = []\n","    for word in words:\n","        if word in contractions:\n","            expanded_words.extend(contractions[word].split())\n","        else:\n","            expanded_words.append(word)\n","\n","    return expanded_words\n","\n"],"id":"pPrUzgrZN8qk"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":159,"status":"ok","timestamp":1683580577094,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"},"user_tz":420},"id":"Z6kXYzjyONqx","outputId":"ab0a9668-eb57-4e0d-afae-e398f6cce851"},"outputs":[{"name":"stdout","output_type":"stream","text":["['I', \"'m\", 'glad', 'you', \"'re\", 'here', '.', 'I', 'did', \"n't\", 'know', 'that', '.']\n"]}],"source":["# Example usage\n","text = \"I'm glad you're here. I didn't know that.\"\n","expanded_text = tokenizer(text)\n","print(expanded_text)\n"],"id":"Z6kXYzjyONqx"},{"cell_type":"markdown","metadata":{"id":"7d375363"},"source":["# 4. Implement the BPE algorithm with the following interface\n","\n","Your normalization should expand the contractions you implemented in problem 3."],"id":"7d375363"},{"cell_type":"code","execution_count":null,"metadata":{"id":"37b78c0a"},"outputs":[],"source":["class Tokenizer:\n","    def __init__(self, vocab_size):\n","        pass\n","    \n","    def normalize(self, text):\n","        pass\n","    \n","    def train(self, corpus):\n","        pass\n","    \n","    def encode(self, text):\n","        pass\n","    \n","    def decode(self, text):\n","        pass"],"id":"37b78c0a"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":166,"status":"ok","timestamp":1684222956802,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"},"user_tz":420},"id":"lWbusKu6gKPb","outputId":"4bd91638-219c-4531-fa68-5df73f58540f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Vocabulary Size: 18\n","Original Text: you're awesome, I did'nt know that\n","Encoded Text: [2, 3, 1, 3, 1, 3, 3, 2, 3, 1, 3, 2, 3, 1, 2, 1, 2, 3, 2, 3, 1, 2, 3, 2, 3, 2, 3, 3]\n","Decoded Text: m h ' h ' h h m h ' h m h ' m ' m h m h ' m h m h m h h\n"]},{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["import nltk\n","from nltk.tokenize import word_tokenize\n","from collections import defaultdict\n","from itertools import groupby\n","\n","nltk.download('punkt')\n","\n","\n","class Tokenizer:\n","    def __init__(self, vocab_size):\n","        self.vocab_size = vocab_size\n","        self.vocab = {}\n","        self.inv_vocab = {}\n","\n","    def normalize(self, text):\n","        # Replace contractions\n","        words = word_tokenize(text)\n","        expanded_words = []\n","        for word in words:\n","            if word in contractions:\n","                expanded_words.extend(contractions[word].split())\n","            else:\n","                expanded_words.append(word)\n","        return expanded_words\n","\n","    def train(self, corpus):\n","        # Tokenize the corpus and initialize character counts\n","        tokenized_corpus = [self.normalize(text) for text in corpus]\n","        char_counts = defaultdict(int)\n","\n","        # Count character occurrences\n","        for text in tokenized_corpus:\n","            for word in text:\n","                for char in word:\n","                    char_counts[char] += 1\n","\n","        # Initialize the vocabulary with single characters\n","        self.vocab = {char: count for char, count in char_counts.items()}\n","        self.inv_vocab = {i: char for i, char in enumerate(self.vocab.keys())}\n","\n","        # Build the vocabulary using the BPE algorithm\n","        for _ in range(self.vocab_size - len(self.vocab)):\n","            # Find the most frequent pair of consecutive characters\n","            pair = max(char_counts.items(), key=lambda x: x[1])\n","            pair_chars = pair[0]\n","\n","            # Create a new merged character and update the vocabulary\n","            new_char = pair_chars[0] + pair_chars[1]\n","            self.vocab[new_char] = pair[1]\n","            self.inv_vocab[len(self.vocab) - 1] = new_char\n","\n","            # Update the character counts\n","            char_counts.pop(pair_chars)\n","            for text in tokenized_corpus:\n","                new_text = []\n","                for word in text:\n","                    new_word = ''.join([c if c != pair_chars else new_char for c in word])\n","                    new_text.append(new_word)\n","                tokenized_corpus[tokenized_corpus.index(text)] = new_text\n","\n","                char_counts[new_char] = 0\n","                for word in new_text:\n","                    for char in word:\n","                        char_counts[new_char] += 1\n","\n","        print(\"Vocabulary Size:\", len(self.vocab))\n","\n","    def encode(self, text):\n","        tokenized_text = self.normalize(text)\n","        encoded_text = []\n","        for word in tokenized_text:\n","            encoded_word = [self.vocab[char] for char in word if char in self.vocab]\n","            encoded_text.extend(encoded_word)\n","        return encoded_text\n","\n","    def decode(self, text):\n","        decoded_text = [self.inv_vocab[token] for token in text if token in self.inv_vocab]\n","        return decoded_text\n","\n","\n","# Create a mapping of contractions and their expansions\n","contractions = {\n","    \"I'm\": \"I am\",\n","    \"you're\": \"you are\",\n","    \"didn't\": \"did not\",\n","    # Add more contractions and their expansions as needed\n","}\n","\n","# Example usage\n","corpus = [\n","    \"I'm happy\",\n","    \"you're awesome\",\n","    \"didn't know that\"\n","]\n","\n","tokenizer = Tokenizer(vocab_size=10)\n","tokenizer.train(corpus)\n","\n","text = \"you're awesome, I did'nt know that\"\n","encoded_text = tokenizer.encode(text)\n","decoded_text = tokenizer.decode(encoded_text)\n","\n","print(\"Original Text:\", text)\n","print(\"Encoded Text:\", encoded_text)\n","print(\"Decoded Text:\", ' '.join(decoded_text))\n"],"id":"lWbusKu6gKPb"},{"cell_type":"markdown","metadata":{"id":"d458104e"},"source":["# 5. Using the package https://www.nltk.org/api/nltk.chat.html#module-nltk.chat, you will create a regular expression based chatbot that answers the following questions.  \n","\n","    a. What’s the temperature today? (check for the temperature at weather channel)\n","    b. What’s my zip code? (based on the person’s location)\n","    c. How much is $19.99 in <currency>? (You can search Google for “exchange rate between us and <currency>”)\n","    d. What’s the definition of <word>? (you will need to look for the definition at Wikipedia or dictionary)\n","    \n","The chatbot structure from NLTK uses static string responses, you have to modify it (as in the example below) to allow for functional objects that can parse the web, for example.\n","\n","Note that you will need to process HTML to create the answers, and you will use Beautiful Soup to do that. \n","\n","https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.html?highlight=select"],"id":"d458104e"},{"cell_type":"code","source":["pip install geocoder"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FqTbk1wv27Qp","executionInfo":{"status":"ok","timestamp":1686258835092,"user_tz":420,"elapsed":5554,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}},"outputId":"ce6f8ddb-2064-4e82-ce91-e27a24cdc2ed"},"id":"FqTbk1wv27Qp","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting geocoder\n","  Downloading geocoder-1.38.1-py2.py3-none-any.whl (98 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from geocoder) (8.1.3)\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from geocoder) (0.18.3)\n","Collecting ratelim (from geocoder)\n","  Downloading ratelim-0.1.6-py2.py3-none-any.whl (4.0 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from geocoder) (2.27.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from geocoder) (1.16.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ratelim->geocoder) (4.4.2)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->geocoder) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->geocoder) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->geocoder) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->geocoder) (3.4)\n","Installing collected packages: ratelim, geocoder\n","Successfully installed geocoder-1.38.1 ratelim-0.1.6\n"]}]},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yVVOIo1a3ZpY","executionInfo":{"status":"ok","timestamp":1686258954330,"user_tz":420,"elapsed":360,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}},"outputId":"01a92ee2-7382-447f-ce22-151c2a09d636"},"id":"yVVOIo1a3ZpY","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["from nltk.chat.util import Chat, reflections\n","import random\n","import requests\n","from bs4 import BeautifulSoup\n","import geocoder\n","from nltk.tokenize import word_tokenize\n","import re\n","\n","def get_temp(prompt):\n","    location_url = \"https://weather.com/weather/today/l/4fb2eb4b20edcb606887ba1528d1e7f0ca27f832876ed59016bbbf08547ad493\"\n","    response = requests.get(location_url)\n","    soup = BeautifulSoup(response.content, 'html.parser')\n","    temperature = soup.find('span', {'class': 'CurrentConditions--tempValue--MHmYY'}).get_text()\n","    return f\"The current temperature in Santa Clara is {temperature}\"\n","\n","def get_zip_code(prompt):\n","    g = geocoder.ip('me')\n","    zipcode = g.postal\n","\n","    return f\"The current ZIP code is {zipcode}.\"\n","\n","def google_search_url(query):\n","    query = query.replace(' ', '+')\n","    url = f\"https://www.google.com/search?q={query}\"\n","    return url\n","\n","def currency_convert(prompt):\n","    prompt_url = google_search_url(prompt)\n","    response = requests.get(prompt_url)\n","    soup = BeautifulSoup(response.content, 'html.parser')\n","    amount = soup.find('div', {'class': 'BNeawe iBp4i AP7Wnd'}).find('div', {'class': 'BNeawe iBp4i AP7Wnd'}).get_text()\n","    return f\"The correct amount is {amount}\"\n","\n","def get_word(prompt):\n","    tokens = word_tokenize(prompt)\n","    index = -1\n","    while re.match(r\"[\\.\\?\\!);:]|mean(ing)?\",tokens[index]):\n","        index -= 1\n","    return tokens[index]\n","\n","def get_definition(prompt):\n","    word = get_word(prompt)\n","    api_key = \"3ac25ed7-e378-4c27-aaa4-1128d7d12335\"\n","    url = f\"https://dictionaryapi.com/api/v3/references/collegiate/json/{word}?key={api_key}\"\n","    response = requests.get(url)\n","    if response.status_code == 200:\n","        definitions = response.json()[0].get(\"shortdef\")\n","        print(f\"The definition(s) of {word} is/are: \")\n","        for i, definition in enumerate(definitions):\n","            print(f\"{i+1}. {definition}\")\n","        return \"I hope this answers your question.\"\n","    else:\n","        return \"Sorry, the word could not be found in the dictionary.\"\n","\n","responses = (\n","    (\n","        r\"(hello(.*))|(good [a-zA-Z]+)|((.*)[Tt]emperature(.*))\",\n","        (\n","            get_temp,\n","        ),\n","    ),\n","    (\n","        r\"((.*)[zZ]ip [cC]ode(.*))|(.*)[zZ]ip(.*)|(.*)[lL]ocation(.*)|(.*)[wW]here(.*)\",\n","        (\n","            get_zip_code,\n","        ),\n","    ),\n","    (\n","        r\"(.*)\\$?\\d+(\\.\\d+)?%?(.*)|(.*)[dD]ollars?(.*)\",\n","        (\n","            currency_convert,\n","        ),\n","    ),\n","    (\n","        r\"(.*)defin(e|ition)(.*)|(.*)[Ww]ord(.*)|(.*)mean(ing)?(.*)\",\n","        (\n","            get_definition,\n","        ),\n","    )\n",")\n","\n","def respond(self, str):\n","    \"\"\"\n","    Generate a response to the user input.\n","    :type str: str\n","    :param str: The string to be mapped\n","    :rtype: str\n","    \"\"\"\n","\n","    # check each pattern\n","    for (pattern, response) in self._pairs:\n","        match = pattern.match(str)\n","\n","        # did the pattern match?\n","        if match:\n","            resp = response[0]\n","            resp = resp(str)\n","            resp = self._wildcards(resp, match)  # process wildcards\n","\n","            # fix munged punctuation at the end\n","            if resp[-2:] == \"?.\":\n","                resp = resp[:-2] + \".\"\n","            if resp[-2:] == \"??\":\n","                resp = resp[:-2] + \"?\"\n","            return resp\n","\n","chatbot = Chat(responses, reflections)\n","Chat.respond = respond\n","\n","def chat():\n","    print(\"*\" * 75)\n","    print(\"Chatbot!\".center(75))\n","    print(\"*\" * 75)\n","    print(\"Welcome.\")\n","\n","    chatbot.converse()\n","    \n","chat()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":639},"id":"T0NNAEkV2wsW","executionInfo":{"status":"error","timestamp":1686259129391,"user_tz":420,"elapsed":171553,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}},"outputId":"e854f4fb-9db6-4cdf-8bb3-8bff04449974"},"id":"T0NNAEkV2wsW","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["***************************************************************************\n","                                  Chatbot!                                 \n","***************************************************************************\n","Welcome.\n",">What’s the temperature today?\n","The current temperature in Santa Clara is 72°\n",">What’s my zip code?\n","The current ZIP code is 048508.\n",">How much is $19.99 in INR?\n","The correct amount is 1,226.98 Indian Rupee\n",">What’s the definition of love?\n","The definition(s) of love is/are: \n","1. strong affection for another arising out of kinship or personal ties\n","2. attraction based on sexual desire : affection and tenderness felt by lovers\n","3. affection based on admiration, benevolence, or common interests\n","I hope this answers your question.\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-e728d938f0d8>\u001b[0m in \u001b[0;36m<cell line: 118>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0mchatbot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m \u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-5-e728d938f0d8>\u001b[0m in \u001b[0;36mchat\u001b[0;34m()\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Welcome.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mchatbot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/chat/util.py\u001b[0m in \u001b[0;36mconverse\u001b[0;34m(self, quit)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                 \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\">\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"]}]},{"cell_type":"markdown","metadata":{"id":"ba6de3fc"},"source":["# 6. Implement the spell checker for cell phones\n","\n","Have you ever tried to type in something quickly and because the keyboard size in the cell phone is much smaller than your finger, it typing in the neighboring letters?\n","\n","   a) You will implement the spell checker from the site: https://norvig.com/spell-correct.html\n","\n","   b) You will change your code to consider that replacements would only occur to neighboring words. For example, in the picture, the letter 'u' can be replaced by 'y' or 'i'.\n","\n","![Keyboard iPhone](keyboard.png)"],"id":"ba6de3fc"},{"cell_type":"code","source":["import re\n","from collections import Counter\n","\n","def words(text): return re.findall(r'\\w+', text.lower())\n","\n","WORDS = Counter(words(open('/content/drive/MyDrive/ELEN523/Lab 2/big.txt').read()))\n","\n","def P(word, N=sum(WORDS.values())): \n","    \"Probability of `word`.\"\n","    return WORDS[word] / N\n","\n","def correction(word): \n","    \"Most probable spelling correction for word.\"\n","    return max(candidates(word), key=P)\n","\n","def candidates(word): \n","    \"Generate possible spelling corrections for word.\"\n","    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n","\n","def known(words): \n","    \"The subset of `words` that appear in the dictionary of WORDS.\"\n","    return set(w for w in words if w in WORDS)\n","\n","def edits1(word):\n","    \"All edits that are one edit away from `word`.\"\n","    letters    = 'abcdefghijklmnopqrstuvwxyz'\n","    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n","    deletes    = [L + R[1:]               for L, R in splits if R]\n","    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n","    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n","    inserts    = [L + c + R               for L, R in splits for c in letters]\n","    return set(deletes + transposes + replaces + inserts)\n","\n","def edits2(word): \n","    \"All edits that are two edits away from `word`.\"\n","    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"],"metadata":{"id":"ynYq1piY4AWJ"},"id":"ynYq1piY4AWJ","execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(correction('ypu'))\n","print(correction('jirl'))\n","print(correction('vacarion'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kq526-bP4Drb","executionInfo":{"status":"ok","timestamp":1686259318367,"user_tz":420,"elapsed":361,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"}},"outputId":"1a82e814-8ae4-4542-dccc-5878237fd9c8"},"id":"kq526-bP4Drb","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["you\n","girl\n","vacation\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24762,"status":"ok","timestamp":1686259181076,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"},"user_tz":420},"id":"-8m36A0eTSFs","outputId":"46f98746-3251-4d81-8501-0e1914521b2e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"-8m36A0eTSFs"},{"cell_type":"markdown","metadata":{"id":"8f790ebd"},"source":["# 7. Implement the Weighted Mininum Edit Distance\n","\n","In this problem, you will implement the weighted minimum edit distance algorithm of slide 94.\n","\n","You will consider the following.\n","\n","- delete and insertion cost is 1\n","- substitution cost is 1 if it is in adjacent in the keyboard, like in problem 6.b\n","- substitution cost is 2 if it is below or above, or two characters to the right or left (for example, in the example of 6.b, replacing a 'u' by a 't' or 'o' would have a cost of 2\n","- substitution cost is infinity if that does not apply\n","\n","Run the algorithm for the two words: \n","\n","- 'caft' vs 'cat' \n","- 'coffee' vs 'voffrt'"],"id":"8f790ebd"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":168,"status":"ok","timestamp":1683582215298,"user":{"displayName":"Chitvan Patel","userId":"00142577127970509217"},"user_tz":420},"id":"14d37069","outputId":"2e544444-77b4-4608-f180-7d67a98fe322"},"outputs":[{"name":"stdout","output_type":"stream","text":["Weighted Edit Distance between 'caft' and 'cat': 1\n","Weighted Edit Distance between 'coffee' and 'voffrt': 4\n"]}],"source":["def keyboard_distance(char1, char2):\n","    \"\"\"\n","    Compute the distance between two characters based on their position on a standard QWERTY keyboard.\n","    \"\"\"\n","    keyboard = [['1', '2', '3', '4', '5', '6', '7', '8', '9', '0'],\n","                ['q', 'w', 'e', 'r', 't', 'y', 'u', 'i', 'o', 'p'],\n","                ['a', 's', 'd', 'f', 'g', 'h', 'j', 'k', 'l'],\n","                ['z', 'x', 'c', 'v', 'b', 'n', 'm']]\n","\n","    for row in range(len(keyboard)):\n","        if char1 in keyboard[row]:\n","            pos1 = (row, keyboard[row].index(char1))\n","        if char2 in keyboard[row]:\n","            pos2 = (row, keyboard[row].index(char2))\n","\n","    row_diff = abs(pos1[0] - pos2[0])\n","    col_diff = abs(pos1[1] - pos2[1])\n","\n","    if row_diff <= 1 and col_diff <= 1:\n","        return 1  # Adjacent keys have a substitution cost of 1\n","    elif row_diff <= 2 and col_diff <= 2:\n","        return 2  # Keys with a Manhattan distance of 2 have a substitution cost of 2\n","    else:\n","        return float('inf')  # Non-adjacent keys have a substitution cost of infinity\n","\n","\n","def weighted_edit_distance(word1, word2):\n","    \"\"\"\n","    Compute the weighted minimum edit distance between two words.\n","    \"\"\"\n","    m = len(word1)\n","    n = len(word2)\n","\n","    # Initialize the distance matrix\n","    distance = [[0] * (n+1) for _ in range(m+1)]\n","\n","    # Initialize the first row and column\n","    for i in range(m+1):\n","        distance[i][0] = i\n","    for j in range(n+1):\n","        distance[0][j] = j\n","\n","    # Compute the distance matrix\n","    for i in range(1, m+1):\n","        for j in range(1, n+1):\n","            if word1[i-1] == word2[j-1]:\n","                cost = 0  # No operation needed\n","            else:\n","                cost = keyboard_distance(word1[i-1], word2[j-1])  # Compute the substitution cost\n","            distance[i][j] = min(\n","                distance[i-1][j] + 1,  # Deletion\n","                distance[i][j-1] + 1,  # Insertion\n","                distance[i-1][j-1] + cost  # Substitution\n","            )\n","\n","    return distance[m][n]\n","\n","\n","# Example usage\n","word1 = 'caft'\n","word2 = 'cat'\n","distance = weighted_edit_distance(word1, word2)\n","print(f\"Weighted Edit Distance between '{word1}' and '{word2}': {distance}\")\n","\n","word1 = 'coffee'\n","word2 = 'voffrt'\n","distance = weighted_edit_distance(word1, word2)\n","print(f\"Weighted Edit Distance between '{word1}' and '{word2}': {distance}\")\n"],"id":"14d37069"}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}